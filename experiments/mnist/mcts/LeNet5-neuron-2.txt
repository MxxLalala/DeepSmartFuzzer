Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f8ed4089f28>, tc2=<function tc2 at 0x7f8ed409a048>, tc3=<function tc3 at 0x7f8ed409a158>, tfc_threshold=121, time_period=3600, verbose=True)
initial coverage: 66.7939
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90178240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 66.79389312977099
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901015f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90178da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900e0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90101710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900e0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90101780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.3816793893129784 15
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.3816793893129784 16
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.3816793893129784 17
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 0.7633587786259568 18
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 1.1450381679389352 19
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 1.1450381679389352 8
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 1.1450381679389352 20
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebe48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 1.5267175572519136 9
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 1.5267175572519136 21
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 1.908396946564892 10
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 1.908396946564892 22
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9004af98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ab38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebe48> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 2.2900763358778704 23
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb6a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 2.671755725190849 24
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90059898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a3c8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 3.053435114503827 13
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 3.053435114503827 25
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90059c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900592b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb6a0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 3.4351145038168056 14
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 3.4351145038168056 26
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ae10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 3.816793893129784 15
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 3.816793893129784 27
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a2b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 4.198473282442762 16
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 4.198473282442762 28
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098828> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 4.580152671755741 17
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 4.580152671755741 29
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900989b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 4.961832061068719 30
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff0f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900989b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 5.343511450381698 19
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 5.343511450381698 31
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 5.725190839694676 20
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 5.725190839694676 32
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90059cf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 6.106870229007654 21
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 6.106870229007654 33
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90071860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900712e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb940> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 6.488549618320633 22
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 6.488549618320633 34
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90071ef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900712e8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb940> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 6.870229007633611 23
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 6.870229007633611 35
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900711d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb4e0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90098748> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 7.25190839694659 24
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 7.25190839694659 36
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 7.633587786259568 25
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 7.633587786259568 37
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bb70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 8.015267175572546 26
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 8.015267175572546 38
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->5->17
Best Reward: 0.3816793893129784
coverage_call_count 100
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bdd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 8.396946564885525 27
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 8.396946564885525 39
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a1d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 8.778625954198503 28
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 8.778625954198503 40
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90098080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bb70> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 9.160305343511482 29
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 9.160305343511482 41
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900595f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 9.54198473282446 30
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 9.54198473282446 42
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b9e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900594e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bb70> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 9.923664122137438 31
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 9.923664122137438 43
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bb70> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 10.305343511450417 32
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 10.305343511450417 44
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b400> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bb70> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 10.687022900763395 33
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 10.687022900763395 45
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a7f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 11.068702290076374 34
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 11.068702290076374 46
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900714a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a7f0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 11.450381679389352 35
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 11.450381679389352 47
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90002940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900020b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900714a8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90071978> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a7f0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 9.923664122137438 27
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 11.83206106870233 36
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 11.83206106870233 48
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90071160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002be0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a2b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 10.305343511450417 28
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 12.213740458015309 37
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 12.213740458015309 49
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900022b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 10.687022900763395 29
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 12.595419847328287 38
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 12.595419847328287 50
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 11.068702290076374 30
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 12.977099236641266 39
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 12.977099236641266 51
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a2b0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 11.450381679389352 31
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 13.358778625954244 40
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 13.358778625954244 52
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900a89b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900595f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 11.83206106870233 32
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 13.740458015267222 41
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 13.740458015267222 53
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->5->17->0
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90071240> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b2b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 12.213740458015309 33
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 14.1221374045802 42
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 14.1221374045802 54
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90002748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b2b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 12.595419847328287 34
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 14.50381679389318 43
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 14.50381679389318 55
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900029b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b2b0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 9.923664122137438 27
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 12.977099236641266 35
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 14.885496183206158 44
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 14.885496183206158 56
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90071080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b2b0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 10.305343511450417 28
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 13.358778625954244 36
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 15.267175572519136 45
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 15.267175572519136 57
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fc50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bdd8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 10.687022900763395 29
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 13.740458015267222 37
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 15.648854961832114 46
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 15.648854961832114 58
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9001ff60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b470> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 11.068702290076374 30
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 14.1221374045802 38
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 16.030534351145093 47
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 16.030534351145093 59
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bc50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b2b0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 11.450381679389352 31
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 14.50381679389318 39
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 16.41221374045807 48
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 16.41221374045807 60
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9003be10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 11.83206106870233 32
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 14.885496183206158 40
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 16.79389312977105 49
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 16.79389312977105 61
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bdd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b2b0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 12.213740458015309 33
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 15.267175572519136 41
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 17.175572519084028 50
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 17.175572519084028 62
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->5->17->0->14
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900712e8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb940> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 12.595419847328287 34
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 15.648854961832114 42
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 17.557251908397006 51
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 17.557251908397006 63
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 12.977099236641266 35
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 16.030534351145093 43
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 17.938931297709985 52
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 17.938931297709985 64
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003be10> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 13.358778625954244 36
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 16.41221374045807 44
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 18.320610687022963 53
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 18.320610687022963 65
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90002320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059e48> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b470> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 13.740458015267222 37
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 16.79389312977105 45
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 18.70229007633594 54
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 18.70229007633594 66
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90071390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071860> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900712e8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb940> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 14.1221374045802 38
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 17.175572519084028 46
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 19.08396946564892 55
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 19.08396946564892 67
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f6d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002ef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 14.50381679389318 39
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 17.557251908397006 47
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 19.4656488549619 56
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 19.4656488549619 68
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebc50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071860> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900712e8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb940> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 14.885496183206158 40
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 17.938931297709985 48
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 19.847328244274877 57
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 19.847328244274877 69
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2cf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002ef0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 15.267175572519136 41
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 18.320610687022963 49
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 20.229007633587855 58
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 20.229007633587855 70
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607d14a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bdd8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 15.648854961832114 42
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 18.70229007633594 50
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 20.610687022900834 59
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 20.610687022900834 71
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90059c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059e48> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b470> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 9.923664122137438 27
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 16.030534351145093 43
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 19.08396946564892 51
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 20.992366412213812 60
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 20.992366412213812 72
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b7b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b6d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb940> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 10.305343511450417 28
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 16.41221374045807 44
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 19.4656488549619 52
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 21.37404580152679 61
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 21.37404580152679 73
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->5->17->0->14->5
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 10.687022900763395 29
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 16.79389312977105 45
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 19.847328244274877 53
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 21.75572519083977 62
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 21.75572519083977 74
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ab00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f6d8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90002ef0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 11.068702290076374 30
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 17.175572519084028 46
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 20.229007633587855 54
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 22.137404580152747 63
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 22.137404580152747 75
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 11.450381679389352 31
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 17.557251908397006 47
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 20.610687022900834 55
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 22.519083969465726 64
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 22.519083969465726 76
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1ef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 11.83206106870233 32
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 17.938931297709985 48
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 20.992366412213812 56
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 22.900763358778704 65
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 22.900763358778704 77
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1ef0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1828> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 12.213740458015309 33
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 18.320610687022963 49
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 21.37404580152679 57
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 23.282442748091682 66
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 23.282442748091682 78
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1828> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 9.923664122137438 27
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 12.595419847328287 34
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 18.70229007633594 50
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 21.75572519083977 58
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 23.66412213740466 67
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 23.66412213740466 79
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607ead30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea8d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fc50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f588> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bdd8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 10.305343511450417 28
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 12.977099236641266 35
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 19.08396946564892 51
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 22.137404580152747 59
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 24.04580152671764 68
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 24.04580152671764 80
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607d10f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d10b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 10.687022900763395 29
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 13.358778625954244 36
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 19.4656488549619 52
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 22.519083969465726 60
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 24.427480916030618 69
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 24.427480916030618 81
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2ba8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ab00> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f6d8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90002ef0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 11.068702290076374 30
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 13.740458015267222 37
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 19.847328244274877 53
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 22.900763358778704 61
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 24.809160305343596 70
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 24.809160305343596 82
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fa90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea7f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 11.450381679389352 31
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 14.1221374045802 38
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 20.229007633587855 54
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 23.282442748091682 62
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 25.190839694656574 71
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 25.190839694656574 83
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607eaa58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 11.83206106870233 32
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 14.50381679389318 39
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 20.610687022900834 55
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 23.66412213740466 63
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 25.572519083969553 72
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 25.572519083969553 84
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->5->17->0->14->5->10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607eada0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea7b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8160> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 12.213740458015309 33
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 14.885496183206158 40
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 20.992366412213812 56
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 24.04580152671764 64
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 25.95419847328253 73
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 25.95419847328253 85
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607846a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 12.595419847328287 34
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 15.267175572519136 41
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 21.37404580152679 57
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 24.427480916030618 65
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 26.33587786259551 74
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 26.33587786259551 86
Completed Iteration #1
Best Reward: 0.3816793893129784
coverage_call_count 200
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e60784c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607846a0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 12.977099236641266 35
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 15.648854961832114 42
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 21.75572519083977 58
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 24.809160305343596 66
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 26.717557251908488 75
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 26.717557251908488 87
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6078acf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078ac18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607846a0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 13.358778625954244 36
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 16.030534351145093 43
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 22.137404580152747 59
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 25.190839694656574 67
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 27.099236641221466 76
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 27.099236641221466 88
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea9e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607eac50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 13.740458015267222 37
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 16.41221374045807 44
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 22.519083969465726 60
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 25.572519083969553 68
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 27.480916030534445 77
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 27.480916030534445 89
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078ac18> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607846a0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 14.1221374045802 38
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 16.79389312977105 45
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 22.900763358778704 61
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 25.95419847328253 69
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 27.862595419847423 78
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 27.862595419847423 90
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607847b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea7b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8160> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 14.50381679389318 39
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 17.175572519084028 46
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 23.282442748091682 62
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 26.33587786259551 70
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 28.2442748091604 79
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 28.2442748091604 91
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->5->17->0->14->5->10->8
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6078af28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 9.923664122137438 27
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 14.885496183206158 40
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 17.557251908397006 47
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 23.66412213740466 63
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 26.717557251908488 71
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 28.62595419847338 80
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 28.62595419847338 92
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6078af98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a588> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 10.305343511450417 28
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 15.267175572519136 41
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 17.938931297709985 48
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 24.04580152671764 64
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 27.099236641221466 72
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 29.00763358778636 81
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 29.00763358778636 93
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa7b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1a58> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2ba8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ab00> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f6d8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90002ef0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 10.687022900763395 29
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 15.648854961832114 42
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 18.320610687022963 49
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 24.427480916030618 65
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 27.480916030534445 73
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 29.389312977099337 82
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 29.389312977099337 94
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a6a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607eac50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 11.068702290076374 30
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 16.030534351145093 43
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 18.70229007633594 50
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 24.809160305343596 66
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 27.862595419847423 74
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 29.770992366412315 83
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 29.770992366412315 95
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607aadd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaa90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078af98> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a588> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 11.450381679389352 31
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 16.41221374045807 44
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 19.08396946564892 51
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 25.190839694656574 67
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 28.2442748091604 75
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 30.152671755725294 84
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 30.152671755725294 96
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bfd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 11.83206106870233 32
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 16.79389312977105 45
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 19.4656488549619 52
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 25.572519083969553 68
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 28.62595419847338 76
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 30.534351145038272 85
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 30.534351145038272 97
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a588> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 12.213740458015309 33
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 17.175572519084028 46
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 19.847328244274877 53
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 25.95419847328253 69
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 29.00763358778636 77
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 30.91603053435125 86
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 30.91603053435125 98
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e60784898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078af28> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a588> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 9.923664122137438 27
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 12.595419847328287 34
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 17.557251908397006 47
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 20.229007633587855 54
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 26.33587786259551 70
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 29.389312977099337 78
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 31.29770992366423 87
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 31.29770992366423 99
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607eac50> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 10.305343511450417 28
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 12.977099236641266 35
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 17.938931297709985 48
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 20.610687022900834 55
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 26.717557251908488 71
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 29.770992366412315 79
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 31.679389312977207 88
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 31.679389312977207 100
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607d16d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607eac50> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 10.687022900763395 29
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 13.358778625954244 36
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 18.320610687022963 49
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 20.992366412213812 56
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 27.099236641221466 72
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 30.152671755725294 80
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 32.061068702290186 89
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 32.061068702290186 101
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e60744630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea160> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bcf8> 11.068702290076374 30
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d68> 13.740458015267222 37
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 18.70229007633594 50
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff710> 21.37404580152679 57
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff8d0> 27.480916030534445 73
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 30.534351145038272 81
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8780> 32.442748091603164 90
backprop <src.mcts.MCTS_Node object at 0x7f8e900989e8> 32.442748091603164 102
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->5->17->0->14->5->10->8->14
Best Reward: 0.3816793893129784
iteration: 1
found coverage increase 0.3816793893129784
Current Total Coverage 67.17557251908397
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607842b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607494e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c18> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607713c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607713c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607713c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607497b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607005c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60771438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 67.17557251908397
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607494a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607494a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606853c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 67.17557251908397
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072deb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072deb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606419e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606419e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60685940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea034dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0257668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea02494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8eee188160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea02494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea02494a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea23d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea02494a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900590f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900590f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900590f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 67.17557251908397
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90166358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.3816793893129784 19
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f98> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.3816793893129784 20
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bf28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.7633587786259568 21
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.7633587786259568 22
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 0.7633587786259568 7
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 0.7633587786259568 23
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900717f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 1.1450381679389352 8
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 1.1450381679389352 24
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059b70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f98> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 1.5267175572519136 9
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 1.5267175572519136 25
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 1.5267175572519136 10
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 1.5267175572519136 26
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9007ba20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004af98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bf28> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 1.908396946564892 11
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 1.908396946564892 27
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bf28> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 1.908396946564892 12
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 1.908396946564892 28
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 1.908396946564892 13
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 1.908396946564892 29
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 2.2900763358778704 14
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 2.2900763358778704 30
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059b70> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f98> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 2.671755725190849 15
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 2.671755725190849 31
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 3.053435114503827 16
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 3.053435114503827 32
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90166400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 3.4351145038168056 33
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004af98> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bf28> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 3.4351145038168056 18
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 3.4351145038168056 34
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff240> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1c50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 3.816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 3.816793893129784 35
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7b8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 3.816793893129784 20
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 3.816793893129784 36
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 4.198473282442762 21
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 4.198473282442762 37
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7b8> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 4.580152671755741 22
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 4.580152671755741 38
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7b8> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 4.580152671755741 23
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 4.580152671755741 39
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900592e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 4.961832061068719 24
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 4.961832061068719 40
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7b8> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 4.961832061068719 25
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 4.961832061068719 41
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90178358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 5.343511450381698 26
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 5.343511450381698 42
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->6->17
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 5.725190839694676 27
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 5.725190839694676 43
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 6.106870229007654 28
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 6.106870229007654 44
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90098390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 6.488549618320633 29
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 6.488549618320633 45
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90101588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90178358> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 3.816793893129784 15
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 6.488549618320633 30
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 6.488549618320633 46
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 3.816793893129784 16
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 6.488549618320633 31
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 6.488549618320633 47
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 4.198473282442762 17
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 6.870229007633611 32
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 6.870229007633611 48
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 4.198473282442762 18
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 6.870229007633611 33
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 6.870229007633611 49
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e606acd30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 4.580152671755741 19
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 7.25190839694659 34
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 7.25190839694659 50
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 3.053435114503827 13
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 4.580152671755741 20
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 7.25190839694659 35
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 7.25190839694659 51
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->6->17->5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900592e8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 3.053435114503827 14
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 4.580152671755741 21
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 7.25190839694659 36
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 7.25190839694659 52
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 3.4351145038168056 15
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 4.961832061068719 22
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 7.633587786259568 37
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 7.633587786259568 53
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffeb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 3.816793893129784 16
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 5.343511450381698 23
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 8.015267175572546 38
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 8.015267175572546 54
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901bae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1fd0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 3.816793893129784 17
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 5.343511450381698 24
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 8.015267175572546 39
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 8.015267175572546 55
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901a4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 5.343511450381698 25
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 8.015267175572546 40
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 8.015267175572546 56
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 3.816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 5.343511450381698 26
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 8.015267175572546 41
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 8.015267175572546 57
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 3.816793893129784 20
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 5.343511450381698 27
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 8.015267175572546 42
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 8.015267175572546 58
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e60641cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 2.671755725190849 13
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 4.198473282442762 21
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 5.725190839694676 28
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 8.396946564885525 43
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 8.396946564885525 59
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900592b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 4.198473282442762 22
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 5.725190839694676 29
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 8.396946564885525 44
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 8.396946564885525 60
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
coverage_call_count 700
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffeb8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 2.671755725190849 15
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 4.198473282442762 23
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 5.725190839694676 30
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 8.396946564885525 45
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 8.396946564885525 61
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e60685588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 3.053435114503827 16
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 4.580152671755741 24
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 6.106870229007654 31
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 8.778625954198503 46
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 8.778625954198503 62
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->6->17->5->1
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90002f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 4.961832061068719 25
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 6.488549618320633 32
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 9.160305343511482 47
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 9.160305343511482 63
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e901016a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 3.053435114503827 13
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 5.343511450381698 26
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 6.870229007633611 33
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 9.54198473282446 48
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 9.54198473282446 64
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641cc0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 3.053435114503827 14
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 3.816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 5.343511450381698 27
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 6.870229007633611 34
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 9.54198473282446 49
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 9.54198473282446 65
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1fd0> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 3.816793893129784 20
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 5.343511450381698 28
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 6.870229007633611 35
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 9.54198473282446 50
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 9.54198473282446 66
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 4.198473282442762 21
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 5.725190839694676 29
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 7.25190839694659 36
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 9.923664122137438 51
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 9.923664122137438 67
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1fd0> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 4.198473282442762 22
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 5.725190839694676 30
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 7.25190839694659 37
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 9.923664122137438 52
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 9.923664122137438 68
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90002320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 4.580152671755741 23
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 6.106870229007654 31
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 7.633587786259568 38
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 10.305343511450417 53
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 10.305343511450417 69
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffcf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002320> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 4.198473282442762 19
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 4.961832061068719 24
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 6.488549618320633 32
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 8.015267175572546 39
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 10.687022900763395 54
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 10.687022900763395 70
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900592e8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 4.198473282442762 20
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 4.961832061068719 25
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 6.488549618320633 33
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 8.015267175572546 40
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 10.687022900763395 55
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 10.687022900763395 71
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffeb8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 4.198473282442762 21
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 4.961832061068719 26
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 6.488549618320633 34
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 8.015267175572546 41
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 10.687022900763395 56
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 10.687022900763395 72
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1fd0> 0.3816793893129784 6
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 4.198473282442762 22
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 4.961832061068719 27
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 6.488549618320633 35
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 8.015267175572546 42
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 10.687022900763395 57
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 10.687022900763395 73
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->6->17->5->1->0
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606acc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901016a0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1c88> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 4.198473282442762 23
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 4.961832061068719 28
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 6.488549618320633 36
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 8.015267175572546 43
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 10.687022900763395 58
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 10.687022900763395 74
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90098780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 4.580152671755741 24
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 5.343511450381698 29
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 6.870229007633611 37
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 8.396946564885525 44
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 11.068702290076374 59
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 11.068702290076374 75
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e90002c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 4.961832061068719 25
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 5.725190839694676 30
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 7.25190839694659 38
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 8.778625954198503 45
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 11.450381679389352 60
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 11.450381679389352 76
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa8d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac128> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 5.343511450381698 26
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 6.106870229007654 31
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 7.633587786259568 39
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 9.160305343511482 46
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 11.83206106870233 61
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 11.83206106870233 77
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac128> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 5.343511450381698 27
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 6.106870229007654 32
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 7.633587786259568 40
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 9.160305343511482 47
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 11.83206106870233 62
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 11.83206106870233 78
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098780> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac128> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 5.343511450381698 28
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 6.106870229007654 33
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 7.633587786259568 41
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 9.160305343511482 48
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 11.83206106870233 63
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 11.83206106870233 79
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 1.908396946564892 10
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 5.343511450381698 29
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 6.106870229007654 34
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 7.633587786259568 42
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 9.160305343511482 49
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 11.83206106870233 64
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 11.83206106870233 80
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eed68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098780> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac128> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 5.725190839694676 30
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 6.488549618320633 35
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 8.015267175572546 43
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 9.54198473282446 50
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 12.213740458015309 65
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 12.213740458015309 81
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901016a0> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1c88> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 5.725190839694676 31
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 6.488549618320633 36
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 8.015267175572546 44
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 9.54198473282446 51
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 12.213740458015309 66
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 12.213740458015309 82
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2cf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 2.671755725190849 13
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 6.106870229007654 32
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 6.870229007633611 37
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 8.396946564885525 45
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 9.923664122137438 52
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 12.595419847328287 67
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 12.595419847328287 83
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90101780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac128> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 6.106870229007654 33
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 6.870229007633611 38
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 8.396946564885525 46
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 9.923664122137438 53
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 12.595419847328287 68
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 12.595419847328287 84
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e60685828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac128> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 6.488549618320633 34
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 7.25190839694659 39
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 8.778625954198503 47
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 10.305343511450417 54
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 12.977099236641266 69
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 12.977099236641266 85
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2a90> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 3.053435114503827 16
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 6.488549618320633 35
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 7.25190839694659 40
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 8.778625954198503 48
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 10.305343511450417 55
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 12.977099236641266 70
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 12.977099236641266 86
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->6->17->5->1->0->2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002c50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 6.870229007633611 36
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 7.633587786259568 41
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 9.160305343511482 49
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 10.687022900763395 56
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 13.358778625954244 71
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 13.358778625954244 87
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2ef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 7.25190839694659 37
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 8.015267175572546 42
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 9.54198473282446 50
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 11.068702290076374 57
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 13.740458015267222 72
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 13.740458015267222 88
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a3c8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2ef0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 4.198473282442762 19
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 7.633587786259568 38
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 8.396946564885525 43
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 9.923664122137438 51
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 11.450381679389352 58
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 14.1221374045802 73
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 14.1221374045802 89
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa3c8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002c50> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 4.580152671755741 20
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 8.015267175572546 39
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 8.778625954198503 44
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 10.305343511450417 52
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 11.83206106870233 59
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 14.50381679389318 74
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 14.50381679389318 90
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ab00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 4.961832061068719 21
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 8.396946564885525 40
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 9.160305343511482 45
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 10.687022900763395 53
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 12.213740458015309 60
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 14.885496183206158 75
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 14.885496183206158 91
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee4e0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee588> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90002c50> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 4.961832061068719 22
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 8.396946564885525 41
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 9.160305343511482 46
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 10.687022900763395 54
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 12.213740458015309 61
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 14.885496183206158 76
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 14.885496183206158 92
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ab00> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 4.961832061068719 23
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 8.396946564885525 42
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 9.160305343511482 47
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 10.687022900763395 55
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 12.213740458015309 62
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 14.885496183206158 77
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 14.885496183206158 93
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 4.961832061068719 24
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 8.396946564885525 43
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 9.160305343511482 48
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 10.687022900763395 56
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 12.213740458015309 63
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 14.885496183206158 78
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 14.885496183206158 94
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 5.343511450381698 25
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 8.778625954198503 44
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 9.54198473282446 49
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 11.068702290076374 57
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 12.595419847328287 64
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 15.267175572519136 79
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 15.267175572519136 95
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a400> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa3c8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90002c50> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 5.343511450381698 26
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 8.778625954198503 45
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 9.54198473282446 50
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 11.068702290076374 58
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 12.595419847328287 65
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 15.267175572519136 80
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 15.267175572519136 96
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ae10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 3.053435114503827 13
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 5.725190839694676 27
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 9.160305343511482 46
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 9.923664122137438 51
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 11.450381679389352 59
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 12.977099236641266 66
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 15.648854961832114 81
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 15.648854961832114 97
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea2b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 3.4351145038168056 14
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 6.106870229007654 28
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 9.54198473282446 47
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 10.305343511450417 52
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 11.83206106870233 60
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 13.358778625954244 67
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 16.030534351145093 82
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 16.030534351145093 98
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->6->17->5->1->0->2->4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea2b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 3.816793893129784 15
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 6.488549618320633 29
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 9.923664122137438 48
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 10.687022900763395 53
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 12.213740458015309 61
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 13.740458015267222 68
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 16.41221374045807 83
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 16.41221374045807 99
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e60685710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 4.198473282442762 16
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 6.870229007633611 30
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 10.305343511450417 49
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 11.068702290076374 54
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 12.595419847328287 62
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 14.1221374045802 69
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 16.79389312977105 84
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 16.79389312977105 100
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aac8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 4.198473282442762 17
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 6.870229007633611 31
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 10.305343511450417 50
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 11.068702290076374 55
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 12.595419847328287 63
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 14.1221374045802 70
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 16.79389312977105 85
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 16.79389312977105 101
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea940> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea2b0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 4.198473282442762 18
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 6.870229007633611 32
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 10.305343511450417 51
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 11.068702290076374 56
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 12.595419847328287 64
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 14.1221374045802 71
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 16.79389312977105 86
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 16.79389312977105 102
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002518> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 4.198473282442762 19
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 6.870229007633611 33
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 10.305343511450417 52
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 11.068702290076374 57
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 12.595419847328287 65
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 14.1221374045802 72
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 16.79389312977105 87
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 16.79389312977105 103
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685710> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90002518> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 1.908396946564892 10
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 4.198473282442762 20
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 6.870229007633611 34
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 10.305343511450417 53
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 11.068702290076374 58
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 12.595419847328287 66
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 14.1221374045802 73
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 16.79389312977105 88
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 16.79389312977105 104
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea2b0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 4.580152671755741 21
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 7.25190839694659 35
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 10.687022900763395 54
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 11.450381679389352 59
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 12.977099236641266 67
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 14.50381679389318 74
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 17.175572519084028 89
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 17.175572519084028 105
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea940> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea2b0> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 4.580152671755741 22
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 7.25190839694659 36
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 10.687022900763395 55
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 11.450381679389352 60
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 12.977099236641266 68
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 14.50381679389318 75
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 17.175572519084028 90
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 17.175572519084028 106
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e60700780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607005f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaef0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea2b0> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 2.671755725190849 13
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 4.961832061068719 23
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 7.633587786259568 37
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 11.068702290076374 56
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 11.83206106870233 61
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 13.358778625954244 69
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 14.885496183206158 76
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 17.557251908397006 91
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 17.557251908397006 107
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aac8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 4.961832061068719 24
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 7.633587786259568 38
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 11.068702290076374 57
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 11.83206106870233 62
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 13.358778625954244 70
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 14.885496183206158 77
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 17.557251908397006 92
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 17.557251908397006 108
Completed Iteration #19
Best Reward: 0.3816793893129784
coverage_call_count 800
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607005f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaef0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea2b0> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 5.343511450381698 25
backprop <src.mcts.MCTS_Node object at 0x7f8e60641898> 8.015267175572546 39
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1518> 11.450381679389352 58
backprop <src.mcts.MCTS_Node object at 0x7f8e900a87b8> 12.213740458015309 63
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8f98> 13.740458015267222 71
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f048> 15.267175572519136 78
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 17.938931297709985 93
backprop <src.mcts.MCTS_Node object at 0x7f8e900710b8> 17.938931297709985 109
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->6->17->5->1->0->2->4->10
Best Reward: 0.3816793893129784
iteration: 15
found coverage increase 0.3816793893129784
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607000b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607004e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607004e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607004e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607491d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a940> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d9e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.3816793893129784 15
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d9e8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.3816793893129784 16
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.3816793893129784 17
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.3816793893129784 18
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d9e8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 0.3816793893129784 6
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.3816793893129784 19
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 0.3816793893129784 7
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.3816793893129784 20
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 0.3816793893129784 8
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.3816793893129784 21
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 0.3816793893129784 9
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.3816793893129784 22
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 0.7633587786259568 10
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 0.7633587786259568 23
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67ca20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d9e8> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 1.1450381679389352 11
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 1.1450381679389352 24
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 1.1450381679389352 12
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 1.1450381679389352 25
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 1.1450381679389352 13
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 1.1450381679389352 26
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c588> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d9e8> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 1.5267175572519136 14
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 1.5267175572519136 27
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 1.908396946564892 15
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 1.908396946564892 28
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 1.908396946564892 16
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 1.908396946564892 29
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 1.908396946564892 17
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 1.908396946564892 30
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->1
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cf98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cc0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 2.2900763358778704 18
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 2.2900763358778704 31
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cf98> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cc0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 2.2900763358778704 19
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 2.2900763358778704 32
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066ae48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cf98> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cc0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 2.671755725190849 20
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 2.671755725190849 33
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cc0> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 2.671755725190849 21
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 2.671755725190849 34
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 3.053435114503827 22
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 3.053435114503827 35
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cc0> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 3.4351145038168056 23
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 3.4351145038168056 36
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 3.4351145038168056 24
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 3.4351145038168056 37
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066ae48> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cf98> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cc0> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 3.4351145038168056 25
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 3.4351145038168056 38
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 3.4351145038168056 26
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 3.4351145038168056 39
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687518> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cc0> 1.5267175572519136 9
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 2.2900763358778704 13
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 3.4351145038168056 27
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 3.4351145038168056 40
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697908> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cc0> 1.5267175572519136 10
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 2.2900763358778704 14
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 3.4351145038168056 28
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 3.4351145038168056 41
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 2.2900763358778704 15
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 3.4351145038168056 29
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 3.4351145038168056 42
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afdd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 2.671755725190849 16
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 3.816793893129784 30
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 3.816793893129784 43
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 2.671755725190849 17
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 3.816793893129784 31
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 3.816793893129784 44
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afdd8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 2.671755725190849 18
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 3.816793893129784 32
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 3.816793893129784 45
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cd30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687668> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 3.053435114503827 19
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 4.198473282442762 33
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 4.198473282442762 46
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->1->19
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afdd8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 3.053435114503827 20
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 4.198473282442762 34
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 4.198473282442762 47
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cd30> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687668> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 1.1450381679389352 8
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 3.053435114503827 21
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 4.198473282442762 35
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 4.198473282442762 48
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e900025c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 1.5267175572519136 9
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 3.4351145038168056 22
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 4.580152671755741 36
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 4.580152671755741 49
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 1.5267175572519136 10
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 3.4351145038168056 23
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 4.580152671755741 37
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 4.580152671755741 50
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6976a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cd30> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687668> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 1.908396946564892 11
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 3.816793893129784 24
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 4.961832061068719 38
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 4.961832061068719 51
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 4.198473282442762 25
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 5.343511450381698 39
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 5.343511450381698 52
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900025c0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 2.2900763358778704 13
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 4.198473282442762 26
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 5.343511450381698 40
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 5.343511450381698 53
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 4.580152671755741 27
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 5.725190839694676 41
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 5.725190839694676 54
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900025c0> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 2.671755725190849 15
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 4.580152671755741 28
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 5.725190839694676 42
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 5.725190839694676 55
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afeb8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 3.053435114503827 16
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 4.961832061068719 29
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 6.106870229007654 43
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 6.106870229007654 56
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64be48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 5.343511450381698 30
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 6.488549618320633 44
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 6.488549618320633 57
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bbe0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 5.725190839694676 31
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 6.870229007633611 45
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 6.870229007633611 58
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e6072dda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607719b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 4.198473282442762 19
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 6.106870229007654 32
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 7.25190839694659 46
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 7.25190839694659 59
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afeb8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 4.198473282442762 20
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 6.106870229007654 33
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 7.25190839694659 47
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 7.25190839694659 60
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afd68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900025c0> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 4.580152671755741 21
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 6.488549618320633 34
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 7.633587786259568 48
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 7.633587786259568 61
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->1->19->4
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072dda0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607719b0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 4.580152671755741 22
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 6.488549618320633 35
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 7.633587786259568 49
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 7.633587786259568 62
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607719b0> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 4.580152671755741 23
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 6.488549618320633 36
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 7.633587786259568 50
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 7.633587786259568 63
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64be48> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 4.961832061068719 24
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 6.870229007633611 37
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 8.015267175572546 51
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 8.015267175572546 64
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 4.961832061068719 25
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 6.870229007633611 38
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 8.015267175572546 52
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 8.015267175572546 65
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697b38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 5.343511450381698 26
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 7.25190839694659 39
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 8.396946564885525 53
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 8.396946564885525 66
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6618d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6611d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bbe0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 5.725190839694676 27
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 7.633587786259568 40
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 8.778625954198503 54
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 8.778625954198503 67
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 5.725190839694676 28
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 7.633587786259568 41
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 8.778625954198503 55
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 8.778625954198503 68
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661cf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6618d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6611d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bbe0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 3.053435114503827 13
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 6.106870229007654 29
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 8.015267175572546 42
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 9.160305343511482 56
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 9.160305343511482 69
Completed Iteration #18
Best Reward: 0.3816793893129784
coverage_call_count 1000
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 3.4351145038168056 14
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 6.488549618320633 30
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 8.396946564885525 43
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 9.54198473282446 57
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 9.54198473282446 70
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 3.4351145038168056 15
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 6.488549618320633 31
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 8.396946564885525 44
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 9.54198473282446 58
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 9.54198473282446 71
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->1->19->4->15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 6.488549618320633 32
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 8.396946564885525 45
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 9.54198473282446 59
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 9.54198473282446 72
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 6.488549618320633 33
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 8.396946564885525 46
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 9.54198473282446 60
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 9.54198473282446 73
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bbe0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 3.4351145038168056 18
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 6.488549618320633 34
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 8.396946564885525 47
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 9.54198473282446 61
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 9.54198473282446 74
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6525f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 3.816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 6.870229007633611 35
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 8.778625954198503 48
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 9.923664122137438 62
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 9.923664122137438 75
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64be48> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 2.671755725190849 13
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 3.816793893129784 20
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 6.870229007633611 36
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 8.778625954198503 49
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 9.923664122137438 63
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 9.923664122137438 76
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 3.816793893129784 21
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 6.870229007633611 37
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 8.778625954198503 50
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 9.923664122137438 64
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 9.923664122137438 77
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 4.198473282442762 22
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 7.25190839694659 38
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 9.160305343511482 51
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 10.305343511450417 65
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 10.305343511450417 78
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 4.580152671755741 23
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 7.633587786259568 39
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 9.54198473282446 52
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 10.687022900763395 66
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 10.687022900763395 79
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64be48> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 4.580152671755741 24
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 7.633587786259568 40
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 9.54198473282446 53
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 10.687022900763395 67
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 10.687022900763395 80
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->1->19->4->15->0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 3.4351145038168056 18
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 4.580152671755741 25
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 7.633587786259568 41
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 9.54198473282446 54
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 10.687022900763395 68
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 10.687022900763395 81
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 3.4351145038168056 19
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 4.580152671755741 26
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 7.633587786259568 42
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 9.54198473282446 55
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 10.687022900763395 69
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 10.687022900763395 82
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 3.4351145038168056 20
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 4.580152671755741 27
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 7.633587786259568 43
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 9.54198473282446 56
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 10.687022900763395 70
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 10.687022900763395 83
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 3.816793893129784 21
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 4.961832061068719 28
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 8.015267175572546 44
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 9.923664122137438 57
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 11.068702290076374 71
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 11.068702290076374 84
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 4.198473282442762 22
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 5.343511450381698 29
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 8.396946564885525 45
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 10.305343511450417 58
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 11.450381679389352 72
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 11.450381679389352 85
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d78d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 4.580152671755741 23
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 5.725190839694676 30
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 8.778625954198503 46
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 10.687022900763395 59
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 11.83206106870233 73
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 11.83206106870233 86
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 4.961832061068719 24
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 6.106870229007654 31
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 9.160305343511482 47
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 11.068702290076374 60
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 12.213740458015309 74
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 12.213740458015309 87
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f76d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 5.343511450381698 25
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 6.488549618320633 32
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 9.54198473282446 48
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 11.450381679389352 61
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 12.595419847328287 75
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 12.595419847328287 88
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f72b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7470> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 5.725190839694676 26
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 6.870229007633611 33
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 9.923664122137438 49
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 11.83206106870233 62
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 12.977099236641266 76
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 12.977099236641266 89
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 3.053435114503827 13
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 5.725190839694676 27
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 6.870229007633611 34
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 9.923664122137438 50
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 11.83206106870233 63
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 12.977099236641266 77
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 12.977099236641266 90
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 3.4351145038168056 14
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 6.106870229007654 28
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 7.25190839694659 35
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 10.305343511450417 51
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 12.213740458015309 64
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 13.358778625954244 78
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 13.358778625954244 91
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 3.816793893129784 15
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 6.488549618320633 29
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 7.633587786259568 36
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 10.687022900763395 52
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 12.595419847328287 65
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 13.740458015267222 79
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 13.740458015267222 92
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->1->19->4->15->0->13
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7c88> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 3.816793893129784 16
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 6.488549618320633 30
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 7.633587786259568 37
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 10.687022900763395 53
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 12.595419847328287 66
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 13.740458015267222 80
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 13.740458015267222 93
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7c88> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 4.198473282442762 17
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 6.870229007633611 31
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 8.015267175572546 38
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 11.068702290076374 54
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 12.977099236641266 67
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 14.1221374045802 81
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 14.1221374045802 94
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bb38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d78d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 4.580152671755741 18
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 7.25190839694659 32
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 8.396946564885525 39
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 11.450381679389352 55
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 13.358778625954244 68
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 14.50381679389318 82
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 14.50381679389318 95
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bb38> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d78d0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 4.961832061068719 19
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 7.633587786259568 33
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 8.778625954198503 40
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 11.83206106870233 56
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 13.740458015267222 69
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 14.885496183206158 83
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 14.885496183206158 96
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78ce10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 5.343511450381698 20
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 8.015267175572546 34
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 9.160305343511482 41
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 12.213740458015309 57
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 14.1221374045802 70
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 15.267175572519136 84
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 15.267175572519136 97
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 4.198473282442762 16
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 5.343511450381698 21
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 8.015267175572546 35
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 9.160305343511482 42
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 12.213740458015309 58
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 14.1221374045802 71
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 15.267175572519136 85
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 15.267175572519136 98
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c6d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d78d0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 4.580152671755741 17
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 5.725190839694676 22
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 8.396946564885525 36
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 9.54198473282446 43
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 12.595419847328287 59
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 14.50381679389318 72
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 15.648854961832114 86
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 15.648854961832114 99
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 4.580152671755741 18
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 5.725190839694676 23
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 8.396946564885525 37
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 9.54198473282446 44
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 12.595419847328287 60
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 14.50381679389318 73
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 15.648854961832114 87
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 15.648854961832114 100
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->1->19->4->15->0->13->5
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78ce10> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 4.961832061068719 19
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 6.106870229007654 24
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 8.778625954198503 38
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 9.923664122137438 45
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 12.977099236641266 61
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 14.885496183206158 74
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 16.030534351145093 88
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 16.030534351145093 101
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7eb8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78ce10> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 5.343511450381698 20
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 6.488549618320633 25
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 9.160305343511482 39
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 10.305343511450417 46
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 13.358778625954244 62
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 15.267175572519136 75
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 16.41221374045807 89
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 16.41221374045807 102
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792ac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 5.725190839694676 21
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 6.870229007633611 26
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 9.54198473282446 40
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 10.687022900763395 47
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 13.740458015267222 63
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 15.648854961832114 76
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 16.79389312977105 90
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 16.79389312977105 103
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 6.106870229007654 22
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 7.25190839694659 27
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 9.923664122137438 41
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 11.068702290076374 48
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 14.1221374045802 64
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 16.030534351145093 77
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 17.175572519084028 91
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 17.175572519084028 104
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 6.488549618320633 23
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 7.633587786259568 28
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 10.305343511450417 42
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 11.450381679389352 49
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 14.50381679389318 65
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 16.41221374045807 78
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 17.557251908397006 92
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 17.557251908397006 105
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6160> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 6.488549618320633 24
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 7.633587786259568 29
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 10.305343511450417 43
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 11.450381679389352 50
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 14.50381679389318 66
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 16.41221374045807 79
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 17.557251908397006 93
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 17.557251908397006 106
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f74e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792c50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 6.870229007633611 25
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 8.015267175572546 30
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 10.687022900763395 44
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 11.83206106870233 51
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 14.885496183206158 67
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 16.79389312977105 80
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 17.938931297709985 94
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 17.938931297709985 107
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 6.870229007633611 26
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 8.015267175572546 31
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 10.687022900763395 45
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 11.83206106870233 52
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 14.885496183206158 68
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 16.79389312977105 81
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 17.938931297709985 95
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 17.938931297709985 108
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792d30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 7.25190839694659 27
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 8.396946564885525 32
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 11.068702290076374 46
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 12.213740458015309 53
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 15.267175572519136 69
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 17.175572519084028 82
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 18.320610687022963 96
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 18.320610687022963 109
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a60f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792ac8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 4.580152671755741 15
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 7.633587786259568 28
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 8.778625954198503 33
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 11.450381679389352 47
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 12.595419847328287 54
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 15.648854961832114 70
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 17.557251908397006 83
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 18.70229007633594 97
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 18.70229007633594 110
Completed Iteration #21
Best Reward: 0.3816793893129784
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6748> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6160> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2400> 7.633587786259568 29
backprop <src.mcts.MCTS_Node object at 0x7f8e60784da0> 8.778625954198503 34
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 11.450381679389352 48
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697470> 12.595419847328287 55
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6872b0> 15.648854961832114 71
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 17.557251908397006 84
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 18.70229007633594 98
backprop <src.mcts.MCTS_Node object at 0x7f8e60784438> 18.70229007633594 111
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->1->19->4->15->0->13->5->0
Best Reward: 0.3816793893129784
iteration: 19
found coverage increase 0.3816793893129784
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dc50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dc50> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7928d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7928d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7928d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7928d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d518> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 12
Completed Iteration #18
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722550> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6886d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6885f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a02b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a02b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a02b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6886d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6883c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6889e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6660f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6660f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b94e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b94e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6664a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6664a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6664a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c59e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6664a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c54a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181930f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181825f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18182400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181930f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181930b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181930b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181823c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181935c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181930b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181822b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181933c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6613c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6613c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bcc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e10> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652f60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6979e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6979e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6979e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181825c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181825c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2198> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607eae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18193ac8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607718d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607718d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607718d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181934e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90101630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90101588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90101588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606acc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901bab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606acc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90101320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606acc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901bab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606acc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606acc18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900029e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606851d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90170da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900e0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901a4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a89b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900e0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffcf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fdd8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90101550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606acd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 2000
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1d30> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eeba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90166710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90166390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90166358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900594a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8eee188160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90166320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90071d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90101780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900590f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90059fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea034d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea02496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea02495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea02495f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea02493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea02495f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea02492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 16
Completed Iteration #18
Best Reward: 0
coverage_call_count 2100
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f198> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea23d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606410f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ebe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea02493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea034dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0323fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea02492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea02496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aa58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181d56a0> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900592b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900592b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b34a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b34a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004aa20> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7925f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7925f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfb38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90170dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea02496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900021d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea02497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 12
Completed Iteration #11
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6875c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90170dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90170dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0323fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606419e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90170dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a04a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6881d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d74e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d74e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d74e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d74e0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7149b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6876a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d908> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7140b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7140b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7140b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7140b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c8d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7226a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7074e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7220b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7076d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7076d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6873c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de77110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77114e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77111d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de77113c8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de77369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77363c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77360b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77367b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77360b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77367b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77360b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de77115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77363c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de77112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77110b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77110b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7711c88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.3816793893129642 6
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.7633587786259284 7
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.7633587786259284 8
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 1.1450381679388926 9
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 1.1450381679388926 6
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 1.1450381679388926 10
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 1.1450381679388926 11
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 1.1450381679388926 12
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 1.1450381679388926 13
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c50b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 1.1450381679388926 14
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5668> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 1.1450381679388926 7
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 1.1450381679388926 15
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 1.5267175572518568 8
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 1.5267175572518568 16
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 1.5267175572518568 9
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 1.5267175572518568 17
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de76e97f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9940> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9668> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 1.908396946564821 10
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 1.908396946564821 18
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de768a470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9c50> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 2.290076335877785 11
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 2.290076335877785 19
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 2.290076335877785 12
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 2.290076335877785 20
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de768aa90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9da0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 2.6717557251907493 13
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 2.6717557251907493 21
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de768aa58> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 3.0534351145037135 14
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 3.0534351145037135 22
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de768afd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76904e0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9668> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 3.4351145038166777 15
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 3.4351145038166777 23
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 3.4351145038166777 16
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 3.4351145038166777 24
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de7690b38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690dd8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768aa58> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 3.816793893129642 17
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 3.816793893129642 25
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5668> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 3.816793893129642 18
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 3.816793893129642 26
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de7690a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9da0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 4.198473282442606 19
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 4.198473282442606 27
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 4.58015267175557 20
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 4.58015267175557 28
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e900592b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 4.9618320610685345 21
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 4.9618320610685345 29
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf940> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9da0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 5.343511450381499 22
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 5.343511450381499 30
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e10> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 5.725190839694463 23
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 5.725190839694463 31
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de768ab00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 6.106870229007427 24
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 6.106870229007427 32
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de768ab38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 6.488549618320391 25
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 6.488549618320391 33
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5f98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 6.870229007633355 26
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 6.870229007633355 34
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5d68> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 7.25190839694632 27
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 7.25190839694632 35
Completed Iteration #22
Best Reward: 0.3816793893129642
coverage_call_count 2700
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de768a320> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77367b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf940> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9da0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 7.633587786259284 28
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 7.633587786259284 36
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #2
root->8->7
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de7736cf8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 8.015267175572248 29
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 8.015267175572248 37
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de7736518> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736e80> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736cf8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 8.396946564885212 30
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 8.396946564885212 38
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 8.778625954198176 31
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 8.778625954198176 39
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de771e978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 6.106870229007427 17
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 9.16030534351114 32
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 9.16030534351114 40
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 6.488549618320391 18
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 9.541984732824105 33
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 9.541984732824105 41
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900592b0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 9.541984732824105 34
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 9.541984732824105 42
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77360b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5f98> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 9.923664122137069 35
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 9.923664122137069 43
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722be0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 10.305343511450033 36
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 10.305343511450033 44
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de768a860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 10.687022900762997 37
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 10.687022900762997 45
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de7690a90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77360b8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5f98> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 11.068702290075962 38
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 11.068702290075962 46
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9a58> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736e80> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7736cf8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 8.396946564885212 24
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 11.450381679388926 39
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 11.450381679388926 47
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #3
root->8->7->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de768a128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 8.778625954198176 25
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 11.83206106870189 40
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 11.83206106870189 48
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7225f8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771efd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a128> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 9.16030534351114 26
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 12.213740458014854 41
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 12.213740458014854 49
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c390> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 9.541984732824105 27
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 12.595419847327818 42
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 12.595419847327818 50
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a60f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 9.923664122137069 28
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 12.977099236640782 43
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 12.977099236640782 51
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de768a630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 8.396946564885212 24
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 10.305343511450033 29
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 13.358778625953747 44
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 13.358778625953747 52
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687ef0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e10> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 8.778625954198176 25
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 10.687022900762997 30
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 13.74045801526671 45
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 13.74045801526671 53
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714080> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 9.16030534351114 26
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 11.068702290075962 31
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 14.122137404579675 46
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 14.122137404579675 54
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6ba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 9.541984732824105 27
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 11.450381679388926 32
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 14.50381679389264 47
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 14.50381679389264 55
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de7736c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 9.923664122137069 28
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 11.83206106870189 33
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 14.885496183205603 48
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 14.885496183205603 56
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #4
root->8->7->0->27
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687ef0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e10> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 10.305343511450033 29
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 12.213740458014854 34
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 15.267175572518568 49
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 15.267175572518568 57
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714f98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687080> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714080> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 6.106870229007427 17
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 10.687022900762997 30
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 12.595419847327818 35
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 15.648854961831532 50
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 15.648854961831532 58
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a02e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf080> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a128> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 6.488549618320391 18
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 11.068702290075962 31
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 12.977099236640782 36
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 16.030534351144496 51
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 16.030534351144496 59
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6877b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 6.106870229007427 17
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 6.870229007633355 19
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 11.450381679388926 32
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 13.358778625953747 37
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 16.41221374045746 52
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 16.41221374045746 60
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf320> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 6.488549618320391 18
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 7.25190839694632 20
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 11.83206106870189 33
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 13.74045801526671 38
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 16.793893129770424 53
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 16.793893129770424 61
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfc88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771efd0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de768a128> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 6.870229007633355 19
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 7.633587786259284 21
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 12.213740458014854 34
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 14.122137404579675 39
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 17.17557251908339 54
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 17.17557251908339 62
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687ba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a630> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 7.25190839694632 20
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 8.015267175572248 22
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 12.595419847327818 35
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 14.50381679389264 40
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 17.557251908396353 55
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 17.557251908396353 63
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792b38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 7.633587786259284 21
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 8.396946564885212 23
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 12.977099236640782 36
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 14.885496183205603 41
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 17.938931297709317 56
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 17.938931297709317 64
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e6064eb70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf080> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de768a128> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 8.015267175572248 22
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 8.778625954198176 24
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 13.358778625953747 37
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 15.267175572518568 42
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 18.32061068702228 57
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 18.32061068702228 65
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #5
root->8->7->0->27->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfb70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6198> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 8.396946564885212 23
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 9.16030534351114 25
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 13.74045801526671 38
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 15.648854961831532 43
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 18.702290076335245 58
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 18.702290076335245 66
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bffd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6198> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 8.778625954198176 24
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 9.541984732824105 26
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 14.122137404579675 39
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 16.030534351144496 44
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 19.08396946564821 59
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 19.08396946564821 67
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0d30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 9.16030534351114 25
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 9.923664122137069 27
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 14.50381679389264 40
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 16.41221374045746 45
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 19.465648854961174 60
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 19.465648854961174 68
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b39e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 9.541984732824105 26
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 10.305343511450033 28
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 14.885496183205603 41
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 16.793893129770424 46
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 19.847328244274138 61
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 19.847328244274138 69
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6198> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 9.923664122137069 27
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 10.687022900762997 29
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 15.267175572518568 42
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 17.17557251908339 47
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 20.229007633587102 62
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 20.229007633587102 70
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 10.305343511450033 28
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 11.068702290075962 30
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 15.648854961831532 43
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 17.557251908396353 48
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 20.610687022900066 63
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 20.610687022900066 71
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
coverage_call_count 2800
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #6
root->8->7->0->27->0->1
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e90155978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 10.687022900762997 29
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 11.450381679388926 31
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 16.030534351144496 44
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 17.938931297709317 49
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 20.99236641221303 64
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 20.99236641221303 72
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e900717f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 11.068702290075962 30
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 11.83206106870189 32
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 16.41221374045746 45
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 18.32061068702228 50
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 21.374045801525995 65
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 21.374045801525995 73
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcef0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 11.450381679388926 31
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 12.213740458014854 33
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 16.793893129770424 46
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 18.702290076335245 51
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 21.75572519083896 66
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 21.75572519083896 74
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcef0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 11.450381679388926 32
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 12.213740458014854 34
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 16.793893129770424 47
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 18.702290076335245 52
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 21.75572519083896 67
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 21.75572519083896 75
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8de7736da0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 11.83206106870189 33
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 12.595419847327818 35
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 17.17557251908339 48
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 19.08396946564821 53
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 22.137404580151923 68
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 22.137404580151923 76
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e90155be0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900717f0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 12.213740458014854 34
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 12.977099236640782 36
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 17.557251908396353 49
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 19.465648854961174 54
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 22.519083969464887 69
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 22.519083969464887 77
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #7
root->8->7->0->27->0->1->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b2b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641470> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900717f0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 12.595419847327818 35
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 13.358778625953747 37
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 17.938931297709317 50
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 19.847328244274138 55
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 22.90076335877785 70
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 22.90076335877785 78
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641470> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900717f0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 12.977099236640782 36
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 13.74045801526671 38
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 18.32061068702228 51
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 20.229007633587102 56
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 23.282442748090816 71
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 23.282442748090816 79
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e900e0f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166438> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155be0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60641470> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f8e900717f0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 13.358778625953747 37
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 14.122137404579675 39
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 18.702290076335245 52
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 20.610687022900066 57
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 23.66412213740378 72
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 23.66412213740378 80
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166438> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90155be0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60641470> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f8e900717f0> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 13.74045801526671 38
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 14.50381679389264 40
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 19.08396946564821 53
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 20.99236641221303 58
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 24.045801526716744 73
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 24.045801526716744 81
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f8e90155c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641470> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f8e900717f0> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714710> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7f8de771ef28> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e48> 14.122137404579675 39
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5630> 14.885496183205603 41
backprop <src.mcts.MCTS_Node object at 0x7f8de768a438> 19.465648854961174 54
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 21.374045801525995 59
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9400> 24.427480916029708 74
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 24.427480916029708 82
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #8
root->8->7->0->27->0->1->0->21
Best Reward: 0.3816793893129642
iteration: 79
found coverage increase 0.3816793893129642
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7926a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 11
Completed Iteration #18
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901bae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff588> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 6
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 7
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 8
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901a4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6875c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a6a0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606859e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900024a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900024a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901bacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606859e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90002748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 3000
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607496d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607009e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6979e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607847b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607847b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078ae10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60784978> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7400> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607440b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901bacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 3100
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0335048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6aff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0335048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e04a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 8
Completed Iteration #11
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181935f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181829b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181935f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d9e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d55f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d55f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6525f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606eea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de77116d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6525f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6526d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7079b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6526d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b00> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c287f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ceef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ceb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65cecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65cecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 3400
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ced30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65cefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ceb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60784400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c149b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c149b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65408d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c149b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65cea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c149b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c149b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28d68> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cdd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65345f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65344a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65345f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6534518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65347b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65347b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65340f0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65406a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65406a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de650c630> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65407f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65407f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a57f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 3700
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64570b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ef0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6478748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6478940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6478ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64780f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64780f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60771710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6478438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64faf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64787b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64266d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64787b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64787b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64786d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6478198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64787b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6478b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64315c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 16
Completed Iteration #17
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6426b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64faf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5feffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64faf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5feff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64787b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f709e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f709e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f097b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f097b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f208> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f096d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65687b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f096d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c286d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0335048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c145f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181827b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181827b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6534048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65407b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65345c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65345c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65345c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6975f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65345c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6072da58> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6974e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90170dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65344a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18182898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60744b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6568358> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606850b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e60700f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65345c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90166240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65685f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65685f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65685f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea23d2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65685f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea02497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65346a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901557f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901557f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90170dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0323fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea23d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7925c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8eee188160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea2652b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7925c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90194390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90166128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7925c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7925c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7925c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a668> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90178da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea034d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181823c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea034d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea034d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc160> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea23d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea23d2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90166128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c70b8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76a15c0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea23d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606e00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6668> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea23d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77362b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77362b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6661d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6661d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6661d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6661d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6661d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7220b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9f28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768acc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76906a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7690550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 0.3816793893129926 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.3816793893129926 9
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.3816793893129926 10
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.3816793893129926 11
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 0.3816793893129926 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.3816793893129926 12
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.3816793893129926 13
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.3816793893129926 14
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1cc0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9048> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.7633587786259852 15
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 0.7633587786259852 8
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 0.7633587786259852 16
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de76c50b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9048> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 1.1450381679389778 9
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 1.1450381679389778 17
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 1.1450381679389778 10
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 1.1450381679389778 18
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 1.1450381679389778 11
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 1.1450381679389778 19
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 1.1450381679389778 12
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 1.1450381679389778 20
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a748> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9048> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 1.5267175572519704 13
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 1.5267175572519704 21
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de76f59e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9048> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 1.908396946564963 14
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 1.908396946564963 22
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 1.908396946564963 15
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 1.908396946564963 23
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 1.908396946564963 16
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 1.908396946564963 24
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5a58> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 2.2900763358779557 17
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 2.2900763358779557 25
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 2.2900763358779557 18
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 2.2900763358779557 26
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4abe0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 2.6717557251909483 19
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 2.6717557251909483 27
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 2.6717557251909483 20
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 2.6717557251909483 28
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 2.6717557251909483 21
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 2.6717557251909483 29
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 2.6717557251909483 22
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 2.6717557251909483 30
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 3.053435114503941 23
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 3.053435114503941 31
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a668> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4ab00> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 3.4351145038169335 24
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 3.4351145038169335 32
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426908> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a748> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9048> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 3.816793893129926 25
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 3.816793893129926 33
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de6426748> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4ab00> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 4.198473282442919 26
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 4.198473282442919 34
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de76c55c0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 4.198473282442919 12
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 4.580152671755911 27
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 4.580152671755911 35
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #2
root->6->26
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707320> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 4.580152671755911 13
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 4.961832061068904 28
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 4.961832061068904 36
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa898> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 4.961832061068904 14
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 5.343511450381897 29
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 5.343511450381897 37
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3278> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 5.343511450381897 15
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 5.725190839694889 30
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 5.725190839694889 38
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de646e358> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646ec18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa898> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 5.725190839694889 16
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 6.106870229007882 31
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 6.106870229007882 39
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4acc0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4ab00> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 6.106870229007882 17
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 6.488549618320874 32
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 6.488549618320874 40
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
coverage_call_count 4800
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7550> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426eb8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e358> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646ec18> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa898> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 4.198473282442919 12
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 6.488549618320874 18
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 6.870229007633867 33
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 6.870229007633867 41
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3f98> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3278> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 4.580152671755911 13
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 6.870229007633867 19
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 7.25190839694686 34
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 7.25190839694686 42
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #3
root->6->26->0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707470> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 4.961832061068904 14
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 7.25190839694686 20
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 7.633587786259852 35
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 7.633587786259852 43
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de650cd68> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426748> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4ab00> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 5.343511450381897 15
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 7.633587786259852 21
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 8.015267175572845 36
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 8.015267175572845 44
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 5.725190839694889 16
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 8.015267175572845 22
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 8.396946564885837 37
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 8.396946564885837 45
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de64310f0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 6.106870229007882 17
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 8.396946564885837 23
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 8.77862595419883 38
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 8.77862595419883 46
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64310f0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 6.106870229007882 18
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 8.396946564885837 24
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 8.77862595419883 39
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 8.77862595419883 47
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf978> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 3.4351145038169335 11
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 6.488549618320874 19
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 8.77862595419883 25
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 9.160305343511823 40
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 9.160305343511823 48
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de6478518> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 3.816793893129926 12
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 6.870229007633867 20
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 9.160305343511823 26
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 9.541984732824815 41
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 9.541984732824815 49
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de651f2b0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 4.198473282442919 13
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 7.25190839694686 21
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 9.541984732824815 27
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 9.923664122137808 42
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 9.923664122137808 50
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5f707b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a860> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478518> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 4.580152671755911 14
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 7.633587786259852 22
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 9.923664122137808 28
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 10.3053435114508 43
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 10.3053435114508 51
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de650c978> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c198> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf978> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 4.961832061068904 15
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 8.015267175572845 23
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 10.3053435114508 29
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 10.687022900763793 44
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 10.687022900763793 52
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #4
root->6->26->0->3
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc38d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707470> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 3.4351145038169335 11
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 5.343511450381897 16
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 8.396946564885837 24
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 10.687022900763793 30
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 11.068702290076786 45
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 11.068702290076786 53
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8e900985c0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 3.816793893129926 12
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 5.725190839694889 17
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 8.77862595419883 25
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 11.068702290076786 31
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 11.450381679389778 46
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 11.450381679389778 54
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de6478198> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 4.198473282442919 13
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 6.106870229007882 18
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 9.160305343511823 26
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 11.450381679389778 32
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 11.832061068702771 47
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 11.832061068702771 55
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3240> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478ef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf978> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 4.580152671755911 14
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 6.488549618320874 19
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 9.541984732824815 27
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 11.832061068702771 33
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 12.213740458015764 48
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 12.213740458015764 56
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3240> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6478ef0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf978> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 4.580152671755911 15
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 6.488549618320874 20
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 9.541984732824815 28
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 11.832061068702771 34
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 12.213740458015764 49
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 12.213740458015764 57
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de658d940> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 4.961832061068904 16
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 6.870229007633867 21
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 9.923664122137808 29
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 12.213740458015764 35
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 12.595419847328756 50
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 12.595419847328756 58
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de658d908> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 5.343511450381897 17
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 7.25190839694686 22
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 10.3053435114508 30
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 12.595419847328756 36
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 12.977099236641749 51
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 12.977099236641749 59
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce9b0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a860> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6478518> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 5.725190839694889 18
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 7.633587786259852 23
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 10.687022900763793 31
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 12.977099236641749 37
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 13.358778625954741 52
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 13.358778625954741 60
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 6.106870229007882 19
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 8.015267175572845 24
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 11.068702290076786 32
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 13.358778625954741 38
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 13.740458015267734 53
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 13.740458015267734 61
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf4e0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098400> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 6.488549618320874 20
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 8.396946564885837 25
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 11.450381679389778 33
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 13.740458015267734 39
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 14.122137404580727 54
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 14.122137404580727 62
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #5
root->6->26->0->3->0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 6.870229007633867 21
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 8.77862595419883 26
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 11.832061068702771 34
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 14.122137404580727 40
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 14.50381679389372 55
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 14.50381679389372 63
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5898> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 7.25190839694686 22
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 9.160305343511823 27
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 12.213740458015764 35
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 14.50381679389372 41
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 14.885496183206712 56
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 14.885496183206712 64
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de6478630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 7.633587786259852 23
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 9.541984732824815 28
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 12.595419847328756 36
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 14.885496183206712 42
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 15.267175572519704 57
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 15.267175572519704 65
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7b38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098400> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 8.015267175572845 24
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 9.923664122137808 29
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 12.977099236641749 37
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 15.267175572519704 43
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 15.648854961832697 58
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 15.648854961832697 66
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #6
root->6->26->0->3->0->3
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5b70> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5a90> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900985c0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 8.396946564885837 25
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 10.3053435114508 30
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 13.358778625954741 38
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 15.648854961832697 44
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 16.03053435114569 59
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 16.03053435114569 67
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5da0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5a90> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900985c0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 8.77862595419883 26
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 10.687022900763793 31
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 13.740458015267734 39
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 16.03053435114569 45
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 16.412213740458682 60
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 16.412213740458682 68
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8e900980f0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 9.160305343511823 27
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 11.068702290076786 32
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 14.122137404580727 40
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 16.412213740458682 46
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 16.793893129771675 61
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 16.793893129771675 69
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64faa20> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5898> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 4.198473282442919 12
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 9.541984732824815 28
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 11.450381679389778 33
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 14.50381679389372 41
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 16.793893129771675 47
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 17.175572519084668 62
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 17.175572519084668 70
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf4a8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64faa20> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5898> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 4.580152671755911 13
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 9.923664122137808 29
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 11.832061068702771 34
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 14.885496183206712 42
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 17.175572519084668 48
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 17.55725190839766 63
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 17.55725190839766 71
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
coverage_call_count 4900
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de6555160> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 4.961832061068904 14
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 10.3053435114508 30
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 12.213740458015764 35
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 15.267175572519704 43
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 17.55725190839766 49
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 17.938931297710653 64
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 17.938931297710653 72
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #7
root->6->26->0->3->0->3->3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5080> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64faa20> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5898> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 4.198473282442919 12
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 5.343511450381897 15
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 10.687022900763793 31
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 12.595419847328756 36
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 15.648854961832697 44
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 17.938931297710653 50
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 18.320610687023645 65
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 18.320610687023645 73
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5f60> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d240> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa630> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64faa20> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5898> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 4.580152671755911 13
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 5.725190839694889 16
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 11.068702290076786 32
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 12.977099236641749 37
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 16.03053435114569 45
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 18.320610687023645 51
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 18.702290076336638 66
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 18.702290076336638 74
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de64cba58> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64faa20> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5898> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 4.961832061068904 14
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 6.106870229007882 17
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 11.450381679389778 33
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 13.358778625954741 38
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 16.412213740458682 46
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 18.702290076336638 52
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 19.08396946564963 67
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 19.08396946564963 75
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de6491208> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491438> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5898> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 5.343511450381897 15
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 6.488549618320874 18
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 11.832061068702771 34
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 13.740458015267734 39
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 16.793893129771675 47
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 19.08396946564963 53
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 19.465648854962623 68
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 19.465648854962623 76
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5f706d8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491438> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5898> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 5.725190839694889 16
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 6.870229007633867 19
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 12.213740458015764 35
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 14.122137404580727 40
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 17.175572519084668 48
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 19.465648854962623 54
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 19.847328244275616 69
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 19.847328244275616 77
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de6478d68> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491438> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5898> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 6.106870229007882 17
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 7.25190839694686 20
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 12.595419847328756 36
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 14.50381679389372 41
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 17.55725190839766 49
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 19.847328244275616 55
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 20.22900763358861 70
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 20.22900763358861 78
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb77f0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491438> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5898> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfba8> 6.488549618320874 18
backprop <src.mcts.MCTS_Node object at 0x7f8de6431a90> 7.633587786259852 21
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5978> 12.977099236641749 37
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70860> 14.885496183206712 42
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0b8> 17.938931297710653 50
backprop <src.mcts.MCTS_Node object at 0x7f8de76908d0> 20.22900763358861 56
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 20.6106870229016 71
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cf98> 20.6106870229016 79
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #8
root->6->26->0->3->0->3->3->5
Best Reward: 0.3816793893129926
iteration: 152
found coverage increase 0.3816793893129926
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64574a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64910b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64910b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de658df28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 13
Completed Iteration #18
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e54e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51c70b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f62b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64faac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64faac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64faac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 5100
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef4e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de514f358> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64572b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de518a2e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514fd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f8d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 5200
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5120160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51322b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51327b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51322e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51326a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51205c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de510add8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607712e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515ff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51200b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51200b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50896d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 5300
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50896d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50896d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50891d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50895f8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60784780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c38d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3828> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a17b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50559e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50557f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50557f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50555f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de506c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de506cc88> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60784780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50054a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd98d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 5500
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bceac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50498d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50498d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50498d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a14e0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b932b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1080> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b934e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 5600
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b519b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b512e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b070b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b070b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b070b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b073c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b512b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b512b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b295f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b295f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b132e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 5700
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65cec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65cec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64cbd30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6478d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5588> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65cec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90002160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b134a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65cec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 5800
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6a20> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6478390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a55c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607aaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf278> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a707390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64787b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de651ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6478390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658d6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6431048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6555d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fabe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b136d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fabe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea02494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90155780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90155b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900025c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea0249470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de646e5f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de650c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60771940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6457c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6555160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de646e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64572b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de658d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76906d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76906d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64572b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6426160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76906d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64572b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de64572b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 18
Completed Iteration #23
Best Reward: 0
coverage_call_count 6000
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90098898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea23d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76904a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e900982e8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de77369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a66a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a666208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c64b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea23d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a66a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771ec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e901667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de771e9e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7736f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90166588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de77118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b13390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6431320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a722c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7711940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a78cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de771e6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e901661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 18
Completed Iteration #19
Best Reward: 0
coverage_call_count 6100
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de651f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a714ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64a54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e901661d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6cf8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8ea034dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a74dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e907af7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9004abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90059438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a792b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64fabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9004ac50> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90098898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de77118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64260f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de77115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de658db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64260f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066ab70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a73d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64260f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6066aac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fdf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6fc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de768a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de768a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 17
Completed Iteration #17
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de650cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9001f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6457c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de77115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606aca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de77118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900ff668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f4aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7736f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606856d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de646eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e607d19b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900ffef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e90166780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900e0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7711dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6066af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90101630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c697400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 6300
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0335080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60744d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8ea0335080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606eecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6886d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de77362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76e9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a688160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c67c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18182da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181828d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181828d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7208> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064eb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6071a438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6071aeb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c286d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c652ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c286d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e18193518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60685588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51e5c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181939e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6534390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c148d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181939e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60749748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181939e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de768add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8e18193c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6540898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9007b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e94e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6975f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76e94e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606419e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6534d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e900eb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6064e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e6066a160> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e60641f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e4c687dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f094e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f090f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6078a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f094e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de65689e8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fe80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6072d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e90071438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5005240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de515f0b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de65680f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b077b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e6064eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60700438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606419e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e606419e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6568ef0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b512b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b512b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b510b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd95f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e9003b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c6975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e6071af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b515c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de7690ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de771efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c28f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8e181c5b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50054e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50054e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b519e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64915f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50054e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4b076d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506cf60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de6491588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de76c5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de64917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6491c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6491898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de506c278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de50f80f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 6700
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f83c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de515f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de64914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de65f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f83c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6568da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8898> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5120208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e60641208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f83c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf16a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6540e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf16a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa07f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a7f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de6426ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5f09908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 68.70229007633588
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51323c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51323c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c39e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbeeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de518a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de518ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5120630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de514f128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e4c661a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fefda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f70ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de506cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5005588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 20
Completed Iteration #21
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5049550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e607c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5132048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de514fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b930b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b939e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4b930b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b930b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b936d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b930b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5035fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f2c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba02b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e606ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bcec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bd9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5089b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5055978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de515f3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7048> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b296a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5132e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40edc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40faac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de510a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51322e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40947b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51322e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de51322e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40a45c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de6c14048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5089518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40eda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5049d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40fada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed2b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4057278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b07470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4057748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 7100
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de50552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4094be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4057f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40570b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4057668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40570b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de406a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4057080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de406a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de406a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de406a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4057400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de406ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de406aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4079470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de406af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4079080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4057240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4079a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4079c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4079080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de406aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4057400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4057978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4057ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4079080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de406a320> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4057828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e1a6b3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de514f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de51bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40edba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40fa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40a4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5055f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b51ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de406acc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4079198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4079438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4079dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4079438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bbe390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4079ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4079438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4029198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40790b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40944e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40944e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40790b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4029198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40941d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40790b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de40799e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4029470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4079208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4036780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4079208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4036be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4036e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4036d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4036748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40365c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40365c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40365c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4079208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 14
Completed Iteration #12
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4036ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4079208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4036c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8de4036550> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fc3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4057940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4036d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4036668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4057940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e27b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4036da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40360b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b93320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40360b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4079668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4057da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50c3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5f1fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40365c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40579b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40295f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40944e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40eda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40944e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4094c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de50f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5ccf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de406aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40296a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cca90> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5b6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 8
Completed Iteration #9
Best Reward: 0
coverage_call_count 7300
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8e181b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4b29a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a49b0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4bf1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fa0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4ba0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5fb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40a46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de5049908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de40797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40579b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5cc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40944e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4036e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4029668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5e2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5a4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de4036b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8de4029e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8dcf596fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5b6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8de40edf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8dcf5969b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 68.70229007633588
initial coverage: 66.7939
time passed (minutes): 60.0267
iterations: 247
number of new inputs: 320
final coverage: 68.7023
total coverage increase: 1.9084
