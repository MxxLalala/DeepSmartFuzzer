Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f11c5207f28>, tc2=<function tc2 at 0x7f11c5216048>, tc3=<function tc3 at 0x7f11c5216158>, tfc_threshold=33000000, time_period=3600, verbose=True)
initial coverage: 5.20833
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10eba55208> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 11
Completed Iteration #17
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 12
Completed Iteration #18
Best Reward: 1.041666666666666
Completed Iteration #19
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55208> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 1.041666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 13
Completed Iteration #20
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 14
Completed Iteration #21
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 15
Completed Iteration #22
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 16
Completed Iteration #23
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba55208> 1.041666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 1.041666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 17
Completed Iteration #24
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 18
Completed Iteration #25
Best Reward: 1.041666666666666
Completed MCTS Level/Depth: #0
root
Best Reward: 1.041666666666666
Completed Iteration #0
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 1.041666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 19
Completed Iteration #1
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55208> 1.041666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 1.041666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 20
Completed Iteration #2
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c04b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 1.041666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 21
Completed Iteration #3
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 1.041666666666666 9
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 22
Completed Iteration #4
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 1.041666666666666 10
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 23
Completed Iteration #5
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 1.041666666666666 11
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 1.041666666666666 24
Completed Iteration #6
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 2.083333333333332 12
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 2.083333333333332 25
Completed Iteration #7
Best Reward: 1.041666666666666
Completed Iteration #8
Best Reward: 1.041666666666666
Completed Iteration #9
Best Reward: 1.041666666666666
Completed Iteration #10
Best Reward: 1.041666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10eba30588> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e9e8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 4.166666666666665 13
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 4.166666666666665 26
Completed Iteration #11
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c04b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30588> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e9e8> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 3.124999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 4.166666666666665 14
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 4.166666666666665 27
Completed Iteration #12
Best Reward: 2.083333333333333
Completed Iteration #13
Best Reward: 2.083333333333333
Completed Iteration #14
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10eba62d68> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 4.166666666666665 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 5.208333333333331 15
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 5.208333333333331 28
Completed Iteration #15
Best Reward: 2.083333333333333
Completed Iteration #16
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 5.208333333333331 16
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 5.208333333333331 29
Completed Iteration #17
Best Reward: 2.083333333333333
Completed Iteration #18
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 5.208333333333331 6
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 6.249999999999997 17
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 6.249999999999997 30
Completed Iteration #19
Best Reward: 2.083333333333333
Completed Iteration #20
Best Reward: 2.083333333333333
Completed Iteration #21
Best Reward: 2.083333333333333
Completed Iteration #22
Best Reward: 2.083333333333333
Completed Iteration #23
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 6.249999999999997 18
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 6.249999999999997 31
Completed Iteration #24
Best Reward: 2.083333333333333
Completed Iteration #25
Best Reward: 2.083333333333333
Completed MCTS Level/Depth: #1
root->6
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e82022b0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 6.249999999999997 7
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 7.291666666666663 19
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 7.291666666666663 32
Completed Iteration #0
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82026a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30588> 2.083333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e9e8> 2.083333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 6.249999999999997 8
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 7.291666666666663 20
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 7.291666666666663 33
Completed Iteration #1
Best Reward: 2.083333333333333
Completed Iteration #2
Best Reward: 2.083333333333333
Completed Iteration #3
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e8202a58> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202ac8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 7.291666666666663 9
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 8.333333333333329 21
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 8.333333333333329 34
Completed Iteration #4
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c04b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30588> 2.083333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e9e8> 2.083333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 7.291666666666663 10
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 8.333333333333329 22
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 8.333333333333329 35
Completed Iteration #5
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62d68> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 4.166666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 7.291666666666663 11
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 8.333333333333329 23
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 8.333333333333329 36
Completed Iteration #6
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e820d668> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d518> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202a58> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202ac8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 5.20833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 8.333333333333329 12
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 9.374999999999995 24
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 9.374999999999995 37
Completed Iteration #7
Best Reward: 2.083333333333333
Completed Iteration #8
Best Reward: 2.083333333333333
Completed Iteration #9
Best Reward: 2.083333333333333
Completed Iteration #10
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f111c04b748> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e9e8> 3.124999999999999 6
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 9.374999999999995 13
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 10.41666666666666 25
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 10.41666666666666 38
Completed Iteration #11
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10eba62f28> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62978> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f111c04b748> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e9e8> 4.166666666666665 7
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 10.41666666666666 14
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 11.458333333333327 26
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 11.458333333333327 39
Completed Iteration #12
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5518> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62e10> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62f28> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62978> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f111c04b748> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e9e8> 5.208333333333331 8
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 11.458333333333327 15
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 12.499999999999993 27
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 12.499999999999993 40
Completed Iteration #13
Best Reward: 2.083333333333333
Completed Iteration #14
Best Reward: 2.083333333333333
Completed Iteration #15
Best Reward: 2.083333333333333
Completed Iteration #16
Best Reward: 2.083333333333333
Completed Iteration #17
Best Reward: 2.083333333333333
Completed Iteration #18
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10eba55a90> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62da0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62d68> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 6.2499999999999964 8
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 12.499999999999993 16
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 13.541666666666659 28
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 13.541666666666659 41
Completed Iteration #19
Best Reward: 2.083333333333333
Completed Iteration #20
Best Reward: 2.083333333333333
Completed Iteration #21
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 6.2499999999999964 9
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 12.499999999999993 17
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 13.541666666666659 29
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 13.541666666666659 42
Completed Iteration #22
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 6.2499999999999964 10
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 12.499999999999993 18
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 13.541666666666659 30
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 13.541666666666659 43
Completed Iteration #23
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e820d828> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202ac8> 4.166666666666665 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 5.208333333333331 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 8.333333333333329 11
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 14.583333333333325 19
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 15.624999999999993 31
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 15.624999999999993 44
Completed Iteration #24
Best Reward: 2.083333333333333
Completed Iteration #25
Best Reward: 2.083333333333333
Completed MCTS Level/Depth: #2
root->6->18
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10eba62198> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dac8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d828> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202ac8> 6.249999999999998 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 7.291666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 10.41666666666666 12
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 16.666666666666657 20
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 17.708333333333325 32
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 17.708333333333325 45
Completed Iteration #0
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 8.33333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 11.458333333333327 13
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 17.70833333333332 21
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 18.749999999999993 33
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 18.749999999999993 46
Completed Iteration #1
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6198> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820deb8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82022b0> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 13.54166666666666 14
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 19.791666666666654 22
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 20.833333333333325 34
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 20.833333333333325 47
Completed Iteration #2
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 10.416666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 15.624999999999993 15
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 21.874999999999986 23
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 22.916666666666657 35
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 22.916666666666657 48
Completed Iteration #3
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6198> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820deb8> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10e82022b0> 3.124999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 15.624999999999993 16
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 21.874999999999986 24
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 22.916666666666657 36
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 22.916666666666657 49
Completed Iteration #4
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f111c04b6a0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820deb8> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f10e82022b0> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 17.708333333333325 17
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 23.958333333333318 25
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 24.99999999999999 37
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 24.99999999999999 50
Completed Iteration #5
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c04b6a0> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820deb8> 4.166666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f10e82022b0> 5.208333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 17.708333333333325 18
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 23.958333333333318 26
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 24.99999999999999 38
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 24.99999999999999 51
Completed Iteration #6
Best Reward: 2.083333333333333
Completed Iteration #7
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 17.708333333333325 19
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 23.958333333333318 27
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 24.99999999999999 39
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 24.99999999999999 52
Completed Iteration #8
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 10.416666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 17.708333333333325 20
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 23.958333333333318 28
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 24.99999999999999 40
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 24.99999999999999 53
Completed Iteration #9
Best Reward: 2.083333333333333
Completed Iteration #10
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e820d048> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820deb8> 6.249999999999999 6
backprop <src.mcts.MCTS_Node object at 0x7f10e82022b0> 7.291666666666665 7
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 19.791666666666657 21
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 26.04166666666665 29
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 27.08333333333332 41
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 27.08333333333332 54
Completed Iteration #11
Best Reward: 2.083333333333333
Completed Iteration #12
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e820ddd8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 21.87499999999999 22
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 28.124999999999982 30
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 29.166666666666654 42
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 29.166666666666654 55
Completed Iteration #13
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81a62b0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a69b0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820ddd8> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 22.916666666666657 23
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 29.16666666666665 31
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 30.20833333333332 43
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 30.20833333333332 56
Completed Iteration #14
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6668> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 12.499999999999996 10
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 24.99999999999999 24
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 31.249999999999982 32
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 32.29166666666666 44
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 32.29166666666666 57
Completed Iteration #15
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6208> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6f60> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f111c04b6a0> 3.124999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820deb8> 7.291666666666665 7
backprop <src.mcts.MCTS_Node object at 0x7f10e82022b0> 8.333333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 26.041666666666657 25
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 32.29166666666665 33
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 33.33333333333332 45
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 33.33333333333332 58
Completed Iteration #16
Best Reward: 2.083333333333333
Completed Iteration #17
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62da0> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62d68> 2.083333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 26.041666666666657 26
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 32.29166666666665 34
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 33.33333333333332 46
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 33.33333333333332 59
Completed Iteration #18
Best Reward: 2.083333333333333
Completed Iteration #19
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81b59b0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 6.249999999999998 5
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 6.249999999999998 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 13.541666666666663 11
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 27.08333333333332 27
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 33.333333333333314 35
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 34.374999999999986 47
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 34.374999999999986 60
Completed Iteration #20
Best Reward: 2.083333333333333
Completed Iteration #21
Best Reward: 2.083333333333333
coverage_call_count 100
Completed Iteration #22
Best Reward: 2.083333333333333
Completed Iteration #23
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c50> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd588> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6208> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6f60> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f111c04b6a0> 4.166666666666665 5
backprop <src.mcts.MCTS_Node object at 0x7f10e820deb8> 8.333333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f10e82022b0> 9.374999999999998 9
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 28.124999999999986 28
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 34.37499999999998 36
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 35.41666666666665 48
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 35.41666666666665 61
Completed Iteration #24
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e8202c18> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c18> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6198> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820deb8> 10.416666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10e82022b0> 11.458333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 30.208333333333318 29
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 36.458333333333314 37
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 37.499999999999986 49
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 37.499999999999986 62
Completed Iteration #25
Best Reward: 2.083333333333333
Completed MCTS Level/Depth: #3
root->6->18->2
Best Reward: 2.083333333333333
Completed Iteration #0
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6cf8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 8.333333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 15.624999999999996 12
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 32.29166666666665 30
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 38.54166666666665 38
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 39.58333333333332 50
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 39.58333333333332 63
Completed Iteration #1
Best Reward: 2.083333333333333
Completed Iteration #2
Best Reward: 2.083333333333333
Completed Iteration #3
Best Reward: 2.083333333333333
Completed Iteration #4
Best Reward: 2.083333333333333
Completed Iteration #5
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e820def0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 9.374999999999998 7
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 16.666666666666664 13
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 33.333333333333314 31
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 39.583333333333314 39
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 40.624999999999986 51
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 40.624999999999986 64
Completed Iteration #6
Best Reward: 2.083333333333333
Completed Iteration #7
Best Reward: 2.083333333333333
Completed Iteration #8
Best Reward: 2.083333333333333
Completed Iteration #9
Best Reward: 2.083333333333333
Completed Iteration #10
Best Reward: 2.083333333333333
Completed Iteration #11
Best Reward: 2.083333333333333
Completed Iteration #12
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81bda90> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62198> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820dac8> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d828> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8202ac8> 7.291666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 17.70833333333333 14
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 34.37499999999998 32
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 40.62499999999998 40
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 41.66666666666665 52
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 41.66666666666665 65
Completed Iteration #13
Best Reward: 2.083333333333333
Completed Iteration #14
Best Reward: 2.083333333333333
Completed Iteration #15
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5828> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf60> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b59b0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 6.249999999999998 5
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 7.291666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 10.416666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 18.749999999999993 15
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 35.41666666666664 33
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 41.66666666666664 41
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 42.708333333333314 53
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 42.708333333333314 66
Completed Iteration #16
Best Reward: 2.083333333333333
Completed Iteration #17
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd668> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd400> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820def0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 11.45833333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 19.791666666666657 16
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 36.45833333333331 34
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 42.70833333333331 42
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 43.74999999999998 54
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 43.74999999999998 67
Completed Iteration #18
Best Reward: 2.083333333333333
Completed Iteration #19
Best Reward: 2.083333333333333
Completed Iteration #20
Best Reward: 2.083333333333333
Completed Iteration #21
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddf60> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202ac8> 8.33333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 20.83333333333332 17
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 37.49999999999997 35
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 43.74999999999997 43
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 44.79166666666664 55
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 44.79166666666664 68
Completed Iteration #22
Best Reward: 2.083333333333333
Completed Iteration #23
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddd30> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6cf8> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 12.499999999999996 10
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 21.874999999999986 18
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 38.541666666666636 36
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 44.791666666666636 44
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 45.83333333333331 56
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 45.83333333333331 69
Completed Iteration #24
Best Reward: 2.083333333333333
Completed Iteration #25
Best Reward: 2.083333333333333
Completed MCTS Level/Depth: #4
root->6->18->2->0
Best Reward: 2.083333333333333
Completed Iteration #0
Best Reward: 2.083333333333333
Completed Iteration #1
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6668> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 6.249999999999998 6
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 7.291666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 12.499999999999996 11
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 21.874999999999986 19
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 38.541666666666636 37
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 44.791666666666636 45
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 45.83333333333331 57
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 45.83333333333331 70
Completed Iteration #2
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10eba62e80> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 7.291666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 8.33333333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 13.541666666666663 12
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 22.91666666666665 20
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 39.5833333333333 38
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 45.8333333333333 46
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 46.87499999999997 58
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 46.87499999999997 71
Completed Iteration #3
Best Reward: 2.083333333333333
Completed Iteration #4
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6dd8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 14.583333333333329 13
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 23.958333333333314 21
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 40.624999999999964 39
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 46.874999999999964 47
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 47.916666666666636 59
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 47.916666666666636 72
Completed Iteration #5
Best Reward: 2.083333333333333
Completed Iteration #6
Best Reward: 2.083333333333333
Completed Iteration #7
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd550> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6668> 3.124999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 8.33333333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 9.374999999999996 9
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 15.624999999999995 14
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 24.99999999999998 22
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 41.66666666666663 40
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 47.91666666666663 48
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 48.9583333333333 60
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 48.9583333333333 73
Completed Iteration #8
Best Reward: 2.083333333333333
Completed Iteration #9
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdc50> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 9.374999999999996 9
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 10.416666666666663 10
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 16.66666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 26.041666666666643 23
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 42.70833333333329 41
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 48.95833333333329 49
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 49.999999999999964 61
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 49.999999999999964 74
Completed Iteration #10
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdef0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddd30> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6cf8> 4.166666666666665 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 17.70833333333333 16
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 27.083333333333307 24
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 43.74999999999996 42
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 49.99999999999996 50
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 51.04166666666663 62
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 51.04166666666663 75
Completed Iteration #11
Best Reward: 2.083333333333333
Completed Iteration #12
Best Reward: 2.083333333333333
Completed Iteration #13
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6dd8> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 17.70833333333333 17
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 27.083333333333307 25
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 43.74999999999996 43
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 49.99999999999996 51
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 51.04166666666663 63
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 51.04166666666663 76
Completed Iteration #14
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e8182080> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81652e8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6dd8> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 18.749999999999993 18
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 28.12499999999997 26
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 44.79166666666662 44
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 51.04166666666662 52
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 52.08333333333329 64
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 52.08333333333329 77
Completed Iteration #15
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81824a8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 19.791666666666657 19
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 29.166666666666636 27
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 45.833333333333286 45
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 52.083333333333286 53
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 53.12499999999996 65
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 53.12499999999996 78
Completed Iteration #16
Best Reward: 2.083333333333333
Completed Iteration #17
Best Reward: 2.083333333333333
Completed Iteration #18
Best Reward: 2.083333333333333
Completed Iteration #19
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e8182ef0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182c18> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81824a8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 20.83333333333332 20
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 30.2083333333333 28
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 46.87499999999995 46
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 53.12499999999995 54
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 54.16666666666662 66
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 54.16666666666662 79
Completed Iteration #20
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81652e8> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6dd8> 2.083333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 20.83333333333332 21
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 30.2083333333333 29
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 46.87499999999995 47
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 53.12499999999995 55
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 54.16666666666662 67
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 54.16666666666662 80
Completed Iteration #21
Best Reward: 2.083333333333333
Completed Iteration #22
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e820dbe0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182c18> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81824a8> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 21.874999999999986 22
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 31.249999999999964 30
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 47.916666666666615 48
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 54.166666666666615 56
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 55.208333333333286 68
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 55.208333333333286 81
Completed Iteration #23
Best Reward: 2.083333333333333
Completed Iteration #24
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81824a8> 3.1249999999999982 5
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 21.874999999999986 23
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 31.249999999999964 31
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 47.916666666666615 49
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 54.166666666666615 57
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 55.208333333333286 69
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 55.208333333333286 82
Completed Iteration #25
Best Reward: 2.083333333333333
Completed MCTS Level/Depth: #5
root->6->18->2->0->0
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e8182518> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81822e8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6668> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 7.291666666666665 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 11.458333333333329 10
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 12.499999999999996 11
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 23.958333333333318 24
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 33.3333333333333 32
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 49.99999999999995 50
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 56.24999999999995 58
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 57.29166666666662 70
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 57.29166666666662 83
Completed Iteration #0
Best Reward: 2.083333333333333
Completed Iteration #1
Best Reward: 2.083333333333333
Completed Iteration #2
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e8165d68> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165588> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 13.541666666666663 12
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 24.999999999999986 25
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 34.374999999999964 33
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 51.041666666666615 51
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 57.291666666666615 59
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 58.333333333333286 71
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 58.333333333333286 84
Completed Iteration #3
Best Reward: 2.083333333333333
Completed Iteration #4
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf60> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b59b0> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 11.458333333333329 11
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 13.541666666666663 13
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 24.999999999999986 26
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 34.374999999999964 34
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 51.041666666666615 52
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 57.291666666666615 60
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 58.333333333333286 72
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 58.333333333333286 85
Completed Iteration #5
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e818d048> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d208> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdc50> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 12.499999999999995 12
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 14.583333333333329 14
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 26.04166666666665 27
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 35.41666666666663 35
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 52.08333333333328 53
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 58.33333333333328 61
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 59.37499999999995 73
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 59.37499999999995 86
Completed Iteration #6
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e818d7b8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 13.54166666666666 13
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 15.624999999999995 15
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 27.083333333333314 28
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 36.45833333333329 36
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 53.12499999999994 54
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 59.37499999999994 62
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 60.416666666666615 74
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 60.416666666666615 87
Completed Iteration #7
Best Reward: 2.083333333333333
Completed Iteration #8
Best Reward: 2.083333333333333
Completed Iteration #9
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81240f0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165588> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 16.66666666666666 16
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 28.12499999999998 29
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 37.49999999999996 37
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 54.16666666666661 55
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 60.41666666666661 63
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 61.45833333333328 75
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 61.45833333333328 88
Completed Iteration #10
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 14.583333333333327 14
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 17.70833333333333 17
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 29.166666666666643 30
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 38.54166666666662 38
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 55.20833333333327 56
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 61.45833333333327 64
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 62.49999999999994 76
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 62.49999999999994 89
Completed Iteration #11
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 17.70833333333333 18
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 29.166666666666643 31
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 38.54166666666662 39
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 55.20833333333327 57
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 61.45833333333327 65
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 62.49999999999994 77
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 62.49999999999994 90
Completed Iteration #12
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e8182908> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81826a0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81240f0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165588> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 18.749999999999993 19
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 30.208333333333307 32
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 39.583333333333286 40
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 56.249999999999936 58
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 62.499999999999936 66
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 63.54166666666661 78
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 63.54166666666661 91
Completed Iteration #13
Best Reward: 2.083333333333333
Completed Iteration #14
Best Reward: 2.083333333333333
Completed Iteration #15
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b59b0> 2.083333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 14.583333333333327 15
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 18.749999999999993 20
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 30.208333333333307 33
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 39.583333333333286 41
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 56.249999999999936 59
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 62.499999999999936 67
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 63.54166666666661 79
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 63.54166666666661 92
Completed Iteration #16
Best Reward: 2.083333333333333
Completed Iteration #17
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e818dba8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d358> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182518> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81822e8> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 6.249999999999999 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6668> 7.291666666666665 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 9.374999999999998 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 16.66666666666666 16
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 20.833333333333325 21
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 32.29166666666664 34
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 41.66666666666662 42
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 58.33333333333327 60
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 64.58333333333327 68
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 65.62499999999994 80
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 65.62499999999994 93
Completed Iteration #18
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd630> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdd30> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d048> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e818d208> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdc50> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 17.70833333333333 17
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 21.874999999999993 22
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 33.33333333333331 35
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 42.708333333333286 43
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 59.374999999999936 61
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 65.62499999999994 69
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 66.66666666666661 81
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 66.66666666666661 94
Completed Iteration #19
Best Reward: 2.083333333333333
Completed Iteration #20
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5588> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818da90> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165d68> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165588> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 22.916666666666657 23
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 34.37499999999997 36
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 43.74999999999995 44
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 60.4166666666666 62
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 66.66666666666661 70
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 67.70833333333329 82
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 67.70833333333329 95
Completed Iteration #21
Best Reward: 2.083333333333333
Completed Iteration #22
Best Reward: 2.083333333333333
Completed Iteration #23
Best Reward: 2.083333333333333
Completed Iteration #24
Best Reward: 2.083333333333333
Completed Iteration #25
Best Reward: 2.083333333333333
Completed MCTS Level/Depth: #6
root->6->18->2->0->0->0
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e8124a58> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d208> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdc50> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 18.749999999999993 18
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 23.95833333333332 24
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 35.416666666666636 37
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 44.791666666666615 45
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 61.458333333333265 63
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 67.70833333333329 71
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 68.74999999999996 83
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 68.74999999999996 96
Completed Iteration #0
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e8124898> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124f28> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b59b0> 3.1249999999999982 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 19.791666666666657 19
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 24.999999999999986 25
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 36.4583333333333 38
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 45.83333333333328 46
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 62.49999999999993 64
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 68.74999999999996 72
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 69.79166666666663 84
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 69.79166666666663 97
Completed Iteration #1
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6668> 7.291666666666665 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 9.374999999999998 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 19.791666666666657 20
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 24.999999999999986 26
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 36.4583333333333 39
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 45.83333333333328 47
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 62.49999999999993 65
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 68.74999999999996 73
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 69.79166666666663 85
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 69.79166666666663 98
Completed Iteration #2
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd710> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81822e8> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 7.291666666666665 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6668> 8.333333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 10.416666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 20.83333333333332 21
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 26.04166666666665 27
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 37.499999999999964 40
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 46.87499999999994 48
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 63.54166666666659 66
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 69.79166666666663 74
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 70.8333333333333 86
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 70.8333333333333 99
Completed Iteration #3
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e8182588> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182860> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd630> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdd30> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e818d048> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f10e818d208> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdc50> 5.20833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 21.874999999999986 22
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 27.083333333333314 28
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 38.54166666666663 41
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 47.91666666666661 49
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 64.58333333333326 67
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 70.8333333333333 75
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 71.87499999999997 87
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 71.87499999999997 100
Completed Iteration #4
Best Reward: 2.083333333333333
Completed Iteration #5
Best Reward: 2.083333333333333
Completed Iteration #6
Best Reward: 2.083333333333333
Completed Iteration #7
Best Reward: 2.083333333333333
Completed Iteration #8
Best Reward: 2.083333333333333
Completed Iteration #9
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6668> 8.333333333333332 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 10.416666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 21.874999999999986 23
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 27.083333333333314 29
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 38.54166666666663 42
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 47.91666666666661 50
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 64.58333333333326 68
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 70.8333333333333 76
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 71.87499999999997 88
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 71.87499999999997 101
Completed Iteration #10
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e818d860> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820db00> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62e80> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 22.91666666666665 24
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 28.12499999999998 30
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 39.58333333333329 43
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 48.95833333333327 51
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 65.62499999999993 69
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 71.87499999999997 77
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 72.91666666666664 89
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 72.91666666666664 102
Completed Iteration #11
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5828> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf60> 1.041666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b59b0> 3.1249999999999982 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 22.91666666666665 25
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 28.12499999999998 31
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 39.58333333333329 44
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 48.95833333333327 52
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 65.62499999999993 70
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 71.87499999999997 78
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 72.91666666666664 90
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 72.91666666666664 103
Completed Iteration #12
Best Reward: 2.083333333333333
Completed Iteration #13
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e8137a90> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdd30> 4.166666666666665 4
backprop <src.mcts.MCTS_Node object at 0x7f10e818d048> 5.208333333333331 5
backprop <src.mcts.MCTS_Node object at 0x7f10e818d208> 6.249999999999997 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdc50> 7.291666666666663 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 24.999999999999982 26
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 30.20833333333331 32
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 41.66666666666663 45
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 51.04166666666661 53
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 67.70833333333326 71
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 73.9583333333333 79
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 74.99999999999997 91
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 74.99999999999997 104
Completed Iteration #14
Best Reward: 2.083333333333333
Completed Iteration #15
Best Reward: 2.083333333333333
Completed Iteration #16
Best Reward: 2.083333333333333
Completed Iteration #17
Best Reward: 2.083333333333333
Completed Iteration #18
Best Reward: 2.083333333333333
coverage_call_count 200
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81435c0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124cf8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d860> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820db00> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62e80> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 26.04166666666665 27
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 31.24999999999998 33
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 42.70833333333329 46
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 52.08333333333327 54
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 68.74999999999993 72
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 74.99999999999997 80
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 76.04166666666664 92
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 76.04166666666664 105
Completed Iteration #19
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5080> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd0b8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 12.499999999999996 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 28.124999999999982 28
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 33.333333333333314 34
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 44.79166666666663 47
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 54.16666666666661 55
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 70.83333333333326 73
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 77.0833333333333 81
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 78.12499999999997 93
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 78.12499999999997 106
Completed Iteration #20
Best Reward: 2.083333333333333
Completed Iteration #21
Best Reward: 2.083333333333333
Completed Iteration #22
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e8182390> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81820f0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124a58> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e818d208> 7.291666666666663 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdc50> 8.333333333333329 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 29.16666666666665 29
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 34.37499999999998 35
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 45.83333333333329 48
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 55.20833333333327 56
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 71.87499999999993 74
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 78.12499999999997 82
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 79.16666666666664 94
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 79.16666666666664 107
Completed Iteration #23
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e81379e8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820db00> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba62e80> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 30.208333333333314 30
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 35.41666666666664 36
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 46.87499999999996 49
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 56.249999999999936 57
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 72.9166666666666 75
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 79.16666666666664 83
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 80.20833333333331 95
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 80.20833333333331 108
Completed Iteration #24
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e818de80> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137d30> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 31.24999999999998 31
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 36.45833333333331 37
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 47.91666666666662 50
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 57.2916666666666 58
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 73.95833333333327 76
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 80.20833333333331 84
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 81.24999999999999 96
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 81.24999999999999 109
Completed Iteration #25
Best Reward: 2.083333333333333
Completed MCTS Level/Depth: #7
root->6->18->2->0->0->0->3
Best Reward: 2.083333333333333
Completed Iteration #0
Best Reward: 2.083333333333333
Completed Iteration #1
Best Reward: 2.083333333333333
Completed Iteration #2
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81430b8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143550> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5080> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd0b8> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 14.583333333333329 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 33.333333333333314 32
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 38.54166666666664 38
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 49.99999999999996 51
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 59.374999999999936 59
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 76.0416666666666 77
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 82.29166666666664 85
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 83.33333333333331 97
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 83.33333333333331 110
Completed Iteration #3
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e8143c18> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd0b8> 6.249999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 16.66666666666666 13
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 35.41666666666665 33
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 40.62499999999998 39
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 52.08333333333329 52
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 61.45833333333327 60
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 78.12499999999993 78
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 84.37499999999997 86
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 85.41666666666664 98
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 85.41666666666664 111
Completed Iteration #4
Best Reward: 2.083333333333333
Completed Iteration #5
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd550> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6668> 8.333333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 16.66666666666666 14
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 35.41666666666665 34
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 40.62499999999998 40
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 52.08333333333329 53
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 61.45833333333327 61
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 78.12499999999993 79
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 84.37499999999997 87
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 85.41666666666664 99
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 85.41666666666664 112
Completed Iteration #6
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e8159828> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159668> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143c18> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd0b8> 7.291666666666665 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 17.70833333333333 15
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 36.458333333333314 35
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 41.66666666666664 41
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 53.12499999999996 54
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 62.499999999999936 62
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 79.1666666666666 80
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 85.41666666666664 88
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 86.45833333333331 100
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 86.45833333333331 113
Completed Iteration #7
Best Reward: 2.083333333333333
Completed Iteration #8
Best Reward: 2.083333333333333
Completed Iteration #9
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143550> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5080> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd0b8> 7.291666666666665 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 17.70833333333333 16
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 36.458333333333314 36
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 41.66666666666664 42
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 53.12499999999996 55
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 62.499999999999936 63
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 79.1666666666666 81
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 85.41666666666664 89
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 86.45833333333331 101
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 86.45833333333331 114
Completed Iteration #10
Best Reward: 2.083333333333333
Completed Iteration #11
Best Reward: 2.083333333333333
Completed Iteration #12
Best Reward: 2.083333333333333
Completed Iteration #13
Best Reward: 2.083333333333333
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10e8143710> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143748> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81430b8> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8143550> 3.124999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5080> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd0b8> 8.333333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 18.749999999999993 17
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 37.49999999999998 37
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 42.70833333333331 43
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 54.16666666666662 56
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 63.5416666666666 64
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 80.20833333333327 82
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 86.45833333333331 90
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 87.49999999999999 102
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 87.49999999999999 115
Completed Iteration #14
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e8143eb8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143550> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5080> 7.291666666666665 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd0b8> 10.416666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 20.833333333333325 18
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 39.583333333333314 38
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 44.79166666666664 44
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 56.24999999999996 57
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 65.62499999999993 65
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 82.2916666666666 83
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 88.54166666666664 91
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 89.58333333333331 103
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 89.58333333333331 116
Completed Iteration #15
Best Reward: 2.083333333333333
Completed Iteration #16
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143eb8> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8143550> 5.208333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5080> 7.291666666666665 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd0b8> 10.416666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 20.833333333333325 19
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 39.583333333333314 39
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 44.79166666666664 45
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 56.24999999999996 58
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 65.62499999999993 66
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 82.2916666666666 84
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 88.54166666666664 92
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 89.58333333333331 104
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 89.58333333333331 117
Completed Iteration #17
Best Reward: 2.083333333333333
Completed Iteration #18
Best Reward: 2.083333333333333
Completed Iteration #19
Best Reward: 2.083333333333333
Completed Iteration #20
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd0b8> 10.416666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 20.833333333333325 20
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 39.583333333333314 40
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 44.79166666666664 46
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 56.24999999999996 59
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 65.62499999999993 67
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 82.2916666666666 85
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 88.54166666666664 93
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 89.58333333333331 105
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 89.58333333333331 118
Completed Iteration #21
Best Reward: 2.083333333333333
Completed Iteration #22
Best Reward: 2.083333333333333
Completed Iteration #23
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81597f0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd0b8> 12.499999999999996 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 22.916666666666657 21
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 41.66666666666665 41
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 46.87499999999998 47
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 58.33333333333329 60
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 67.70833333333326 68
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 84.37499999999993 86
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 90.62499999999997 94
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 91.66666666666664 106
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 91.66666666666664 119
Completed Iteration #24
Best Reward: 2.083333333333333
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e80f06d8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d358> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8182518> 6.249999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81822e8> 7.291666666666665 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 9.374999999999998 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6668> 10.416666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 24.99999999999999 22
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6438> 43.749999999999986 42
backprop <src.mcts.MCTS_Node object at 0x7f10e820de48> 48.958333333333314 48
backprop <src.mcts.MCTS_Node object at 0x7f10e820dcc0> 60.41666666666663 61
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 69.79166666666659 69
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 86.45833333333326 87
backprop <src.mcts.MCTS_Node object at 0x7f10eba55630> 92.7083333333333 95
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 93.74999999999997 107
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 93.74999999999997 120
Completed Iteration #25
Best Reward: 2.083333333333333
Completed MCTS Level/Depth: #8
root->6->18->2->0->0->0->3->2
Best Reward: 2.083333333333333
iteration: 0
found coverage increase 2.083333333333333
Current Total Coverage 7.291666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81590f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81590f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818ddd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 7.291666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 7.291666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143358> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4beecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 7.291666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff278> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 7.291666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b921d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b921d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b927b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b921d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b921d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4babac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4babb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4baba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4babd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4babeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 7.291666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0f0> 0.0 3
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4beef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0f0> 0.0 4
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0f0> 0.0 5
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0f0> 0.0 6
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bfffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0f0> 0.0 7
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0f0> 0.0 8
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b924e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0f0> 0.0 9
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0f0> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0f0> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0f0> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0f0> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 7.291666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4babf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4beee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 400
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 7.291666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81188d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81188d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b656a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b656a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b656a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b105c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 7.291666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b103c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10358> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 7.291666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b107f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b107f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f02b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 7.291666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4babc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4babcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4babcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4babcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b925c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4babcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4bfff60> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 3.125000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 3.125000000000001 18
Completed Iteration #21
Best Reward: 3.125000000000001
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 3.125000000000001 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 3.125000000000001 19
Completed Iteration #22
Best Reward: 3.125000000000001
Completed Iteration #23
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4b331d0> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1358> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bfff60> 6.250000000000002 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 6.250000000000002 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 6.250000000000002 20
Completed Iteration #24
Best Reward: 3.125000000000001
Completed Iteration #25
Best Reward: 3.125000000000001
Completed MCTS Level/Depth: #0
root
Best Reward: 3.125000000000001
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 6.250000000000002 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 6.250000000000002 21
Completed Iteration #0
Best Reward: 3.125000000000001
Completed Iteration #1
Best Reward: 3.125000000000001
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b331d0> 3.125000000000001 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1358> 3.125000000000001 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bfff60> 6.250000000000002 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 6.250000000000002 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 6.250000000000002 22
Completed Iteration #2
Best Reward: 3.125000000000001
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b331d0> 3.125000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1358> 3.125000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bfff60> 6.250000000000002 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 6.250000000000002 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 6.250000000000002 23
Completed Iteration #3
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33e48> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 9.375000000000004 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 9.375000000000004 24
Completed Iteration #4
Best Reward: 3.125000000000001
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bfff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 9.375000000000004 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 9.375000000000004 25
Completed Iteration #5
Best Reward: 3.125000000000001
Completed Iteration #6
Best Reward: 3.125000000000001
Reward: 1.0416666666666652
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1710> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 10.416666666666668 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 10.416666666666668 26
Completed Iteration #7
Best Reward: 3.125000000000001
Reward: 1.0416666666666652
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae19e8> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae15c0> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1710> 2.0833333333333304 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 11.458333333333332 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 11.458333333333332 27
Completed Iteration #8
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1d30> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1358> 6.250000000000002 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bfff60> 9.375000000000004 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 14.583333333333332 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 14.583333333333332 28
Completed Iteration #9
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8128> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1f98> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b331d0> 5.208333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1358> 8.333333333333336 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4bfff60> 11.458333333333336 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 16.666666666666664 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 16.666666666666664 29
Completed Iteration #10
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 19.791666666666664 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 19.791666666666664 30
Completed Iteration #11
Best Reward: 3.125000000000001
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 3.125000000000001 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 19.791666666666664 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 19.791666666666664 31
Completed Iteration #12
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33898> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 6.250000000000002 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 22.916666666666664 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 22.916666666666664 32
Completed Iteration #13
Best Reward: 3.125000000000001
Completed Iteration #14
Best Reward: 3.125000000000001
Completed Iteration #15
Best Reward: 3.125000000000001
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33e48> 3.125000000000001 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 22.916666666666664 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 22.916666666666664 33
Completed Iteration #16
Best Reward: 3.125000000000001
Completed Iteration #17
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1390> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1cf8> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33898> 6.250000000000002 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 6.250000000000002 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 9.375000000000004 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 26.041666666666664 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 26.041666666666664 34
Completed Iteration #18
Best Reward: 3.125000000000001
Reward: 1.0416666666666652
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33860> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae15c0> 2.0833333333333304 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1710> 3.1249999999999956 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 27.08333333333333 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 27.08333333333333 35
Completed Iteration #19
Best Reward: 3.125000000000001
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b339b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33e48> 3.125000000000001 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 27.08333333333333 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 27.08333333333333 36
Completed Iteration #20
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1f28> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33b70> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1390> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1cf8> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33898> 8.333333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 8.333333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 11.458333333333336 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 29.16666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 29.16666666666666 37
Completed Iteration #21
Best Reward: 3.125000000000001
Completed Iteration #22
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 11.458333333333336 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 14.583333333333336 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 32.291666666666664 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 32.291666666666664 38
Completed Iteration #23
Best Reward: 3.125000000000001
Completed Iteration #24
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8cf8> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab710> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33e48> 6.250000000000002 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 35.416666666666664 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 35.416666666666664 39
Completed Iteration #25
Best Reward: 3.125000000000001
Completed MCTS Level/Depth: #1
root->3
Best Reward: 3.125000000000001
Completed Iteration #0
Best Reward: 3.125000000000001
Completed Iteration #1
Best Reward: 3.125000000000001
Completed Iteration #2
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8208> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 6.250000000000002 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 14.583333333333336 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 17.708333333333336 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 38.541666666666664 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 38.541666666666664 40
Completed Iteration #3
Best Reward: 3.125000000000001
Completed Iteration #4
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff9b0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33b70> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1390> 7.291666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1cf8> 7.291666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33898> 10.416666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 16.666666666666668 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 19.791666666666668 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 40.625 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 40.625 41
Completed Iteration #5
Best Reward: 3.125000000000001
Completed Iteration #6
Best Reward: 3.125000000000001
Reward: 1.0416666666666652
backprop <src.mcts.MCTS_Node object at 0x7f10f4afff28> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4afff98> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff9b0> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33b70> 5.208333333333331 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1390> 8.333333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1cf8> 8.333333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33898> 11.458333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 17.708333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 20.833333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 41.666666666666664 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 41.666666666666664 42
Completed Iteration #7
Best Reward: 3.125000000000001
Completed Iteration #8
Best Reward: 3.125000000000001
Completed Iteration #9
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10f4affeb8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b7b8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8208> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 8.333333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 19.791666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 22.916666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 43.75 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 43.75 43
Completed Iteration #10
Best Reward: 3.125000000000001
Completed Iteration #11
Best Reward: 3.125000000000001
Completed Iteration #12
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f198> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 21.874999999999996 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 24.999999999999996 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 45.833333333333336 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 45.833333333333336 44
Completed Iteration #13
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1588> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc19e8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affeb8> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b7b8> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 7.291666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8208> 7.291666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 10.416666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 23.95833333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 27.08333333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 47.91666666666667 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 47.91666666666667 45
Completed Iteration #14
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8390> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 27.08333333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 30.20833333333333 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 51.04166666666667 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 51.04166666666667 46
Completed Iteration #15
Best Reward: 3.125000000000001
Completed Iteration #16
Best Reward: 3.125000000000001
Completed Iteration #17
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f111c0c1630> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b7b8> 6.249999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 9.375 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8208> 9.375 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 12.5 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 29.16666666666666 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 32.291666666666664 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 53.12500000000001 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 53.12500000000001 47
Completed Iteration #18
Best Reward: 3.125000000000001
Completed Iteration #19
Best Reward: 3.125000000000001
Completed Iteration #20
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f11dfae27f0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae28d0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8390> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 31.249999999999993 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 34.375 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 55.20833333333334 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 55.20833333333334 48
Completed Iteration #21
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 15.625 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 34.37499999999999 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 37.5 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 58.33333333333334 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 58.33333333333334 49
Completed Iteration #22
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 6.250000000000002 3
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 6.250000000000002 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 18.75 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 37.49999999999999 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 40.625 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 61.45833333333334 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 61.45833333333334 50
Completed Iteration #23
Best Reward: 3.125000000000001
Completed Iteration #24
Best Reward: 3.125000000000001
Completed Iteration #25
Best Reward: 3.125000000000001
Completed MCTS Level/Depth: #2
root->3->17
Best Reward: 3.125000000000001
Completed Iteration #0
Best Reward: 3.125000000000001
Completed Iteration #1
Best Reward: 3.125000000000001
Completed Iteration #2
Best Reward: 3.125000000000001
Completed Iteration #3
Best Reward: 3.125000000000001
Completed Iteration #4
Best Reward: 3.125000000000001
Completed Iteration #5
Best Reward: 3.125000000000001
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f198> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 37.49999999999999 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 40.625 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 61.45833333333334 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 61.45833333333334 51
Completed Iteration #6
Best Reward: 3.125000000000001
Completed Iteration #7
Best Reward: 3.125000000000001
Completed Iteration #8
Best Reward: 3.125000000000001
Completed Iteration #9
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10f4b923c8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92240> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8390> 7.291666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 39.58333333333333 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 42.708333333333336 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 63.54166666666668 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 63.54166666666668 52
Completed Iteration #10
Best Reward: 3.125000000000001
Completed Iteration #11
Best Reward: 3.125000000000001
Completed Iteration #12
Best Reward: 3.125000000000001
Reward: 1.0416666666666652
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab978> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92a90> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b923c8> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92240> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8390> 8.333333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 40.62499999999999 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 43.75 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 64.58333333333334 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 64.58333333333334 53
Completed Iteration #13
Best Reward: 3.125000000000001
Completed Iteration #14
Best Reward: 3.125000000000001
Reward: 1.0416666666666652
backprop <src.mcts.MCTS_Node object at 0x7f111c059e10> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92240> 4.166666666666663 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8390> 9.374999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 41.66666666666666 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 44.791666666666664 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 65.62500000000001 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 65.62500000000001 54
Completed Iteration #15
Best Reward: 3.125000000000001
Completed Iteration #16
Best Reward: 3.125000000000001
Reward: 1.0416666666666652
backprop <src.mcts.MCTS_Node object at 0x7f10f4babb70> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8208> 10.416666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 19.791666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 42.70833333333332 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 45.83333333333333 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 66.66666666666669 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 66.66666666666669 55
Completed Iteration #17
Best Reward: 3.125000000000001
Completed Iteration #18
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f11913e2160> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae25f8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae27f0> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f11dfae28d0> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8390> 11.458333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 44.79166666666666 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 47.916666666666664 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 68.75000000000001 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 68.75000000000001 56
Completed Iteration #19
Best Reward: 3.125000000000001
Completed Iteration #20
Best Reward: 3.125000000000001
Reward: 1.0416666666666652
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8358> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae80b8> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4afff28> 2.0833333333333304 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4afff98> 2.0833333333333304 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff9b0> 4.166666666666663 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33b70> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1390> 9.374999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1cf8> 9.374999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33898> 12.499999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 45.83333333333332 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 48.95833333333333 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 69.79166666666669 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 69.79166666666669 57
Completed Iteration #21
Best Reward: 3.125000000000001
Completed Iteration #22
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92da0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8048> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f111c0c1630> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b7b8> 8.333333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 11.458333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8208> 12.499999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 21.874999999999996 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 47.91666666666666 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 51.041666666666664 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 71.87500000000001 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 71.87500000000001 58
Completed Iteration #23
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33400> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee6a0> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 24.999999999999996 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 51.04166666666666 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 54.166666666666664 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 75.00000000000001 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 75.00000000000001 59
Completed Iteration #24
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33588> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 54.16666666666666 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 57.291666666666664 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 78.12500000000001 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 78.12500000000001 60
Completed Iteration #25
Best Reward: 3.125000000000001
Completed MCTS Level/Depth: #3
root->3->17->6
Best Reward: 3.125000000000001
Completed Iteration #0
Best Reward: 3.125000000000001
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4babc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 3.125000000000001 3
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 6.250000000000002 4
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 6.250000000000002 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 24.999999999999996 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 54.16666666666666 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 57.291666666666664 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 78.12500000000001 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 78.12500000000001 61
Completed Iteration #1
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143da0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33400> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee6a0> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 27.08333333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 56.24999999999999 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 59.375 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 80.20833333333334 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 80.20833333333334 62
Completed Iteration #2
Best Reward: 3.125000000000001
Completed Iteration #3
Best Reward: 3.125000000000001
Completed Iteration #4
Best Reward: 3.125000000000001
Reward: 1.0416666666666652
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee7f0> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81438d0> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 7.291666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 7.291666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 28.124999999999993 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 57.29166666666666 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 60.416666666666664 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 81.25000000000001 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 81.25000000000001 63
Completed Iteration #5
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e8165fd0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143da0> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33400> 7.291666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee6a0> 7.291666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 30.208333333333325 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 59.37499999999999 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 62.5 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 83.33333333333334 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 83.33333333333334 64
Completed Iteration #6
Best Reward: 3.125000000000001
Completed Iteration #7
Best Reward: 3.125000000000001
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1588> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc19e8> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4affeb8> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b7b8> 8.333333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 11.458333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8208> 12.499999999999996 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 30.208333333333325 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 59.37499999999999 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 62.5 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 83.33333333333334 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 83.33333333333334 65
Completed Iteration #8
Best Reward: 3.125000000000001
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f11913d0d68> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143da0> 7.291666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33400> 10.416666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee6a0> 10.416666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 33.33333333333333 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 62.49999999999999 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 65.625 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 86.45833333333334 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 86.45833333333334 66
Completed Iteration #9
Best Reward: 3.125000000000001
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 4.166666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 7.291666666666667 6
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 7.291666666666667 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 33.33333333333333 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 62.49999999999999 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 65.625 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 86.45833333333334 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 86.45833333333334 67
Completed Iteration #10
Best Reward: 3.125000000000001
Completed Iteration #11
Best Reward: 3.125000000000001
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8470> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33d30> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165fd0> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8143da0> 9.375 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33400> 12.5 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee6a0> 12.5 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 35.416666666666664 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 64.58333333333333 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 67.70833333333333 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 88.54166666666667 54
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 88.54166666666667 68
Completed Iteration #12
Best Reward: 3.125000000000001
Completed Iteration #13
Best Reward: 3.125000000000001
Completed Iteration #14
Best Reward: 3.125000000000001
Completed Iteration #15
Best Reward: 3.125000000000001
Completed Iteration #16
Best Reward: 3.125000000000001
Completed Iteration #17
Best Reward: 3.125000000000001
Reward: 4.166666666666665
backprop <src.mcts.MCTS_Node object at 0x7f10e81657b8> 4.166666666666665 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165b38> 4.166666666666665 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee7f0> 5.20833333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81438d0> 5.20833333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 8.333333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 8.333333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 11.458333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 11.458333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 39.58333333333333 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 68.75 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 71.875 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 92.70833333333334 55
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 92.70833333333334 69
Completed Iteration #18
Best Reward: 4.166666666666665
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10e8165518> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 14.583333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 42.70833333333333 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 71.875 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 75.0 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 95.83333333333334 56
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 95.83333333333334 70
Completed Iteration #19
Best Reward: 4.166666666666665
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee2e8> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6ba8> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165518> 6.250000000000002 3
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 17.708333333333332 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 45.83333333333333 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 75.0 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 78.125 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 98.95833333333334 57
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 98.95833333333334 71
Completed Iteration #20
Best Reward: 4.166666666666665
Completed Iteration #21
Best Reward: 4.166666666666665
Completed Iteration #22
Best Reward: 4.166666666666665
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81436a0> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8143da0> 9.375 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33400> 12.5 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee6a0> 12.5 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 45.83333333333333 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 75.0 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 78.125 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 98.95833333333334 58
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 98.95833333333334 72
Completed Iteration #23
Best Reward: 4.166666666666665
Completed Iteration #24
Best Reward: 4.166666666666665
Completed Iteration #25
Best Reward: 4.166666666666665
Completed MCTS Level/Depth: #4
root->3->17->6->12
Best Reward: 4.166666666666665
Completed Iteration #0
Best Reward: 4.166666666666665
Completed Iteration #1
Best Reward: 4.166666666666665
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6a90> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81438d0> 8.333333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 11.458333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 11.458333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 14.583333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 20.833333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 48.95833333333333 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 78.125 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 81.25 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 102.08333333333334 59
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 102.08333333333334 73
Completed Iteration #2
Best Reward: 4.166666666666665
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 22.916666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 51.041666666666664 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 80.20833333333333 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 83.33333333333333 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 104.16666666666667 60
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 104.16666666666667 74
Completed Iteration #3
Best Reward: 4.166666666666665
Completed Iteration #4
Best Reward: 4.166666666666665
Completed Iteration #5
Best Reward: 4.166666666666665
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 11.458333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 14.583333333333332 9
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 22.916666666666664 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 51.041666666666664 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 80.20833333333333 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 83.33333333333333 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 104.16666666666667 61
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 104.16666666666667 75
Completed Iteration #6
Best Reward: 4.166666666666665
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33748> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b921d0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6a90> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81438d0> 10.416666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 13.541666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 13.541666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 16.666666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 24.999999999999996 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 53.125 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 82.29166666666666 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 85.41666666666666 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 106.25 62
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 106.25 76
Completed Iteration #7
Best Reward: 4.166666666666665
Reward: 7.291666666666667
backprop <src.mcts.MCTS_Node object at 0x7f10e8165588> 7.291666666666667 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165550> 7.291666666666667 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81657b8> 11.458333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165b38> 11.458333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee7f0> 12.499999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81438d0> 17.708333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 20.833333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 20.833333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 23.958333333333332 11
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 32.291666666666664 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 60.416666666666664 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 89.58333333333333 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 92.70833333333333 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 113.54166666666667 63
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 113.54166666666667 77
Completed Iteration #8
Best Reward: 7.291666666666667
Reward: 5.208333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6fd0> 5.208333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4baba58> 5.208333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33748> 7.291666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b921d0> 7.291666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6a90> 10.416666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81438d0> 22.916666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 26.041666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 26.041666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 29.166666666666664 12
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 37.5 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 65.625 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 94.79166666666666 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 97.91666666666666 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 118.75 64
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 118.75 78
Completed Iteration #9
Best Reward: 7.291666666666667
Completed Iteration #10
Best Reward: 7.291666666666667
Completed Iteration #11
Best Reward: 7.291666666666667
Completed Iteration #12
Best Reward: 7.291666666666667
Completed Iteration #13
Best Reward: 7.291666666666667
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10e81823c8> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 40.625 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 68.75 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 97.91666666666666 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 101.04166666666666 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 121.875 65
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 121.875 79
Completed Iteration #14
Best Reward: 7.291666666666667
Completed Iteration #15
Best Reward: 7.291666666666667
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5278> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5518> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 42.708333333333336 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 70.83333333333333 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 99.99999999999999 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 103.12499999999999 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 123.95833333333333 66
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 123.95833333333333 80
Completed Iteration #16
Best Reward: 7.291666666666667
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5550> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5278> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5518> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 6.249999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 44.79166666666667 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 72.91666666666666 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 102.08333333333331 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 105.20833333333331 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 126.04166666666666 67
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 126.04166666666666 81
Completed Iteration #17
Best Reward: 7.291666666666667
Completed Iteration #18
Best Reward: 7.291666666666667
Completed Iteration #19
Best Reward: 7.291666666666667
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd710> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143c18> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee2e8> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6ba8> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165518> 8.333333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 46.87500000000001 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 74.99999999999999 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 104.16666666666664 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 107.29166666666664 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 128.125 68
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 128.125 82
Completed Iteration #20
Best Reward: 7.291666666666667
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdb00> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 50.00000000000001 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 78.12499999999999 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 107.29166666666664 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 110.41666666666664 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 131.25 69
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 131.25 83
Completed Iteration #21
Best Reward: 7.291666666666667
Reward: 1.0416666666666652
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae87f0> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae2518> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdb00> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 51.04166666666667 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 79.16666666666666 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 108.33333333333331 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 111.45833333333331 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 132.29166666666666 70
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 132.29166666666666 84
Completed Iteration #22
Best Reward: 7.291666666666667
Completed Iteration #23
Best Reward: 7.291666666666667
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10e81a62b0> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 54.16666666666667 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 82.29166666666666 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 111.45833333333331 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 114.58333333333331 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 135.41666666666666 71
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 135.41666666666666 85
Completed Iteration #24
Best Reward: 7.291666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae87f0> 1.0416666666666652 3
backprop <src.mcts.MCTS_Node object at 0x7f11dfae2518> 1.0416666666666652 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdb00> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 54.16666666666667 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 82.29166666666666 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 111.45833333333331 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 114.58333333333331 54
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 135.41666666666666 72
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 135.41666666666666 86
Completed Iteration #25
Best Reward: 7.291666666666667
Completed MCTS Level/Depth: #5
root->3->17->6->12->8
Best Reward: 7.291666666666667
Completed Iteration #0
Best Reward: 7.291666666666667
Reward: 1.0416666666666652
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6668> 1.0416666666666652 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81438d0> 23.95833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 27.08333333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 27.08333333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 30.20833333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 55.208333333333336 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 83.33333333333333 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 112.49999999999999 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 115.62499999999999 55
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 136.45833333333331 73
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 136.45833333333331 87
Completed Iteration #1
Best Reward: 7.291666666666667
Completed Iteration #2
Best Reward: 7.291666666666667
Reward: 5.208333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd6a0> 5.208333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56d8> 5.208333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee7f0> 17.70833333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81438d0> 29.16666666666666 9
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 32.291666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 32.291666666666664 13
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 35.416666666666664 14
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 60.41666666666667 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 88.54166666666666 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 117.70833333333331 54
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 120.83333333333331 56
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 141.66666666666666 74
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 141.66666666666666 88
Completed Iteration #3
Best Reward: 7.291666666666667
Completed Iteration #4
Best Reward: 7.291666666666667
Completed Iteration #5
Best Reward: 7.291666666666667
Completed Iteration #6
Best Reward: 7.291666666666667
Reward: 5.208333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddd68> 5.208333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd3c8> 5.208333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd6a0> 10.416666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56d8> 10.416666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee7f0> 22.91666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81438d0> 34.37499999999999 10
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 37.5 11
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 37.5 14
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 40.625 15
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 65.625 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 93.74999999999999 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 122.91666666666664 55
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 126.04166666666664 57
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 146.875 75
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 146.875 89
Completed Iteration #7
Best Reward: 7.291666666666667
Completed Iteration #8
Best Reward: 7.291666666666667
Completed Iteration #9
Best Reward: 7.291666666666667
Completed Iteration #10
Best Reward: 7.291666666666667
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33208> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5860> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6a90> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81438d0> 36.45833333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 39.583333333333336 12
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 39.583333333333336 15
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 42.708333333333336 16
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 67.70833333333333 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 95.83333333333331 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 124.99999999999997 56
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 128.12499999999997 58
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 148.95833333333334 76
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 148.95833333333334 90
Completed Iteration #11
Best Reward: 7.291666666666667
Completed Iteration #12
Best Reward: 7.291666666666667
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 45.833333333333336 17
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 70.83333333333333 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 98.95833333333331 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 128.12499999999997 57
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 131.24999999999997 59
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 152.08333333333334 77
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 152.08333333333334 91
Completed Iteration #13
Best Reward: 7.291666666666667
Reward: 6.249999999999999
backprop <src.mcts.MCTS_Node object at 0x7f111c03eba8> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5fd0> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6fd0> 11.458333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4baba58> 11.458333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33748> 13.541666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b921d0> 13.541666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6a90> 18.75 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81438d0> 42.70833333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 45.833333333333336 13
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 45.833333333333336 16
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 52.083333333333336 18
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 77.08333333333333 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 105.20833333333331 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 134.37499999999997 58
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 137.49999999999997 60
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 158.33333333333334 78
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 158.33333333333334 92
Completed Iteration #14
Best Reward: 7.291666666666667
Completed Iteration #15
Best Reward: 7.291666666666667
Completed Iteration #16
Best Reward: 7.291666666666667
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd5c0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdcc0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 54.16666666666667 19
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 79.16666666666666 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 107.29166666666664 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 136.45833333333331 59
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 139.58333333333331 61
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 160.41666666666669 79
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 160.41666666666669 93
Completed Iteration #17
Best Reward: 7.291666666666667
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5cc0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5240> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd5c0> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdcc0> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 56.25000000000001 20
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 81.24999999999999 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 109.37499999999997 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 138.54166666666666 60
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 141.66666666666666 62
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 162.50000000000003 80
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 162.50000000000003 94
Completed Iteration #18
Best Reward: 7.291666666666667
Completed Iteration #19
Best Reward: 7.291666666666667
Reward: 4.166666666666665
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92b70> 4.166666666666665 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 4.166666666666665 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 7.291666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 7.291666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 60.41666666666667 21
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 85.41666666666666 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 113.54166666666664 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 142.70833333333331 61
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 145.83333333333331 63
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 166.66666666666669 81
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 166.66666666666669 95
Completed Iteration #20
Best Reward: 7.291666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81438d0> 42.70833333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 45.833333333333336 14
backprop <src.mcts.MCTS_Node object at 0x7f11913e2080> 45.833333333333336 17
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 60.41666666666667 22
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 85.41666666666666 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 113.54166666666664 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 142.70833333333331 62
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 145.83333333333331 64
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 166.66666666666669 82
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 166.66666666666669 96
Completed Iteration #21
Best Reward: 7.291666666666667
Completed Iteration #22
Best Reward: 7.291666666666667
Reward: 4.166666666666665
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 4.166666666666665 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03e198> 4.166666666666665 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92b70> 8.33333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 8.33333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 11.458333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 11.458333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 64.58333333333334 23
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 89.58333333333333 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 117.70833333333331 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 146.87499999999997 63
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 149.99999999999997 65
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 170.83333333333334 83
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 170.83333333333334 97
Completed Iteration #23
Best Reward: 7.291666666666667
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6710> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d390> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5cc0> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5240> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd5c0> 6.249999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdcc0> 6.249999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 66.66666666666667 24
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 91.66666666666666 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 119.79166666666664 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 148.95833333333331 64
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 152.08333333333331 66
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 172.91666666666669 84
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 172.91666666666669 98
Completed Iteration #24
Best Reward: 7.291666666666667
Completed Iteration #25
Best Reward: 7.291666666666667
Completed MCTS Level/Depth: #6
root->3->17->6->12->8->16
Best Reward: 7.291666666666667
Completed Iteration #0
Best Reward: 7.291666666666667
Completed Iteration #1
Best Reward: 7.291666666666667
Completed Iteration #2
Best Reward: 7.291666666666667
Completed Iteration #3
Best Reward: 7.291666666666667
Completed Iteration #4
Best Reward: 7.291666666666667
Completed Iteration #5
Best Reward: 7.291666666666667
Reward: 5.208333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e8202be0> 5.208333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd898> 5.208333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 9.374999999999998 3
backprop <src.mcts.MCTS_Node object at 0x7f111c03e198> 9.374999999999998 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92b70> 13.541666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 13.541666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 16.666666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 16.666666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 71.875 25
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 96.87499999999999 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 124.99999999999997 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 154.16666666666666 65
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 157.29166666666666 67
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 178.12500000000003 85
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 178.12500000000003 99
Completed Iteration #6
Best Reward: 7.291666666666667
Completed Iteration #7
Best Reward: 7.291666666666667
Completed Iteration #8
Best Reward: 7.291666666666667
Completed Iteration #9
Best Reward: 7.291666666666667
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddcc0> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 19.791666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 75.0 26
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 99.99999999999999 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 128.12499999999997 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 157.29166666666666 66
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 160.41666666666666 68
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 181.25000000000003 86
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 181.25000000000003 100
Completed Iteration #10
Best Reward: 7.291666666666667
Completed Iteration #11
Best Reward: 7.291666666666667
Reward: 6.249999999999999
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5320> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81435c0> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202be0> 11.458333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd898> 11.458333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f111c03e198> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92b70> 19.791666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 19.791666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 22.916666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 26.041666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 81.25 27
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 106.24999999999999 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 134.37499999999997 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 163.54166666666666 67
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 166.66666666666666 69
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 187.50000000000003 87
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 187.50000000000003 101
Completed Iteration #12
Best Reward: 7.291666666666667
Completed Iteration #13
Best Reward: 7.291666666666667
Completed Iteration #14
Best Reward: 7.291666666666667
Reward: 6.249999999999999
backprop <src.mcts.MCTS_Node object at 0x7f111c03ed30> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d358> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5320> 12.499999999999998 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81435c0> 12.499999999999998 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202be0> 17.708333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd898> 17.708333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 21.874999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f111c03e198> 21.874999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92b70> 26.041666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 26.041666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 29.166666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 32.291666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 87.5 28
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 112.49999999999999 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 140.62499999999997 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 169.79166666666666 68
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 172.91666666666666 70
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 193.75000000000003 88
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 193.75000000000003 102
Completed Iteration #15
Best Reward: 7.291666666666667
Completed Iteration #16
Best Reward: 7.291666666666667
Reward: 6.249999999999999
backprop <src.mcts.MCTS_Node object at 0x7f10e8202240> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202e48> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ed30> 12.499999999999998 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d358> 12.499999999999998 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5320> 18.749999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81435c0> 18.749999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8202be0> 23.958333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd898> 23.958333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 28.124999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f111c03e198> 28.124999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92b70> 32.291666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 32.291666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 35.416666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 38.541666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 93.75 29
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 118.74999999999999 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 146.87499999999997 54
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 176.04166666666666 69
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 179.16666666666666 71
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 200.00000000000003 89
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 200.00000000000003 103
Completed Iteration #17
Best Reward: 7.291666666666667
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5710> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f50f0> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddcc0> 6.250000000000002 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 41.666666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 96.875 30
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 121.87499999999999 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 149.99999999999997 55
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 179.16666666666666 70
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 182.29166666666666 72
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 203.12500000000003 90
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 203.12500000000003 104
Completed Iteration #18
Best Reward: 7.291666666666667
Completed Iteration #19
Best Reward: 7.291666666666667
Completed Iteration #20
Best Reward: 7.291666666666667
Completed Iteration #21
Best Reward: 7.291666666666667
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5748> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 44.791666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 100.0 31
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 124.99999999999999 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 153.12499999999997 56
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 182.29166666666666 71
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 185.41666666666666 73
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 206.25000000000003 91
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 206.25000000000003 105
Completed Iteration #22
Best Reward: 7.291666666666667
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f111c04b4a8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f111c04b6d8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5710> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81f50f0> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddcc0> 8.333333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 46.875 12
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 102.08333333333333 32
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 127.08333333333331 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 155.20833333333331 57
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 184.375 72
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 187.5 74
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 208.33333333333337 92
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 208.33333333333337 106
Completed Iteration #23
Best Reward: 7.291666666666667
Completed Iteration #24
Best Reward: 7.291666666666667
Reward: 6.249999999999999
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5d30> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd198> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202240> 12.499999999999998 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202e48> 12.499999999999998 3
backprop <src.mcts.MCTS_Node object at 0x7f111c03ed30> 18.749999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820d358> 18.749999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5320> 24.999999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81435c0> 24.999999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8202be0> 30.208333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd898> 30.208333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 34.37499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f111c03e198> 34.37499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92b70> 38.541666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 38.541666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 41.666666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 53.125 13
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 108.33333333333333 33
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 133.33333333333331 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 161.45833333333331 58
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 190.625 73
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 193.75 75
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 214.58333333333337 93
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 214.58333333333337 107
Completed Iteration #25
Best Reward: 7.291666666666667
Completed MCTS Level/Depth: #7
root->3->17->6->12->8->16->3
Best Reward: 7.291666666666667
Completed Iteration #0
Best Reward: 7.291666666666667
Completed Iteration #1
Best Reward: 7.291666666666667
Reward: 6.249999999999999
backprop <src.mcts.MCTS_Node object at 0x7f10e81f57b8> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d358> 24.999999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5320> 31.249999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81435c0> 31.249999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10e8202be0> 36.45833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd898> 36.45833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 40.62499999999999 8
backprop <src.mcts.MCTS_Node object at 0x7f111c03e198> 40.62499999999999 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92b70> 44.791666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 44.791666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 47.916666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 59.375 14
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 114.58333333333333 34
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 139.58333333333331 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 167.70833333333331 59
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 196.875 74
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 200.0 76
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 220.83333333333337 94
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 220.83333333333337 108
Completed Iteration #2
Best Reward: 7.291666666666667
Completed Iteration #3
Best Reward: 7.291666666666667
Reward: 6.249999999999999
backprop <src.mcts.MCTS_Node object at 0x7f10e82026a0> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82029b0> 6.249999999999999 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f57b8> 12.499999999999998 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d358> 31.249999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5320> 37.49999999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81435c0> 37.49999999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f10e8202be0> 42.70833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd898> 42.70833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 46.87499999999999 9
backprop <src.mcts.MCTS_Node object at 0x7f111c03e198> 46.87499999999999 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92b70> 51.041666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 51.041666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 54.166666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 65.625 15
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 120.83333333333333 35
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 145.83333333333331 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 173.95833333333331 60
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 203.125 75
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 206.25 77
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 227.08333333333337 95
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 227.08333333333337 109
Completed Iteration #4
Best Reward: 7.291666666666667
coverage_call_count 700
Completed Iteration #5
Best Reward: 7.291666666666667
Completed Iteration #6
Best Reward: 7.291666666666667
Completed Iteration #7
Best Reward: 7.291666666666667
Reward: 5.208333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10eba62be0> 5.208333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd898> 47.916666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 52.08333333333333 10
backprop <src.mcts.MCTS_Node object at 0x7f111c03e198> 52.08333333333333 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92b70> 56.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 56.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 59.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 70.83333333333333 16
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 126.04166666666666 36
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 151.04166666666666 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 179.16666666666666 61
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 208.33333333333334 76
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 211.45833333333334 78
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 232.2916666666667 96
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 232.2916666666667 110
Completed Iteration #8
Best Reward: 7.291666666666667
Completed Iteration #9
Best Reward: 7.291666666666667
Completed Iteration #10
Best Reward: 7.291666666666667
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10eba62898> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 59.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 62.5 13
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 73.95833333333333 17
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 129.16666666666666 37
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 154.16666666666666 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 182.29166666666666 62
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 211.45833333333334 77
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 214.58333333333334 79
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 235.4166666666667 97
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 235.4166666666667 111
Completed Iteration #11
Best Reward: 7.291666666666667
Completed Iteration #12
Best Reward: 7.291666666666667
Completed Iteration #13
Best Reward: 7.291666666666667
Completed Iteration #14
Best Reward: 7.291666666666667
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5f98> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd898> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62898> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 61.458333333333336 13
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 64.58333333333333 14
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 76.04166666666666 18
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 131.25 38
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 156.25 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 184.375 63
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 213.54166666666669 78
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 216.66666666666669 80
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 237.50000000000006 98
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 237.50000000000006 112
Completed Iteration #15
Best Reward: 7.291666666666667
Completed Iteration #16
Best Reward: 7.291666666666667
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10e8202198> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52e8> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 67.70833333333333 15
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 79.16666666666666 19
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 134.375 39
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 159.375 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 187.5 64
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 216.66666666666669 79
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 219.79166666666669 81
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 240.62500000000006 99
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 240.62500000000006 113
Completed Iteration #17
Best Reward: 7.291666666666667
Completed Iteration #18
Best Reward: 7.291666666666667
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f10eba62320> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62ba8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202198> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52e8> 5.208333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 69.79166666666666 16
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 81.24999999999999 20
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 136.45833333333334 40
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 161.45833333333334 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 189.58333333333334 65
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 218.75000000000003 80
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 221.87500000000003 82
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 242.7083333333334 100
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 242.7083333333334 114
Completed Iteration #19
Best Reward: 7.291666666666667
Completed Iteration #20
Best Reward: 7.291666666666667
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5a90> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52e8> 8.333333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 72.91666666666666 17
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 84.37499999999999 21
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 139.58333333333334 41
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 164.58333333333334 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 192.70833333333334 66
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 221.87500000000003 81
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 225.00000000000003 83
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 245.8333333333334 101
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 245.8333333333334 115
Completed Iteration #21
Best Reward: 7.291666666666667
Reward: 3.125000000000001
backprop <src.mcts.MCTS_Node object at 0x7f10eba558d0> 3.125000000000001 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 64.58333333333334 14
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 76.04166666666666 18
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd470> 87.49999999999999 22
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 142.70833333333334 42
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 167.70833333333334 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 195.83333333333334 67
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1400> 225.00000000000003 82
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae84e0> 228.12500000000003 84
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd37b8> 248.9583333333334 102
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 248.9583333333334 116
Completed Iteration #22
Best Reward: 7.291666666666667
Completed Iteration #23
Best Reward: 7.291666666666667
Completed Iteration #24
Best Reward: 7.291666666666667
Completed Iteration #25
Best Reward: 7.291666666666667
Completed MCTS Level/Depth: #8
root->3->17->6->12->8->16->3->11
Best Reward: 7.291666666666667
iteration: 11
found coverage increase 7.291666666666667
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e82025c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e82022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 14.583333333333334
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c04b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c04b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f58d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba55b38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 14.583333333333334
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bfffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bfff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bfff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81244e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bfffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124fd0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f10e8124390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 14.583333333333334
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4affe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 14.583333333333334
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e818d3c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 14.583333333333334
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 20
Completed Iteration #23
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81373c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4affba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81375c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81180b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81180b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 14.583333333333334
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b757f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b757f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10c88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4affb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 14.583333333333334
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81376d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81376d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45090b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45099e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45090b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45099e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45196a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509240> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 14.583333333333334
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4affba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81241d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4509630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81592e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b654a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b654a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45091d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81592e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45090f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45199e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 13
Completed Iteration #19
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45199e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45199e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 14.583333333333334
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0198> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f08d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45096a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 1200
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44722b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf98> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44726a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44726a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44726a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44726a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4458748> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44273c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44170b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44170b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44170b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44279e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44273c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44729b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427198> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f823c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45195f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82c18> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 2.0833333333333304 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 2.0833333333333304 22
Completed Iteration #25
Best Reward: 2.0833333333333304
Completed MCTS Level/Depth: #0
root
Best Reward: 2.0833333333333304
Completed Iteration #0
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 2.0833333333333304 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 2.0833333333333304 23
Completed Iteration #1
Best Reward: 2.0833333333333304
Completed Iteration #2
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82390> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f826d8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82c18> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 3.1249999999999964 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 3.1249999999999964 24
Completed Iteration #3
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f906d8> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90588> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82390> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f826d8> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82c18> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 5.208333333333327 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 5.208333333333327 25
Completed Iteration #4
Best Reward: 2.0833333333333304
Completed Iteration #5
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 7.291666666666657 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 7.291666666666657 26
Completed Iteration #6
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 9.374999999999988 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 9.374999999999988 27
Completed Iteration #7
Best Reward: 2.0833333333333304
Completed Iteration #8
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 9.374999999999988 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 9.374999999999988 28
Completed Iteration #9
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 11.458333333333318 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 11.458333333333318 29
Completed Iteration #10
Best Reward: 2.0833333333333304
Completed Iteration #11
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90c88> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 12.499999999999984 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 12.499999999999984 30
Completed Iteration #12
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 12.499999999999984 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 12.499999999999984 31
Completed Iteration #13
Best Reward: 2.0833333333333304
coverage_call_count 1400
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa01d0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 14.583333333333314 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 14.583333333333314 32
Completed Iteration #14
Best Reward: 2.0833333333333304
Completed Iteration #15
Best Reward: 2.0833333333333304
Completed Iteration #16
Best Reward: 2.0833333333333304
Completed Iteration #17
Best Reward: 2.0833333333333304
Completed Iteration #18
Best Reward: 2.0833333333333304
Completed Iteration #19
Best Reward: 2.0833333333333304
Completed Iteration #20
Best Reward: 2.0833333333333304
Completed Iteration #21
Best Reward: 2.0833333333333304
Completed Iteration #22
Best Reward: 2.0833333333333304
Completed Iteration #23
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad4a8> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 10.416666666666652 6
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 16.666666666666643 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 16.666666666666643 33
Completed Iteration #24
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadba8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad9e8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90c88> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 17.708333333333307 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 17.708333333333307 34
Completed Iteration #25
Best Reward: 2.0833333333333304
Completed MCTS Level/Depth: #1
root->2
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadc50> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad4a8> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 10.416666666666652 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 10.416666666666652 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 12.499999999999982 7
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 19.791666666666636 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 19.791666666666636 35
Completed Iteration #0
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad6d8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 13.541666666666648 8
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 20.8333333333333 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 20.8333333333333 36
Completed Iteration #1
Best Reward: 2.0833333333333304
Completed Iteration #2
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba5c0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba630> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadc50> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad4a8> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 10.416666666666652 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 12.499999999999982 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 12.499999999999982 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 15.624999999999979 9
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 22.91666666666663 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 22.91666666666663 37
Completed Iteration #3
Best Reward: 2.0833333333333304
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbac18> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbaa58> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 4.166666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad6d8> 4.166666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 18.74999999999998 10
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 26.04166666666663 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 26.04166666666663 38
Completed Iteration #4
Best Reward: 3.1250000000000018
Completed Iteration #5
Best Reward: 3.1250000000000018
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad6d8> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 18.74999999999998 11
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 26.04166666666663 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 26.04166666666663 39
Completed Iteration #6
Best Reward: 3.1250000000000018
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa03c8> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0f60> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa01d0> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 12.499999999999982 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 14.583333333333313 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 14.583333333333313 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 20.833333333333307 12
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 28.124999999999957 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 28.124999999999957 40
Completed Iteration #7
Best Reward: 3.1250000000000018
Completed Iteration #8
Best Reward: 3.1250000000000018
Completed Iteration #9
Best Reward: 3.1250000000000018
Completed Iteration #10
Best Reward: 3.1250000000000018
Completed Iteration #11
Best Reward: 3.1250000000000018
Completed Iteration #12
Best Reward: 3.1250000000000018
Completed Iteration #13
Best Reward: 3.1250000000000018
Completed Iteration #14
Best Reward: 3.1250000000000018
Completed Iteration #15
Best Reward: 3.1250000000000018
Completed Iteration #16
Best Reward: 3.1250000000000018
Completed Iteration #17
Best Reward: 3.1250000000000018
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f4417f60> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75470> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba5c0> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba630> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadc50> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad4a8> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 10.416666666666652 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 14.583333333333313 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 16.666666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 16.666666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 22.916666666666636 13
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 30.208333333333286 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 30.208333333333286 41
Completed Iteration #18
Best Reward: 3.1250000000000018
Completed Iteration #19
Best Reward: 3.1250000000000018
Completed Iteration #20
Best Reward: 3.1250000000000018
Completed Iteration #21
Best Reward: 3.1250000000000018
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadd30> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba278> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa01d0> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 16.666666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 18.74999999999997 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 18.74999999999997 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 24.999999999999964 14
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 32.291666666666615 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 32.291666666666615 42
Completed Iteration #22
Best Reward: 3.1250000000000018
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadc88> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad940> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 27.083333333333293 15
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 34.37499999999994 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 34.37499999999994 43
Completed Iteration #23
Best Reward: 3.1250000000000018
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad978> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadc18> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbac18> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbaa58> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 8.333333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad6d8> 8.333333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 31.249999999999957 16
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 38.54166666666661 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 38.54166666666661 44
Completed Iteration #24
Best Reward: 4.166666666666666
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #2
root->2->19
Best Reward: 4.166666666666666
Completed Iteration #0
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba860> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba898> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa03c8> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0f60> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa01d0> 10.416666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 20.833333333333307 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 22.916666666666636 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 22.916666666666636 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 35.41666666666662 17
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 42.70833333333327 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 42.70833333333327 45
Completed Iteration #1
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbaeb8> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbac50> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417f60> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75470> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba5c0> 7.2916666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba630> 7.2916666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 9.374999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadc50> 9.374999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 11.458333333333323 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad4a8> 11.458333333333323 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 13.541666666666654 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 23.958333333333307 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 26.041666666666636 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 26.041666666666636 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 38.54166666666662 18
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 45.83333333333327 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 45.83333333333327 46
Completed Iteration #2
Best Reward: 4.166666666666666
Completed Iteration #3
Best Reward: 4.166666666666666
Completed Iteration #4
Best Reward: 4.166666666666666
Completed Iteration #5
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbac88> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52ba8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbaeb8> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbac50> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417f60> 9.374999999999998 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75470> 9.374999999999998 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba5c0> 11.458333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba630> 11.458333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 13.541666666666659 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadc50> 13.541666666666659 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 15.62499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad4a8> 15.62499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 17.70833333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 28.12499999999997 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 30.2083333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 30.2083333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 42.708333333333286 19
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 49.999999999999936 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 49.999999999999936 47
Completed Iteration #6
Best Reward: 4.166666666666666
Completed Iteration #7
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1a58> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75470> 11.458333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba5c0> 13.541666666666659 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba630> 13.541666666666659 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 15.62499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadc50> 15.62499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 17.70833333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad4a8> 17.70833333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 19.79166666666665 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 30.2083333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 32.29166666666663 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 32.29166666666663 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 44.791666666666615 20
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 52.083333333333265 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 52.083333333333265 48
Completed Iteration #8
Best Reward: 4.166666666666666
Completed Iteration #9
Best Reward: 4.166666666666666
Completed Iteration #10
Best Reward: 4.166666666666666
Completed Iteration #11
Best Reward: 4.166666666666666
Completed Iteration #12
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f45092b0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90fd0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadd30> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba278> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa01d0> 12.499999999999988 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 32.29166666666663 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 34.37499999999996 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 34.37499999999996 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 46.87499999999994 21
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 54.16666666666659 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 54.16666666666659 49
Completed Iteration #13
Best Reward: 4.166666666666666
Completed Iteration #14
Best Reward: 4.166666666666666
Completed Iteration #15
Best Reward: 4.166666666666666
Completed Iteration #16
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90d30> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba630> 15.62499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 17.70833333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadc50> 17.70833333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 19.79166666666665 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad4a8> 19.79166666666665 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 21.87499999999998 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 34.37499999999996 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 36.458333333333286 16
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 36.458333333333286 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 48.95833333333327 22
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 56.24999999999992 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 56.24999999999992 50
Completed Iteration #17
Best Reward: 4.166666666666666
Completed Iteration #18
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c18> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52a58> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 19.79166666666665 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadc50> 19.79166666666665 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 21.87499999999998 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad4a8> 21.87499999999998 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 23.958333333333307 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 36.458333333333286 16
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 38.541666666666615 17
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 38.541666666666615 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 51.0416666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 58.33333333333325 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 58.33333333333325 51
Completed Iteration #19
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52fd0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 39.58333333333328 18
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 39.58333333333328 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 52.083333333333265 24
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 59.374999999999915 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 59.374999999999915 52
Completed Iteration #20
Best Reward: 4.166666666666666
Completed Iteration #21
Best Reward: 4.166666666666666
Completed Iteration #22
Best Reward: 4.166666666666666
Completed Iteration #23
Best Reward: 4.166666666666666
Completed Iteration #24
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 38.541666666666615 17
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 41.66666666666661 19
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 41.66666666666661 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 54.16666666666659 25
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 61.45833333333324 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 61.45833333333324 53
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #3
root->2->19->2
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b00> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f635c0> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba860> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba898> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa03c8> 9.374999999999998 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0f60> 9.374999999999998 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa01d0> 15.62499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 41.666666666666615 18
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 44.79166666666661 20
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 44.79166666666661 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 57.29166666666659 26
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 64.58333333333324 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 64.58333333333324 54
Completed Iteration #0
Best Reward: 4.166666666666666
Completed Iteration #1
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9128> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 45.83333333333327 21
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 45.83333333333327 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 58.33333333333326 27
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 65.62499999999991 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 65.62499999999991 55
Completed Iteration #2
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0748> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadc50> 20.833333333333314 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 22.916666666666643 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad4a8> 22.916666666666643 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 24.99999999999997 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 42.70833333333328 19
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 46.874999999999936 22
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 46.874999999999936 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 59.37499999999992 28
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 66.66666666666659 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 66.66666666666659 56
Completed Iteration #3
Best Reward: 4.166666666666666
Completed Iteration #4
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba908> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 44.79166666666661 20
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 48.958333333333265 23
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 48.958333333333265 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 61.45833333333325 29
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 68.74999999999991 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 68.74999999999991 57
Completed Iteration #5
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad7f0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52160> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba908> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 46.874999999999936 21
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 51.04166666666659 24
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 51.04166666666659 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 63.54166666666658 30
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 70.83333333333324 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 70.83333333333324 58
Completed Iteration #6
Best Reward: 4.166666666666666
Completed Iteration #7
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c50> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 48.958333333333265 22
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 53.12499999999992 25
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 53.12499999999992 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 65.62499999999991 31
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 72.91666666666657 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 72.91666666666657 59
Completed Iteration #8
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 51.04166666666659 23
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 55.20833333333325 26
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 55.20833333333325 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 67.70833333333324 32
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 74.9999999999999 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 74.9999999999999 60
Completed Iteration #9
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63da0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b38> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9128> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 56.249999999999915 27
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 56.249999999999915 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 68.74999999999991 33
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 76.04166666666657 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 76.04166666666657 61
Completed Iteration #10
Best Reward: 4.166666666666666
Completed Iteration #11
Best Reward: 4.166666666666666
Completed Iteration #12
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f786a0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f782b0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52fd0> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 5.208333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 58.33333333333324 28
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 58.33333333333324 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 70.83333333333324 34
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 78.1249999999999 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 78.1249999999999 62
Completed Iteration #13
Best Reward: 4.166666666666666
Completed Iteration #14
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f526a0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadc50> 22.916666666666643 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 24.99999999999997 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad4a8> 24.99999999999997 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 27.0833333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 53.12499999999992 24
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 60.41666666666657 29
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 60.41666666666657 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 72.91666666666657 35
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 80.20833333333323 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 80.20833333333323 63
Completed Iteration #15
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78cc0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b38> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9128> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 6.249999999999995 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 61.458333333333236 30
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 61.458333333333236 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 73.95833333333324 36
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 81.2499999999999 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 81.2499999999999 64
Completed Iteration #16
Best Reward: 4.166666666666666
Completed Iteration #17
Best Reward: 4.166666666666666
Completed Iteration #18
Best Reward: 4.166666666666666
Completed Iteration #19
Best Reward: 4.166666666666666
Completed Iteration #20
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadf60> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad4a8> 27.0833333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4417668> 29.16666666666663 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 55.20833333333325 25
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 63.541666666666565 31
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 63.541666666666565 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 76.04166666666657 37
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 83.33333333333323 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 83.33333333333323 65
Completed Iteration #21
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90dd8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad7f0> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52160> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba908> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 56.249999999999915 26
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 64.58333333333323 32
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 64.58333333333323 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 77.08333333333324 38
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 84.3749999999999 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 84.3749999999999 66
Completed Iteration #22
Best Reward: 4.166666666666666
Completed Iteration #23
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63f98> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f782b0> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52fd0> 4.1666666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 7.291666666666661 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 65.6249999999999 33
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 65.6249999999999 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 78.12499999999991 39
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 85.41666666666657 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 85.41666666666657 67
Completed Iteration #24
Best Reward: 4.166666666666666
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #4
root->2->19->2->11
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78208> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 58.33333333333324 27
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 67.70833333333323 34
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 67.70833333333323 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 80.20833333333324 40
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 87.4999999999999 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 87.4999999999999 68
Completed Iteration #0
Best Reward: 4.166666666666666
Completed Iteration #1
Best Reward: 4.166666666666666
Completed Iteration #2
Best Reward: 4.166666666666666
Completed Iteration #3
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78b70> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02390> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c50> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 60.41666666666657 28
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 69.79166666666656 35
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 69.79166666666656 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 82.29166666666657 41
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 89.58333333333323 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 89.58333333333323 69
Completed Iteration #4
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02518> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 62.4999999999999 29
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 71.87499999999989 36
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 71.87499999999989 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 84.3749999999999 42
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 91.66666666666656 54
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 91.66666666666656 70
Completed Iteration #5
Best Reward: 4.166666666666666
Completed Iteration #6
Best Reward: 4.166666666666666
Completed Iteration #7
Best Reward: 4.166666666666666
Completed Iteration #8
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 8.333333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 66.66666666666657 30
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 76.04166666666656 37
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 76.04166666666656 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 88.54166666666657 43
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 95.83333333333323 55
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 95.83333333333323 71
Completed Iteration #9
Best Reward: 4.166666666666666
Completed Iteration #10
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d4a8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d518> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78b70> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02390> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c50> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 67.70833333333324 31
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 77.08333333333323 38
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 77.08333333333323 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 89.58333333333324 44
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 96.8749999999999 56
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 96.8749999999999 72
Completed Iteration #11
Best Reward: 4.166666666666666
coverage_call_count 1500
Completed Iteration #12
Best Reward: 4.166666666666666
Completed Iteration #13
Best Reward: 4.166666666666666
Completed Iteration #14
Best Reward: 4.166666666666666
Completed Iteration #15
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de10> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d160> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 10.416666666666663 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 12.499999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 71.87499999999991 32
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 81.2499999999999 39
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 81.2499999999999 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 93.74999999999991 45
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 101.04166666666657 57
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 101.04166666666657 73
Completed Iteration #16
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f292e8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29128> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90dd8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417dd8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad7f0> 4.1666666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52160> 4.1666666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba908> 6.249999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 72.91666666666659 33
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 82.29166666666657 40
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 82.29166666666657 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 94.79166666666659 46
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 102.08333333333324 58
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 102.08333333333324 74
Completed Iteration #17
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f44724e0> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509470> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45092b0> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90fd0> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadd30> 7.2916666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba278> 7.2916666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa01d0> 18.749999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 76.04166666666659 34
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 85.41666666666657 41
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 85.41666666666657 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 97.91666666666659 47
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 105.20833333333324 59
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 105.20833333333324 75
Completed Iteration #18
Best Reward: 4.166666666666666
Completed Iteration #19
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba710> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78d68> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02518> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 78.12499999999991 35
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 87.4999999999999 42
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 87.4999999999999 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 99.99999999999991 48
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 107.29166666666657 60
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 107.29166666666657 76
Completed Iteration #20
Best Reward: 4.166666666666666
Completed Iteration #21
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02240> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d518> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78b70> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02390> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c50> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 80.20833333333324 36
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 89.58333333333323 43
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 89.58333333333323 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 102.08333333333324 49
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 109.3749999999999 61
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 109.3749999999999 77
Completed Iteration #22
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02c18> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02f28> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba908> 7.291666666666659 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 81.24999999999991 37
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 90.6249999999999 44
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 90.6249999999999 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 103.12499999999991 50
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 110.41666666666657 62
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 110.41666666666657 78
Completed Iteration #23
Best Reward: 4.166666666666666
Completed Iteration #24
Best Reward: 4.166666666666666
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #5
root->2->19->2->11->0
Best Reward: 4.166666666666666
Completed Iteration #0
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3f293c8> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de48> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 13.541666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 15.624999999999995 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 84.37499999999991 38
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 93.7499999999999 45
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 93.7499999999999 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 106.24999999999991 51
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 113.54166666666657 63
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 113.54166666666657 79
Completed Iteration #1
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dcc0> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de10> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d160> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 11.458333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 16.666666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 18.749999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 87.49999999999991 39
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 96.8749999999999 46
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 96.8749999999999 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 109.37499999999991 52
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 116.66666666666657 64
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 116.66666666666657 80
Completed Iteration #2
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63908> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f785c0> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f293c8> 6.2500000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de48> 6.2500000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 8.333333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 19.791666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 90.62499999999991 40
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 99.9999999999999 47
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 99.9999999999999 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 112.49999999999991 53
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 119.79166666666657 65
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 119.79166666666657 81
Completed Iteration #3
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f297f0> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 15.625 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 23.95833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 26.041666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 94.79166666666659 41
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 104.16666666666657 48
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 104.16666666666657 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 116.66666666666659 54
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 123.95833333333324 66
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 123.95833333333324 82
Completed Iteration #4
Best Reward: 4.166666666666666
Completed Iteration #5
Best Reward: 4.166666666666666
Completed Iteration #6
Best Reward: 4.166666666666666
Completed Iteration #7
Best Reward: 4.166666666666666
Completed Iteration #8
Best Reward: 4.166666666666666
Completed Iteration #9
Best Reward: 4.166666666666666
Completed Iteration #10
Best Reward: 4.166666666666666
Completed Iteration #11
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02208> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d0f0> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f297f0> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 18.75 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 27.08333333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 29.166666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 97.91666666666659 42
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 107.29166666666657 49
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 107.29166666666657 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 119.79166666666659 55
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 127.08333333333324 67
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 127.08333333333324 83
Completed Iteration #12
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52d30> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 10.41666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 21.875 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 30.20833333333333 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 32.291666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 101.04166666666659 43
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 110.41666666666657 50
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 110.41666666666657 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 122.91666666666659 56
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 130.20833333333326 68
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 130.20833333333326 84
Completed Iteration #13
Best Reward: 4.166666666666666
Completed Iteration #14
Best Reward: 4.166666666666666
Completed Iteration #15
Best Reward: 4.166666666666666
Completed Iteration #16
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29ac8> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b38> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52d30> 6.2500000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 13.541666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 25.0 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 33.33333333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 35.416666666666664 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 104.16666666666659 44
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 113.54166666666657 51
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 113.54166666666657 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 126.04166666666659 57
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 133.33333333333326 69
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 133.33333333333326 85
Completed Iteration #17
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29a58> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29f28> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63908> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f785c0> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f293c8> 10.41666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de48> 10.41666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 37.49999999999999 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 39.58333333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 108.33333333333326 45
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 117.70833333333324 52
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 117.70833333333324 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 130.20833333333326 58
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 137.49999999999991 70
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 137.49999999999991 86
Completed Iteration #18
Best Reward: 4.166666666666666
Completed Iteration #19
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca3c8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca438> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dcc0> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de10> 11.458333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d160> 11.458333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 29.166666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 41.66666666666666 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 43.74999999999999 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 112.49999999999993 46
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 121.87499999999991 53
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 121.87499999999991 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 134.37499999999991 59
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 141.66666666666657 71
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 141.66666666666657 87
Completed Iteration #20
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaa20> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d0f0> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f297f0> 11.458333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 17.708333333333336 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 33.33333333333333 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 45.83333333333332 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 47.91666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 116.6666666666666 47
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 126.04166666666659 54
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 126.04166666666659 54
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 138.54166666666657 60
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 145.83333333333323 72
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 145.83333333333323 88
Completed Iteration #21
Best Reward: 4.166666666666666
Completed Iteration #22
Best Reward: 4.166666666666666
Completed Iteration #23
Best Reward: 4.166666666666666
Completed Iteration #24
Best Reward: 4.166666666666666
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #6
root->2->19->2->11->0->19
Best Reward: 4.166666666666666
Completed Iteration #0
Best Reward: 4.166666666666666
Completed Iteration #1
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece9e8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece5f8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaa20> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d0f0> 11.458333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f297f0> 15.625 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 21.875 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 37.49999999999999 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 49.999999999999986 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 52.08333333333332 16
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 120.83333333333327 48
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 130.20833333333326 55
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 130.20833333333326 55
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 142.70833333333323 61
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 149.9999999999999 73
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 149.9999999999999 89
Completed Iteration #2
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3f637f0> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de48> 13.541666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 15.625000000000002 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 53.124999999999986 16
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 55.20833333333332 17
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 123.95833333333327 49
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 133.33333333333326 56
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 133.33333333333326 56
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 145.83333333333323 62
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 153.1249999999999 74
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 153.1249999999999 90
Completed Iteration #3
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 56.249999999999986 17
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 58.33333333333332 18
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 127.08333333333327 50
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 136.45833333333326 57
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 136.45833333333326 57
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 148.95833333333323 63
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 156.2499999999999 75
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 156.2499999999999 91
Completed Iteration #4
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29390> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29e48> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02208> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d0f0> 13.541666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f297f0> 17.70833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 23.95833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 39.58333333333332 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 58.333333333333314 18
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 60.41666666666665 19
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 129.1666666666666 51
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 138.5416666666666 58
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 138.5416666666666 58
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 151.04166666666657 64
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 158.33333333333323 76
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 158.33333333333323 92
Completed Iteration #5
Best Reward: 4.166666666666666
Completed Iteration #6
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca550> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece5c0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29ac8> 4.166666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b38> 4.166666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52d30> 7.29166666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 24.999999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 40.624999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 59.37499999999998 19
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 61.458333333333314 20
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 130.20833333333326 52
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 139.58333333333326 59
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 139.58333333333326 59
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 152.08333333333323 65
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 159.3749999999999 77
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 159.3749999999999 93
Completed Iteration #7
Best Reward: 4.166666666666666
Completed Iteration #8
Best Reward: 4.166666666666666
Completed Iteration #9
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca4a8> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca908> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca3c8> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca438> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dcc0> 10.41666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 10.41666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de10> 14.583333333333336 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d160> 14.583333333333336 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 43.749999999999986 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 62.49999999999998 20
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 64.58333333333331 21
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 133.33333333333326 53
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 142.70833333333326 60
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 142.70833333333326 60
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 155.20833333333323 66
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 162.4999999999999 78
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 162.4999999999999 94
Completed Iteration #10
Best Reward: 4.166666666666666
Completed Iteration #11
Best Reward: 4.166666666666666
Completed Iteration #12
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc128> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de48> 16.66666666666667 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 18.750000000000004 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 65.62499999999999 21
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 67.70833333333331 22
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 136.45833333333326 54
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 145.83333333333326 61
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 145.83333333333326 61
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 158.33333333333323 67
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 165.6249999999999 79
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 165.6249999999999 95
Completed Iteration #13
Best Reward: 4.166666666666666
Completed Iteration #14
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc7b8> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc828> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 67.70833333333331 22
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 69.79166666666664 23
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 138.5416666666666 55
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 147.9166666666666 62
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 147.9166666666666 62
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 160.41666666666657 68
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 167.70833333333323 80
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 167.70833333333323 96
Completed Iteration #15
Best Reward: 4.166666666666666
Completed Iteration #16
Best Reward: 4.166666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f10f3f299e8> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52cf8> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca550> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece5c0> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29ac8> 6.249999999999998 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b38> 6.249999999999998 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52d30> 9.375 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 27.08333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 45.833333333333314 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 69.79166666666664 23
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 71.87499999999997 24
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 140.62499999999994 56
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 149.99999999999994 63
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 149.99999999999994 63
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 162.49999999999991 69
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 169.79166666666657 81
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 169.79166666666657 97
Completed Iteration #17
Best Reward: 4.166666666666666
Completed Iteration #18
Best Reward: 4.166666666666666
Completed Iteration #19
Best Reward: 4.166666666666666
Completed Iteration #20
Best Reward: 4.166666666666666
Completed Iteration #21
Best Reward: 4.166666666666666
Completed Iteration #22
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece390> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc828> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 9.374999999999998 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 73.95833333333331 24
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 76.04166666666664 25
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 144.7916666666666 57
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 154.1666666666666 64
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 154.1666666666666 64
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 166.66666666666657 70
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 173.95833333333323 82
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 173.95833333333323 98
Completed Iteration #23
Best Reward: 4.166666666666666
Completed Iteration #24
Best Reward: 4.166666666666666
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #7
root->2->19->2->11->0->19->1
Best Reward: 4.166666666666666
Completed Iteration #0
Best Reward: 4.166666666666666
Completed Iteration #1
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc8d0> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcac8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece9e8> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece5f8> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaa20> 12.499999999999998 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d0f0> 17.70833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f297f0> 21.874999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 31.249999999999986 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 49.99999999999998 16
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 78.12499999999999 25
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 80.20833333333331 26
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 148.95833333333326 58
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 158.33333333333326 65
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 158.33333333333326 65
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 170.83333333333323 71
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 178.1249999999999 83
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 178.1249999999999 99
Completed Iteration #2
Best Reward: 4.166666666666666
Completed Iteration #3
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb358> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d160> 18.75 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 54.16666666666664 17
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 82.29166666666666 26
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 84.37499999999999 27
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 153.12499999999991 59
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 162.49999999999991 66
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 162.49999999999991 66
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 174.9999999999999 72
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 182.29166666666654 84
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 182.29166666666654 100
Completed Iteration #4
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb7b8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb5f8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb358> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d160> 22.916666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 58.33333333333331 18
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 86.45833333333333 27
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 88.54166666666666 28
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 157.29166666666657 60
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 166.66666666666657 67
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 166.66666666666657 67
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 179.16666666666654 73
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 186.4583333333332 85
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 186.4583333333332 101
Completed Iteration #5
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc160> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b38> 9.375 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52d30> 12.500000000000002 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 34.374999999999986 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 61.45833333333331 19
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 89.58333333333333 28
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 91.66666666666666 29
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 160.41666666666657 61
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 169.79166666666657 68
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 169.79166666666657 68
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 182.29166666666654 74
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 189.5833333333332 86
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 189.5833333333332 102
Completed Iteration #6
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb1d0> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbaef0> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca4a8> 6.2500000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca908> 6.2500000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca3c8> 10.41666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca438> 10.41666666666667 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dcc0> 13.541666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 13.541666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de10> 17.708333333333336 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d160> 26.041666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 64.58333333333331 20
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 92.70833333333333 29
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 94.79166666666666 30
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 163.54166666666657 62
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 172.91666666666657 69
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 172.91666666666657 69
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 185.41666666666654 75
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 192.7083333333332 87
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 192.7083333333332 103
Completed Iteration #7
Best Reward: 4.166666666666666
Completed Iteration #8
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6d8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d160> 30.20833333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 68.74999999999999 21
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 96.875 30
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 98.95833333333333 31
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 167.70833333333323 63
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 177.08333333333323 70
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 177.08333333333323 70
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 189.5833333333332 76
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 196.87499999999986 88
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 196.87499999999986 104
Completed Iteration #9
Best Reward: 4.166666666666666
Completed Iteration #10
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3edccc0> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29e48> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02208> 8.333333333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d0f0> 20.83333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f297f0> 24.999999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 37.499999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 71.87499999999999 22
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 100.0 31
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 102.08333333333333 32
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 170.83333333333323 64
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 180.20833333333323 71
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 180.20833333333323 71
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 192.7083333333332 77
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 199.99999999999986 89
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 199.99999999999986 105
Completed Iteration #11
Best Reward: 4.166666666666666
Completed Iteration #12
Best Reward: 4.166666666666666
Completed Iteration #13
Best Reward: 4.166666666666666
Completed Iteration #14
Best Reward: 4.166666666666666
Completed Iteration #15
Best Reward: 4.166666666666666
Completed Iteration #16
Best Reward: 4.166666666666666
Completed Iteration #17
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbac8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbbe0> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edccc0> 7.291666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29e48> 9.374999999999998 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02208> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d0f0> 24.999999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3f297f0> 29.166666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 41.66666666666665 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 76.04166666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 104.16666666666667 32
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 106.25 33
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 174.9999999999999 65
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 184.3749999999999 72
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 184.3749999999999 72
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 196.87499999999986 78
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 204.16666666666652 90
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 204.16666666666652 106
Completed Iteration #18
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90278> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca908> 9.375000000000005 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca3c8> 13.541666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca438> 13.541666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dcc0> 16.66666666666667 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 16.66666666666667 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de10> 20.833333333333336 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d160> 33.33333333333333 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 79.16666666666666 24
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 107.29166666666667 33
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 109.375 34
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 178.1249999999999 66
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 187.4999999999999 73
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 187.4999999999999 73
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 199.99999999999986 79
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 207.29166666666652 91
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 207.29166666666652 107
Completed Iteration #19
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90898> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e906d8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6d8> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d160> 37.49999999999999 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 83.33333333333333 25
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 111.45833333333334 34
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 113.54166666666667 35
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 182.29166666666654 67
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 191.66666666666654 74
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 191.66666666666654 74
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 204.16666666666652 80
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 211.45833333333317 92
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 211.45833333333317 108
Completed Iteration #20
Best Reward: 4.166666666666666
Completed Iteration #21
Best Reward: 4.166666666666666
Completed Iteration #22
Best Reward: 4.166666666666666
Completed Iteration #23
Best Reward: 4.166666666666666
Reward: 3.1250000000000018
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb2b0> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e907f0> 3.1250000000000018 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29390> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29e48> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02208> 15.625000000000002 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d0f0> 28.124999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3f297f0> 32.29166666666666 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb00> 44.79166666666665 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 86.45833333333333 26
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63240> 114.58333333333334 35
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 116.66666666666667 36
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90748> 185.41666666666654 68
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 194.79166666666654 75
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82518> 194.79166666666654 75
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 207.29166666666652 81
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd400> 214.58333333333317 93
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 214.58333333333317 109
Completed Iteration #24
Best Reward: 4.166666666666666
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #8
root->2->19->2->11->0->19->1->16
Best Reward: 4.166666666666666
iteration: 37
found coverage increase 4.166666666666666
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e909b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e909b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29898> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 6
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 8
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 9
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e905c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb978> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f295f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eceb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 1700
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f029b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f024e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f290f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecea90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecea90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece6a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e902b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f786d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f636a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fade48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa05c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f782b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f782b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecad68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ef0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 1.0416666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 1.0416666666666643 7
Completed Iteration #7
Best Reward: 1.0416666666666643
Completed Iteration #8
Best Reward: 1.0416666666666643
Completed Iteration #9
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f823c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 1.0416666666666643 8
Completed Iteration #10
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10f3f900f0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ef0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 2.0833333333333286 9
Completed Iteration #11
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9f28> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ef0> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 3.124999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 3.124999999999993 10
Completed Iteration #12
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 3.124999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 3.124999999999993 11
Completed Iteration #13
Best Reward: 1.0416666666666643
Completed Iteration #14
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 4.166666666666657 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 4.166666666666657 12
Completed Iteration #15
Best Reward: 1.0416666666666643
Completed Iteration #16
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 4.166666666666657 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 4.166666666666657 13
Completed Iteration #17
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 5.2083333333333215 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 5.2083333333333215 14
Completed Iteration #18
Best Reward: 1.0416666666666643
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 5.208333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 8.333333333333321 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 8.333333333333321 15
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 8.333333333333321 16
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #0
root
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ef0> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 9.374999999999986 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 9.374999999999986 17
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
coverage_call_count 1900
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4427748> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427278> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 6.249999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ef0> 7.291666666666657 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 12.499999999999986 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 12.499999999999986 18
Completed Iteration #7
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90dd8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 7.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 7.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 15.624999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 15.624999999999986 19
Completed Iteration #8
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 15.624999999999986 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 15.624999999999986 20
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaf60> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 16.66666666666665 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 16.66666666666665 21
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90898> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02a58> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaf60> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 17.708333333333314 16
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 17.708333333333314 22
Completed Iteration #18
Best Reward: 3.125
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78be0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78a58> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaf60> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 18.74999999999998 17
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 18.74999999999998 23
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecee48> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 21.87499999999998 18
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 21.87499999999998 24
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f3f637f0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52940> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ef0> 10.416666666666657 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 24.99999999999998 19
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 24.99999999999998 25
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #1
root->2
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb390> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 10.416666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 10.416666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 11.458333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 28.12499999999998 20
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 28.12499999999998 26
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4417b38> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 13.541666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 13.541666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 14.583333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 31.24999999999998 21
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 31.24999999999998 27
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f3f826d8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 16.666666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 16.666666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 17.70833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 34.37499999999998 22
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 34.37499999999998 28
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #2
root->2->5
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #3
root->2->5->8
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1438> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1e80> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb390> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 19.791666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 19.791666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 20.83333333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 37.49999999999998 23
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 37.49999999999998 29
Completed Iteration #3
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad128> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d898> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90dd8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 22.916666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 22.916666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 23.95833333333333 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 40.62499999999998 24
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 40.62499999999998 30
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9e80> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d898> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90dd8> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 26.041666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 26.041666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 27.08333333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 43.74999999999998 25
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 43.74999999999998 31
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f44e11d0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d898> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90dd8> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 29.166666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 29.166666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 30.20833333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 46.87499999999998 26
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 46.87499999999998 32
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4458208> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1e80> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb390> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 32.291666666666664 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 32.291666666666664 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 33.33333333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 49.99999999999998 27
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 49.99999999999998 33
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #4
root->2->5->8->26
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
coverage_call_count 2000
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdf98> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44378d0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417b38> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 34.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 35.416666666666664 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 35.416666666666664 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 36.45833333333333 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 53.12499999999998 28
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 53.12499999999998 34
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0f60> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc828> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f826d8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 37.5 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 38.541666666666664 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 38.541666666666664 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 39.58333333333333 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 56.24999999999998 29
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 56.24999999999998 35
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdcf8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d898> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90dd8> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 34.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 40.625 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 41.666666666666664 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 41.666666666666664 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 42.70833333333333 16
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 59.37499999999998 30
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 59.37499999999998 36
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4509940> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 43.75 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 44.791666666666664 16
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 44.791666666666664 16
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 45.83333333333333 17
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 62.49999999999998 31
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 62.49999999999998 37
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #5
root->2->5->8->26->2
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0d30> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f03c8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458208> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1e80> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb390> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 34.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 37.5 13
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 46.875 16
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 47.916666666666664 17
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 47.916666666666664 17
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 48.95833333333333 18
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 65.62499999999997 32
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 65.62499999999997 38
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd9e8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 37.5 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 40.625 14
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 50.0 17
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 51.041666666666664 18
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 51.041666666666664 18
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 52.08333333333333 19
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 68.74999999999997 33
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 68.74999999999997 39
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4519630> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0550> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad128> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d898> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90dd8> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 40.625 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 43.75 15
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 53.125 18
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 54.166666666666664 19
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 54.166666666666664 19
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 55.20833333333333 20
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 71.87499999999997 34
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 71.87499999999997 40
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #6
root->2->5->8->26->2->1
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0550> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529c50> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519630> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0550> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad128> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d898> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90dd8> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 43.75 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 46.875 16
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 56.25 19
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 57.291666666666664 20
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 57.291666666666664 20
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 58.33333333333333 21
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 74.99999999999997 35
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 74.99999999999997 41
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10eba55278> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1e80> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb390> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 46.875 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 50.0 17
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 59.375 20
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 60.416666666666664 21
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 60.416666666666664 21
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 61.45833333333333 22
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 78.12499999999997 36
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 78.12499999999997 42
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1e80> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb390> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 50.0 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 53.125 18
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 62.5 21
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 63.541666666666664 22
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 63.541666666666664 22
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 64.58333333333333 23
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 81.24999999999997 37
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 81.24999999999997 43
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #7
root->2->5->8->26->2->1->2
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e82022e8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d898> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90dd8> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4427780> 53.125 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4417748> 56.25 19
backprop <src.mcts.MCTS_Node object at 0x7f10f44177f0> 65.625 22
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 66.66666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 66.66666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc95f8> 67.70833333333333 24
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 84.37499999999997 38
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90668> 84.37499999999997 44
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #8
root->2->5->8->26->2->1->2->27
Best Reward: 3.125
iteration: 49
found coverage increase 3.125
Current Total Coverage 21.875
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f111c04b5c0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202828> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 1.0416666666666643 3
Completed Iteration #1
Best Reward: 1.0416666666666643
coverage_call_count 2100
Completed Iteration #2
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202828> 1.0416666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 1.0416666666666643 4
Completed Iteration #3
Best Reward: 1.0416666666666643
Completed Iteration #4
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5780> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202828> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 2.0833333333333286 5
Completed Iteration #5
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c03ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 2.0833333333333286 6
Completed Iteration #6
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82024e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 2.0833333333333286 7
Completed Iteration #7
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10eba3eb00> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202828> 3.124999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 3.124999999999993 8
Completed Iteration #8
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10e8202160> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202828> 4.166666666666657 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 4.166666666666657 9
Completed Iteration #9
Best Reward: 1.0416666666666643
Completed Iteration #10
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10e8182550> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182cf8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3eb00> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202828> 5.2083333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 5.2083333333333215 10
Completed Iteration #11
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f10e8182dd8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202828> 6.249999999999986 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 6.249999999999986 11
Completed Iteration #12
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1193740278> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f111c033b70> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202160> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202828> 7.29166666666665 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 7.29166666666665 12
Completed Iteration #13
Best Reward: 1.0416666666666643
Completed Iteration #14
Best Reward: 1.0416666666666643
Completed Iteration #15
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059978> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3eb00> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8202828> 8.333333333333314 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 8.333333333333314 13
Completed Iteration #16
Best Reward: 1.0416666666666643
Completed Iteration #17
Best Reward: 1.0416666666666643
Completed Iteration #18
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f11913d0eb8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202828> 9.374999999999979 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 9.374999999999979 14
Completed Iteration #19
Best Reward: 1.0416666666666643
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 12.499999999999979 15
Completed Iteration #20
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 15.624999999999979 16
Completed Iteration #21
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd3c8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 18.74999999999998 17
Completed Iteration #22
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6160> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddf98> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd3c8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 21.87499999999998 18
Completed Iteration #23
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a60b8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6160> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddf98> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd3c8> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 24.99999999999998 19
Completed Iteration #24
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 24.99999999999998 20
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #0
root
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0668> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 28.12499999999998 21
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f11dfacfe10> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 20.833333333333336 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 30.208333333333314 22
Completed Iteration #4
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 23.958333333333336 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 33.333333333333314 23
Completed Iteration #5
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f111c033dd8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059940> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0668> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 27.083333333333336 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 36.458333333333314 24
Completed Iteration #6
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 27.083333333333336 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 36.458333333333314 25
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 30.208333333333336 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 39.583333333333314 26
Completed Iteration #12
Best Reward: 3.125
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f10e8182be0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182240> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfacfe10> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 32.29166666666667 13
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 41.66666666666665 27
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f11913e20f0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 35.41666666666667 14
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 44.79166666666665 28
Completed Iteration #16
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 35.41666666666667 15
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 44.79166666666665 29
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81a67f0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b00> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f11913e20f0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 34.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 38.54166666666667 16
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 47.91666666666665 30
Completed Iteration #19
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8165908> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165780> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 34.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 37.5 13
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 41.66666666666667 17
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 51.04166666666665 31
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6240> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165550> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182be0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8182240> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f11dfacfe10> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 43.75000000000001 18
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 53.124999999999986 32
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f10e8165d30> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 45.83333333333334 19
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 55.20833333333332 33
Completed Iteration #24
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f111c02b128> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b048> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6240> 5.208333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165550> 5.208333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8182be0> 7.291666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8182240> 7.291666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7f11dfacfe10> 9.375000000000007 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 48.95833333333334 20
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 58.33333333333332 34
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #1
root->8
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f111c0470b8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fda58> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a67f0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b00> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f11913e20f0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 37.5 13
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 40.625 14
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 52.08333333333334 21
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 61.45833333333332 35
Completed Iteration #0
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfacfe48> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a60b8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6160> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddf98> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd3c8> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 40.625 14
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 43.75 15
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 55.20833333333334 22
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 64.58333333333331 36
Completed Iteration #1
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6978> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 43.75 15
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 46.875 16
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 58.33333333333334 23
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 67.70833333333331 37
Completed Iteration #2
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6d68> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 34.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 46.875 16
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 50.0 17
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 61.45833333333334 24
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 70.83333333333331 38
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8165a90> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 50.0 17
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 53.125 18
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 64.58333333333334 25
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 73.95833333333331 39
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81245f8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae2550> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6978> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 53.125 18
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 56.25 19
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 67.70833333333334 26
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 77.08333333333331 40
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f11dfae24a8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165f98> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 59.375 20
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 70.83333333333334 27
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 80.20833333333331 41
Completed Iteration #15
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff6a0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae2588> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f111c0470b8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fda58> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a67f0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b00> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f11913e20f0> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 56.25 19
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 62.5 21
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 73.95833333333334 28
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 83.33333333333331 42
Completed Iteration #16
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4afff60> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affda0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae24a8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165f98> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 65.625 22
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 77.08333333333334 29
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 86.45833333333331 43
Completed Iteration #17
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4afffd0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4afff60> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4affda0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f11dfae24a8> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8165f98> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 68.75 23
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 80.20833333333334 30
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 89.58333333333331 44
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b4e0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff198> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4afff60> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4affda0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f11dfae24a8> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8165f98> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 71.875 24
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 83.33333333333334 31
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 92.70833333333331 45
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bef0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165f98> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 75.0 25
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 86.45833333333334 32
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 95.83333333333331 46
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #2
root->8->18
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 34.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 37.5 13
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 59.375 20
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 78.125 26
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 89.58333333333334 33
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 98.95833333333331 47
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8202d30> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6cc0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165908> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165780> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 37.5 13
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 40.625 14
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 62.5 21
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 81.25 27
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 92.70833333333334 34
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 102.08333333333331 48
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8159b38> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 65.625 22
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 84.375 28
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 95.83333333333334 35
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 105.20833333333331 49
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8124a58> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affba8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165a90> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 68.75 23
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 87.5 29
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 98.95833333333334 36
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 108.33333333333331 50
Completed Iteration #13
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5630> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5da0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159b38> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 71.875 24
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 90.625 30
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 102.08333333333334 37
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 111.45833333333331 51
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5908> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 75.0 25
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 93.75 31
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 105.20833333333334 38
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 114.58333333333331 52
Completed Iteration #17
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1438> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae12b0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81245f8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f11dfae2550> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6978> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 78.125 26
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 96.875 32
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 108.33333333333334 39
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 117.70833333333331 53
Completed Iteration #18
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81b57b8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1be0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5908> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 81.25 27
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 100.0 33
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 111.45833333333334 40
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 120.83333333333331 54
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f11dfae2518> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159d30> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f111c033dd8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f111c059940> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0668> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 40.625 14
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 43.75 15
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 84.375 28
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 103.125 34
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 114.58333333333334 41
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 123.95833333333331 55
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81828d0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fda58> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a67f0> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b00> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f11913e20f0> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 87.5 29
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 106.25 35
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 117.70833333333334 42
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 127.08333333333331 56
Completed Iteration #24
Best Reward: 3.125
coverage_call_count 2200
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1ef0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae16a0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae2518> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159d30> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f111c033dd8> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f111c059940> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0668> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 43.75 15
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 46.875 16
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 90.625 30
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 109.375 36
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 120.83333333333334 43
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 130.20833333333331 57
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #3
root->8->18->4
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae17b8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae16a0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f11dfae2518> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8159d30> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f111c033dd8> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f111c059940> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0668> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 46.875 16
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 50.0 17
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 93.75 31
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 112.5 37
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 123.95833333333334 44
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 133.33333333333331 58
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29320> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f11dfacfe48> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a60b8> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6160> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddf98> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd3c8> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 50.0 17
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 53.125 18
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 96.875 32
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 115.625 38
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 127.08333333333334 45
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 136.45833333333331 59
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1908> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddf98> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd3c8> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 53.125 18
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 56.25 19
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 100.0 33
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 118.75 39
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 130.20833333333334 46
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 139.58333333333331 60
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81820f0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6d68> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 56.25 19
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 59.375 20
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 103.125 34
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 121.875 40
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 133.33333333333334 47
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 142.70833333333331 61
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92fd0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059940> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0668> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 59.375 20
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 62.5 21
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 106.25 35
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 125.0 41
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 136.45833333333334 48
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 145.83333333333331 62
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b927f0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92320> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81820f0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6d68> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 62.5 21
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 65.625 22
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 109.375 36
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 128.125 42
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 139.58333333333334 49
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 148.95833333333331 63
Completed Iteration #16
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8118978> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92a58> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 65.625 22
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 68.75 23
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 112.5 37
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 131.25 43
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 142.70833333333334 50
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 152.08333333333331 64
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1f28> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 68.75 23
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 71.875 24
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 115.625 38
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 134.375 44
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 145.83333333333334 51
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 155.20833333333331 65
Completed Iteration #20
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8118860> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92ba8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29320> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f11dfacfe48> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a60b8> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6160> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddf98> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd3c8> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 71.875 24
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 75.0 25
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 118.75 39
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 137.5 45
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 148.95833333333334 52
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 158.33333333333331 66
Completed Iteration #21
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8137cc0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202d30> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6cc0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165908> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8165780> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 75.0 25
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 78.125 26
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 121.875 40
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 140.625 46
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 152.08333333333334 53
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 161.45833333333331 67
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #4
root->8->18->4->4
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f11dfae27f0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159588> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1908> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddf98> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd3c8> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 78.125 26
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 81.25 27
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 125.0 41
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 143.75 47
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 155.20833333333334 54
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 164.58333333333331 68
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b927b8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165780> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 81.25 27
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 84.375 28
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 128.125 42
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 146.875 48
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 158.33333333333334 55
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 167.70833333333331 69
Completed Iteration #2
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81186d8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae16a0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f11dfae2518> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8159d30> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f111c033dd8> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f111c059940> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0668> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 84.375 28
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 87.5 29
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 131.25 43
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 150.0 49
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 161.45833333333334 56
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 170.83333333333331 70
Completed Iteration #3
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8137470> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 34.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 87.5 29
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 90.625 30
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 134.375 44
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 153.125 50
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 164.58333333333334 57
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 173.95833333333331 71
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b756a0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b757b8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118978> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92a58> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 90.625 30
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 93.75 31
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 137.5 45
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 156.25 51
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 167.70833333333334 58
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 177.08333333333331 72
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75668> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfacfe48> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81a60b8> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6160> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddf98> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd3c8> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 93.75 31
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 96.875 32
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 140.625 46
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 159.375 52
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 170.83333333333334 59
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 180.20833333333331 73
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b330f0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b757b8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118978> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92a58> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 96.875 32
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 100.0 33
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 143.75 47
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 162.5 53
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 173.95833333333334 60
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 183.33333333333331 74
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33e80> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059940> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0668> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 100.0 33
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 103.125 34
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 146.875 48
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 165.625 54
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 177.08333333333334 61
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 186.45833333333331 75
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8b70> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddf98> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd3c8> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 103.125 34
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 106.25 35
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 150.0 49
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 168.75 55
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 180.20833333333334 62
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 189.58333333333331 76
Completed Iteration #22
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8828> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8c50> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1ef0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae16a0> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f11dfae2518> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e8159d30> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f111c033dd8> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f111c059940> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0668> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 106.25 35
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 109.375 36
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 153.125 50
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 171.875 56
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 183.33333333333334 63
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 192.70833333333331 77
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #5
root->8->18->4->4->3
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81376a0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b927b8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165780> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 37.5 13
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 109.375 36
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 112.5 37
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 156.25 51
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 175.0 57
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 186.45833333333334 64
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 195.83333333333331 78
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8f60> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6d68> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 40.625 14
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 112.5 37
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 115.625 38
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 159.375 52
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 178.125 58
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 189.58333333333334 65
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 198.95833333333331 79
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e818d4e0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8a20> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137cc0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202d30> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6cc0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8165908> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8165780> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 43.75 15
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 115.625 38
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 118.75 39
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 162.5 53
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 181.25 59
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 192.70833333333334 66
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 202.08333333333331 80
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33320> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165780> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 46.875 16
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 118.75 39
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 121.875 40
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 165.625 54
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 184.375 60
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 195.83333333333334 67
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 205.20833333333331 81
Completed Iteration #15
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8438> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d2e8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33320> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165780> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 50.0 17
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 121.875 40
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 125.0 41
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 168.75 55
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 187.5 61
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 198.95833333333334 68
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 208.33333333333331 82
Completed Iteration #16
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fe48> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f710> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137470> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 53.125 18
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 125.0 41
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 128.125 42
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 171.875 56
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 190.625 62
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 202.08333333333334 69
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 211.45833333333331 83
Completed Iteration #17
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab908> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75128> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1f28> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 56.25 19
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 128.125 42
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 131.25 43
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 175.0 57
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 193.75 63
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 205.20833333333334 70
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 214.58333333333331 84
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4baba20> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab748> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8438> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e818d2e8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33320> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8165780> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 59.375 20
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 131.25 43
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 134.375 44
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 178.125 58
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 196.875 64
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 208.33333333333334 71
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 217.70833333333331 85
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e818d7f0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 62.5 21
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 134.375 44
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 137.5 45
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 181.25 59
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 200.0 65
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 211.45833333333334 72
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 220.83333333333331 86
Completed Iteration #24
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8320> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75ba8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fe48> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f710> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8137470> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 34.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 65.625 22
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 137.5 45
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 140.625 46
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 184.375 60
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 203.125 66
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 214.58333333333334 73
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 223.95833333333331 87
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #6
root->8->18->4->4->3->16
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92320> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81820f0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6d68> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 37.5 13
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 68.75 23
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 140.625 46
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 143.75 47
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 187.5 61
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 206.25 67
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 217.70833333333334 74
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 227.08333333333331 88
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab860> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75ba8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fe48> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f710> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8137470> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 40.625 14
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 71.875 24
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 143.75 47
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 146.875 48
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 190.625 62
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 209.375 68
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 220.83333333333334 75
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 230.20833333333331 89
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10cc0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62748> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d7f0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 43.75 15
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 75.0 25
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 146.875 48
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 150.0 49
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 193.75 63
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 212.5 69
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 223.95833333333334 76
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 233.33333333333331 90
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fc88> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62780> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10cc0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62748> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e818d7f0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 46.875 16
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 78.125 26
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 150.0 49
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 153.125 50
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 196.875 64
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 215.625 70
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 227.08333333333334 77
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 236.45833333333331 91
Completed Iteration #14
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75358> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62748> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e818d7f0> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 50.0 17
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 81.25 27
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 153.125 50
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 156.25 51
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 200.0 65
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 218.75 71
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 230.20833333333334 78
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 239.58333333333331 92
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1828> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10400> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fc88> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62780> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10cc0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba62748> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e818d7f0> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 53.125 18
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 84.375 28
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 156.25 51
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 159.375 52
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 203.125 66
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 221.875 72
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 233.33333333333334 79
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 242.70833333333331 93
Completed Iteration #22
Best Reward: 3.125
coverage_call_count 2300
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65cf8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75128> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1f28> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 56.25 19
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 87.5 29
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 159.375 52
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 162.5 53
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 206.25 67
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 225.0 73
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 236.45833333333334 80
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 245.83333333333331 94
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b102b0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f630> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8f60> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6d68> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 59.375 20
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 90.625 30
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 162.5 53
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 165.625 54
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 209.375 68
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 228.125 74
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 239.58333333333334 81
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 248.95833333333331 95
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #7
root->8->18->4->4->3->16->6
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65748> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92320> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81820f0> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 18.75 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6d68> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 62.5 21
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 93.75 31
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 165.625 54
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 168.75 55
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 212.5 69
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 231.25 75
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 242.70833333333334 82
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 252.08333333333331 96
Completed Iteration #2
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fcc0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65eb8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b927f0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92320> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81820f0> 15.625 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 21.875 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6d68> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 65.625 22
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 96.875 32
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 168.75 55
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 171.875 56
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 215.625 70
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 234.375 76
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 245.83333333333334 83
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 255.20833333333331 97
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3470> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b102b0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f630> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8f60> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 25.0 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6d68> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 68.75 23
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 100.0 33
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 171.875 56
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 175.0 57
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 218.75 71
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 237.5 77
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 248.95833333333334 84
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 258.3333333333333 98
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3278> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81434e0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3470> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f60> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b102b0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f630> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8f60> 12.5 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 28.125 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6d68> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 34.375 12
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 71.875 24
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 103.125 34
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 175.0 57
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 178.125 58
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 221.875 72
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 240.625 78
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 252.08333333333334 85
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 261.4583333333333 99
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd518> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 31.25 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b38> 34.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6d68> 34.375 12
backprop <src.mcts.MCTS_Node object at 0x7f10e8182e10> 37.5 13
backprop <src.mcts.MCTS_Node object at 0x7f11913d0e48> 75.0 25
backprop <src.mcts.MCTS_Node object at 0x7f10e82021d0> 106.25 35
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde10> 178.125 58
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddeb8> 181.25 59
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddc88> 225.0 73
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 243.75 79
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd128> 255.20833333333334 86
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5ac8> 264.5833333333333 100
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #8
root->8->18->4->4->3->16->6->19
Best Reward: 3.125
iteration: 50
found coverage increase 3.125
Current Total Coverage 25.0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4babf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4beef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 25.0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43e48> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 2.083333333333332 7
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 2.083333333333332 8
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 2.083333333333332 9
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1e80> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1b38> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43e48> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 4.166666666666664 10
Completed Iteration #11
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf208> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 5.208333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 5.208333333333332 11
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf4a8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1b38> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43e48> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 7.291666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 7.291666666666664 12
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf4a8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1b38> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43e48> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 7.291666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 7.291666666666664 13
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 7.291666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 7.291666666666664 14
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #0
root
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 9.374999999999996 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 9.374999999999996 15
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43fd0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e436d8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf208> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 10.416666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 10.416666666666664 16
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d68> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 12.499999999999996 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 12.499999999999996 17
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee160> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc50> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf208> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 13.541666666666664 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 13.541666666666664 18
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4babcc0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 14.583333333333332 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 14.583333333333332 19
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8118b00> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43208> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf4a8> 3.125 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1b38> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43e48> 7.291666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 15.625 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 15.625 20
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 7.291666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 17.708333333333332 16
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 17.708333333333332 21
Completed Iteration #17
Best Reward: 2.083333333333332
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 17.708333333333332 17
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 17.708333333333332 22
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d710> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43208> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf4a8> 4.166666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1b38> 6.25 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43e48> 8.333333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 18.75 18
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 18.75 23
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3de80> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43208> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf4a8> 6.25 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1b38> 8.333333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43e48> 10.416666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 20.833333333333332 19
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 20.833333333333332 24
Completed Iteration #23
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a1d0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1b38> 10.416666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43e48> 12.499999999999996 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 22.916666666666664 20
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 22.916666666666664 25
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #1
root->0
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a9b0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aa20> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4babcc0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 7.291666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 9.374999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 24.999999999999996 21
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 24.999999999999996 26
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aa58> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5f8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d68> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 9.374999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 11.458333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 27.08333333333333 22
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 27.08333333333333 27
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61128> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee7b8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a9b0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aa20> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4babcc0> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 10.416666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 12.499999999999996 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 28.124999999999996 23
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 28.124999999999996 28
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43438> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1ef0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 12.499999999999996 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 14.583333333333329 9
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 30.20833333333333 24
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 30.20833333333333 29
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffdd8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aa20> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4babcc0> 6.25 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 14.583333333333329 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 16.66666666666666 10
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 32.29166666666666 25
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 32.29166666666666 30
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee400> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeba8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d68> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 16.66666666666666 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 18.749999999999993 11
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 34.374999999999986 26
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 34.374999999999986 31
Completed Iteration #9
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 18.749999999999993 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 20.833333333333325 12
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 36.458333333333314 27
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 36.458333333333314 32
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a8d0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aa20> 7.291666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4babcc0> 8.333333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 20.833333333333325 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 22.916666666666657 13
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 38.54166666666664 28
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 38.54166666666664 33
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafa58> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a470> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43438> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1ef0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 22.916666666666657 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 24.99999999999999 14
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 40.62499999999997 29
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 40.62499999999997 34
Completed Iteration #19
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f617b8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 23.958333333333325 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 26.041666666666657 15
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 41.66666666666664 30
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 41.66666666666664 35
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75400> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 24.999999999999993 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 27.083333333333325 16
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 42.708333333333314 31
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 42.708333333333314 36
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #2
root->0->16
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61f28> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75518> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee400> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeba8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d68> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 27.083333333333325 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 29.166666666666657 17
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 44.79166666666664 32
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 44.79166666666664 37
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75828> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 28.124999999999993 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 30.208333333333325 18
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 45.833333333333314 33
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 45.833333333333314 38
Completed Iteration #1
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75a90> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6278> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61128> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee7b8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a9b0> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aa20> 8.333333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4babcc0> 9.375 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 29.16666666666666 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 31.249999999999993 19
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 46.874999999999986 34
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 46.874999999999986 39
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01240> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01048> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75828> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 30.20833333333333 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 32.29166666666666 20
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 47.91666666666666 35
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 47.91666666666666 40
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61390> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a470> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43438> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1ef0> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 9.374999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 31.249999999999996 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 33.33333333333333 21
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 48.95833333333333 36
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 48.95833333333333 41
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5ac88> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 11.458333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 33.33333333333333 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 35.41666666666666 22
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 51.04166666666666 37
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 51.04166666666666 42
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75470> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f758d0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafa58> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a470> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43438> 7.291666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1ef0> 7.291666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 13.54166666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 35.41666666666666 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 37.499999999999986 23
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 53.124999999999986 38
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 53.124999999999986 43
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75358> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 15.624999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 37.499999999999986 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 39.583333333333314 24
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 55.208333333333314 39
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 55.208333333333314 44
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75400> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 37.499999999999986 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 39.583333333333314 25
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 55.208333333333314 40
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 55.208333333333314 45
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01c88> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d0f0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61390> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a470> 6.25 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43438> 8.333333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1ef0> 8.333333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 16.66666666666666 10
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 38.54166666666666 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 40.624999999999986 26
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 56.249999999999986 41
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 56.249999999999986 46
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #3
root->0->16->8
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d940> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d9b0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5ac88> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 18.749999999999993 11
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 40.624999999999986 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 42.708333333333314 27
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 58.333333333333314 42
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 58.333333333333314 47
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1df28> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1dda0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43438> 10.416666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1ef0> 10.416666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 20.833333333333325 12
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 42.708333333333314 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 44.79166666666664 28
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 60.41666666666664 43
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 60.41666666666664 48
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25668> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25400> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75358> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 22.916666666666657 13
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 44.79166666666664 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 46.87499999999997 29
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 62.49999999999997 44
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 62.49999999999997 49
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a470> 6.25 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43438> 10.416666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1ef0> 10.416666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 22.916666666666657 14
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 44.79166666666664 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 46.87499999999997 30
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 62.49999999999997 45
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 62.49999999999997 50
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a4e0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5af60> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d940> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d9b0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5ac88> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 24.99999999999999 15
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 46.87499999999997 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 48.9583333333333 31
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 64.5833333333333 46
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 64.5833333333333 51
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25668> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25400> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75358> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 12.499999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 24.99999999999999 16
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 46.87499999999997 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 48.9583333333333 32
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 64.5833333333333 47
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 64.5833333333333 52
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25400> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75358> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 12.499999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 24.99999999999999 17
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 46.87499999999997 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 48.9583333333333 33
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 64.5833333333333 48
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 64.5833333333333 53
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1deb8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5af60> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d940> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d9b0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5ac88> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 14.583333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 27.08333333333332 18
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 48.9583333333333 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 51.04166666666663 34
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 66.66666666666663 49
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 66.66666666666663 54
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 10.41666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 14.583333333333325 11
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 27.08333333333332 19
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 48.9583333333333 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 51.04166666666663 35
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 66.66666666666663 50
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 66.66666666666663 55
Completed Iteration #23
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75470> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f758d0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafa58> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a470> 6.25 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43438> 10.416666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1ef0> 10.416666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 27.08333333333332 20
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 48.9583333333333 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 51.04166666666663 36
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 66.66666666666663 51
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 66.66666666666663 56
Completed Iteration #24
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d6d8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 12.499999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 16.666666666666657 12
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 29.166666666666654 21
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 51.04166666666663 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 53.12499999999996 37
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 68.74999999999996 52
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 68.74999999999996 57
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #4
root->0->16->8->29
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e8143ef0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1358> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25668> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25400> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75358> 6.2499999999999964 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 18.74999999999999 13
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 31.249999999999986 22
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 53.12499999999996 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 55.208333333333286 38
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 70.83333333333329 53
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 70.83333333333329 58
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f017b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1deb8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5af60> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d940> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d9b0> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5ac88> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 8.333333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 12.499999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 18.74999999999999 14
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 31.249999999999986 23
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 53.12499999999996 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 55.208333333333286 39
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 70.83333333333329 54
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 70.83333333333329 59
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25400> 4.166666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75358> 6.2499999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 18.74999999999999 15
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 31.249999999999986 24
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 53.12499999999996 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 55.208333333333286 40
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 70.83333333333329 55
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 70.83333333333329 60
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f755c0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 10.41666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 14.583333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 20.83333333333332 16
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 33.333333333333314 25
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 55.208333333333286 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 57.291666666666615 41
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 72.91666666666661 56
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 72.91666666666661 61
Completed Iteration #11
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5ada0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 22.916666666666654 17
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 35.41666666666664 26
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 57.291666666666615 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 59.37499999999994 42
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 74.99999999999994 57
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 74.99999999999994 62
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a0b8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 23.95833333333332 18
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 36.458333333333314 27
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 58.333333333333286 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 60.416666666666615 43
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 76.04166666666661 58
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 76.04166666666661 63
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
coverage_call_count 2500
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4a90> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4b00> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143ef0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1358> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25668> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25400> 6.2499999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75358> 8.333333333333329 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 26.041666666666654 19
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 38.54166666666664 28
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 60.416666666666615 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 62.49999999999994 44
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 78.12499999999994 59
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 78.12499999999994 64
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2390> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 27.08333333333332 20
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 39.583333333333314 29
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 61.458333333333286 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 63.541666666666615 45
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 79.16666666666661 60
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 79.16666666666661 65
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2a20> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed27b8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2390> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 28.12499999999999 21
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 40.624999999999986 30
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 62.49999999999996 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 64.58333333333329 46
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 80.20833333333329 61
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 80.20833333333329 66
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc198> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed27f0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2390> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 30.20833333333332 22
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 42.708333333333314 31
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 64.58333333333329 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 66.66666666666661 47
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 82.29166666666661 62
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 82.29166666666661 67
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #5
root->0->16->8->29->8
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d6d8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 14.583333333333325 11
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 30.20833333333332 23
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 42.708333333333314 32
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 64.58333333333329 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 66.66666666666661 48
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 82.29166666666661 63
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 82.29166666666661 68
Completed Iteration #1
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a278> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 16.666666666666657 12
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 32.29166666666666 24
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 44.79166666666664 33
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 66.66666666666661 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 68.74999999999994 49
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 84.37499999999994 64
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 84.37499999999994 69
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4ba8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4da0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f755c0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 11.458333333333329 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 17.708333333333325 13
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 33.33333333333333 25
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 45.833333333333314 34
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 67.70833333333329 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 69.79166666666661 50
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 85.41666666666661 65
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 85.41666666666661 70
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2518> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 19.791666666666657 14
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 35.41666666666666 26
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 47.91666666666664 35
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 69.79166666666661 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 71.87499999999994 51
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 87.49999999999994 66
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 87.49999999999994 71
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4ba8> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4da0> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f755c0> 3.125 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 11.458333333333329 10
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 19.791666666666657 15
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 35.41666666666666 27
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 47.91666666666664 36
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 69.79166666666661 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 71.87499999999994 52
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 87.49999999999994 67
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 87.49999999999994 72
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc668> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc6d8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2518> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 20.833333333333325 16
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 36.45833333333333 28
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 48.958333333333314 37
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 70.83333333333329 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 72.91666666666661 53
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 88.54166666666661 68
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 88.54166666666661 73
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f755c0> 3.125 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 11.458333333333329 11
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 20.833333333333325 17
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 36.45833333333333 29
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 48.958333333333314 38
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 70.83333333333329 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 72.91666666666661 54
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 88.54166666666661 69
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 88.54166666666661 74
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef13c8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1438> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4ba8> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4da0> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f755c0> 4.166666666666668 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 12.499999999999996 12
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 21.874999999999993 18
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 37.5 30
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 49.999999999999986 39
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 71.87499999999996 54
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 73.95833333333329 55
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 89.58333333333329 70
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 89.58333333333329 75
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1978> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4da0> 4.166666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f755c0> 6.25 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 14.583333333333329 13
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 23.958333333333325 19
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 39.58333333333333 31
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 52.083333333333314 40
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 73.95833333333329 55
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 76.04166666666661 56
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 91.66666666666661 71
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 91.66666666666661 76
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2400> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2ba8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d6d8> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 26.041666666666657 20
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 41.66666666666666 32
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 54.16666666666664 41
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 76.04166666666661 56
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 78.12499999999994 57
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 93.74999999999994 72
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 93.74999999999994 77
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #6
root->0->16->8->29->8->11
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1edccc0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edca58> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a278> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 6.25 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 27.083333333333325 21
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 42.70833333333333 33
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 55.208333333333314 42
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 77.08333333333329 57
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 79.16666666666661 58
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 94.79166666666661 73
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 94.79166666666661 78
Completed Iteration #1
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc668> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc6d8> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2518> 3.125 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 6.25 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 27.083333333333325 22
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 42.70833333333333 34
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 55.208333333333314 43
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 77.08333333333329 58
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 79.16666666666661 59
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 94.79166666666661 74
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 94.79166666666661 79
Completed Iteration #2
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25c18> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edca58> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a278> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 7.291666666666668 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 28.124999999999993 23
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 43.75 35
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 56.249999999999986 44
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 78.12499999999996 59
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 80.20833333333329 60
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 95.83333333333329 75
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 95.83333333333329 80
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25c18> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1edca58> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a278> 4.166666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 7.291666666666668 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 28.124999999999993 24
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 43.75 36
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 56.249999999999986 45
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 78.12499999999996 60
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 80.20833333333329 61
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 95.83333333333329 76
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 95.83333333333329 81
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b358> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b3c8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a278> 5.208333333333336 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 8.333333333333336 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 29.16666666666666 25
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 44.79166666666667 37
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 57.29166666666666 46
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 79.16666666666663 61
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 81.24999999999996 62
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 96.87499999999996 77
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 96.87499999999996 82
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bf60> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc6d8> 3.125 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2518> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 10.416666666666668 10
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 31.249999999999993 26
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 46.875 38
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 59.374999999999986 47
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 81.24999999999996 62
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 83.33333333333329 63
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 98.95833333333329 78
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 98.95833333333329 83
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96748> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e967b8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc668> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc6d8> 4.166666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2518> 6.25 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 11.458333333333336 11
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 32.29166666666666 27
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 47.91666666666667 39
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 60.41666666666666 48
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 82.29166666666663 63
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 84.37499999999996 64
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 99.99999999999996 79
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 99.99999999999996 84
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edccc0> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1edca58> 2.0833333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a278> 5.208333333333336 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 11.458333333333336 12
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 32.29166666666666 28
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 47.91666666666667 40
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 60.41666666666666 49
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 82.29166666666663 64
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 84.37499999999996 65
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 99.99999999999996 80
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 99.99999999999996 85
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc908> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc6d8> 5.208333333333336 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2518> 7.291666666666668 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 12.500000000000004 13
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 33.33333333333333 29
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 48.95833333333334 41
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 61.45833333333333 50
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 83.3333333333333 65
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 85.41666666666663 66
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 101.04166666666663 81
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 101.04166666666663 86
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b1d0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 14.583333333333336 14
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 35.41666666666666 30
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 51.04166666666667 42
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 63.54166666666666 51
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 85.41666666666663 66
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 87.49999999999996 67
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 103.12499999999996 82
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 103.12499999999996 87
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #7
root->0->16->8->29->8->11->3
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc6d8> 5.208333333333336 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2518> 7.291666666666668 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 14.583333333333336 15
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 35.41666666666666 31
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 51.04166666666667 43
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 63.54166666666666 52
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 85.41666666666663 67
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 87.49999999999996 68
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 103.12499999999996 83
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 103.12499999999996 88
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2518> 7.291666666666668 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 14.583333333333336 16
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 35.41666666666666 32
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 51.04166666666667 44
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 63.54166666666666 53
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 85.41666666666663 68
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 87.49999999999996 69
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 103.12499999999996 84
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 103.12499999999996 89
Completed Iteration #11
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3c18> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3a58> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc908> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc6d8> 6.2500000000000036 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2518> 8.333333333333336 10
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 15.625000000000004 17
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 36.45833333333333 33
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 52.08333333333334 45
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 64.58333333333333 54
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 86.4583333333333 69
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 88.54166666666663 70
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 104.16666666666663 85
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 104.16666666666663 90
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96ef0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3668> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2518> 10.416666666666668 11
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 17.708333333333336 18
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 38.54166666666666 34
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 54.16666666666667 46
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 66.66666666666666 55
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 88.54166666666663 70
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 90.62499999999996 71
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 106.24999999999996 86
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 106.24999999999996 91
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96668> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3668> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2518> 12.5 12
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 19.791666666666668 19
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 40.624999999999986 35
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5c0> 56.25 47
backprop <src.mcts.MCTS_Node object at 0x7f10e1faff98> 68.74999999999999 56
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 90.62499999999996 71
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 92.70833333333329 72
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439b0> 108.33333333333329 87
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 108.33333333333329 92
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #8
root->0->16->8->29->8->11->3->16
Best Reward: 2.083333333333332
iteration: 52
found coverage increase 2.083333333333332
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 27.083333333333332
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e692e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e692e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 27.083333333333332
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bceba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e699e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69630> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1c50> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f015f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f011d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f015f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 2700
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f015f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f015f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4beef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f619e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bceb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f015f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be39e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be39e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be39e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be39e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 27.083333333333332
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e439e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 27.083333333333332
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dc88> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 27.083333333333332
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f010b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f014e0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01fd0> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 1.0416666666666679 3
Completed Iteration #1
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee400> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 2.0833333333333357 4
Completed Iteration #2
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3e48> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3780> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f014e0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01fd0> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 3.1250000000000036 5
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e818de48> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3780> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f014e0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01fd0> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 4.166666666666671 6
Completed Iteration #5
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01fd0> 4.166666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 5.208333333333339 7
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01fd0> 4.166666666666671 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 5.208333333333339 8
Completed Iteration #10
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f28> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01fd0> 5.208333333333339 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 6.250000000000007 9
Completed Iteration #11
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1e80> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 7.291666666666675 10
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 7.291666666666675 11
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01fd0> 5.208333333333339 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 7.291666666666675 12
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e818de10> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 8.333333333333343 13
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 8.333333333333343 14
Completed Iteration #22
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee6a0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 9.37500000000001 15
Completed Iteration #23
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 10.416666666666679 16
Completed Iteration #24
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 10.416666666666679 17
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab550> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab160> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee400> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 11.458333333333346 18
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1438> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab160> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee400> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 12.500000000000014 19
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1438> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1a58> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee6a0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 13.541666666666682 20
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 14.58333333333335 21
Completed Iteration #10
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 9.37500000000001 11
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 14.58333333333335 22
Completed Iteration #11
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8159390> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab160> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee400> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 10.416666666666679 12
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 15.625000000000018 23
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b2b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1630> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 11.458333333333346 13
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 16.666666666666686 24
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 12.500000000000014 14
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 17.708333333333353 25
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5d30> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1a58> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee6a0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 13.541666666666682 15
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 18.75000000000002 26
Completed Iteration #17
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10ac8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e10> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b2b0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1630> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 14.58333333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 19.79166666666669 27
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 14.58333333333335 17
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 19.79166666666669 28
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65da0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818de10> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 15.625000000000018 18
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 20.833333333333357 29
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #1
root->3
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f11dfae28d0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1630> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 16.666666666666686 19
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 21.875000000000025 30
Completed Iteration #2
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1da0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 17.708333333333353 20
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 22.916666666666693 31
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d240> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d9b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1da0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 18.75000000000002 21
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 23.95833333333336 32
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a7f0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 19.79166666666669 22
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 25.00000000000003 33
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10470> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 20.833333333333357 23
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 26.041666666666696 34
Completed Iteration #17
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5b00> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d9b0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1da0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 10.416666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 21.875000000000025 24
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 27.083333333333364 35
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab518> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b7b8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a7f0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 11.458333333333346 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 22.916666666666693 25
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 28.125000000000032 36
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1e10> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1198> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae28d0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1630> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 12.500000000000014 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 23.95833333333336 26
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 29.1666666666667 37
Completed Iteration #23
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b7b8> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a7f0> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 12.500000000000014 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 23.95833333333336 27
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 29.1666666666667 38
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #2
root->3->3
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 13.541666666666682 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 25.00000000000003 28
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 30.208333333333368 39
Completed Iteration #0
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81432b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 14.58333333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 26.041666666666696 29
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 31.250000000000036 40
Completed Iteration #1
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81180b8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 15.625000000000018 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 27.083333333333364 30
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 32.2916666666667 41
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 5.208333333333339 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 7.291666666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 15.625000000000018 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 27.083333333333364 31
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 32.2916666666667 42
Completed Iteration #5
Best Reward: 1.0416666666666679
coverage_call_count 2900
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5400> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab2e8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81180b8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 8.333333333333343 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 16.666666666666686 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 28.125000000000032 32
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 33.33333333333337 43
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10940> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5588> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 6.250000000000007 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 9.37500000000001 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 17.708333333333353 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 29.1666666666667 33
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 34.37500000000004 44
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10eba620b8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 10.416666666666679 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 18.75000000000002 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 30.208333333333368 34
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 35.416666666666714 45
Completed Iteration #13
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba620b8> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 10.416666666666679 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 18.75000000000002 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 30.208333333333368 35
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 35.416666666666714 46
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8143358> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1c88> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81432b0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 11.458333333333346 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 19.79166666666669 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 31.250000000000036 36
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 36.458333333333385 47
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd588> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 12.500000000000014 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 20.833333333333357 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 32.2916666666667 37
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 37.50000000000006 48
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b650b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba620b8> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 12.500000000000014 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 20.833333333333357 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 32.2916666666667 38
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 37.50000000000006 49
Completed Iteration #24
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8137710> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81376d8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10940> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5588> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 7.291666666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 13.541666666666682 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 21.875000000000025 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 33.33333333333337 39
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 38.54166666666673 50
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #3
root->3->3->0
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81376d8> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10940> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5588> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 7.291666666666675 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 13.541666666666682 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 21.875000000000025 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 33.33333333333337 40
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 38.54166666666673 51
Completed Iteration #0
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f11dfacfe10> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5588> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 8.333333333333343 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 14.58333333333335 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 22.916666666666693 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 34.37500000000004 41
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 39.5833333333334 52
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d9b0> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1da0> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 4.166666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 8.333333333333343 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 14.58333333333335 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 22.916666666666693 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 34.37500000000004 42
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 39.5833333333334 53
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61128> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5588> 4.166666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 9.37500000000001 13
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 15.625000000000018 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 23.95833333333336 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 35.416666666666714 43
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 40.62500000000007 54
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65cc0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d240> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d9b0> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1da0> 4.166666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 5.208333333333339 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 10.416666666666679 14
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 16.666666666666686 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 25.00000000000003 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 36.458333333333385 44
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 41.66666666666674 55
Completed Iteration #9
Best Reward: 1.0416666666666679
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf98> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 6.250000000000007 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 11.458333333333346 15
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 17.708333333333353 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 26.041666666666696 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 37.50000000000006 45
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 42.708333333333414 56
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1278> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fc50> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1da0> 5.208333333333339 7
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 7.291666666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 12.500000000000014 16
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 18.75000000000002 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 27.083333333333364 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 38.54166666666673 46
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 43.750000000000085 57
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddd30> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f320> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 13.541666666666682 17
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 19.79166666666669 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 28.125000000000032 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 39.5833333333334 47
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 44.79166666666676 58
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33b38> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33ac8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddd30> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f320> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 14.58333333333335 18
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 20.833333333333357 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 29.1666666666667 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 40.62500000000007 48
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 45.83333333333343 59
Completed Iteration #21
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33c18> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33ac8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddd30> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f320> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 15.625000000000018 19
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 21.875000000000025 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 30.208333333333368 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 41.66666666666674 49
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 46.8750000000001 60
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137710> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81376d8> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10940> 2.0833333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5588> 4.166666666666671 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 15.625000000000018 20
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 21.875000000000025 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 30.208333333333368 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 41.66666666666674 50
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 46.8750000000001 61
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #4
root->3->3->0->18
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8137080> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33630> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1da0> 6.250000000000007 8
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 8.333333333333343 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 16.666666666666686 21
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 22.916666666666693 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 31.250000000000036 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 42.708333333333414 51
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 47.91666666666677 62
Completed Iteration #0
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae86d8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 9.37500000000001 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 17.708333333333353 22
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 23.95833333333336 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 32.2916666666667 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 43.750000000000085 52
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 48.95833333333344 63
Completed Iteration #1
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f111c02b1d0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61cc0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf98> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 10.416666666666679 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 18.75000000000002 23
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 25.00000000000003 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 33.33333333333337 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 44.79166666666676 53
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 50.000000000000114 64
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1278> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fc50> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1da0> 6.250000000000007 9
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 10.416666666666679 13
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 18.75000000000002 24
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 25.00000000000003 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 33.33333333333337 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 44.79166666666676 54
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 50.000000000000114 65
Completed Iteration #4
Best Reward: 1.0416666666666679
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92978> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bac8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65cc0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d240> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d9b0> 4.166666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1da0> 7.291666666666675 10
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 11.458333333333346 14
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 19.79166666666669 25
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 26.041666666666696 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 34.37500000000004 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 45.83333333333343 55
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 51.041666666666785 66
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8137860> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33630> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1da0> 8.333333333333343 11
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 12.500000000000014 15
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 20.833333333333357 26
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 27.083333333333364 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 35.416666666666714 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 46.8750000000001 56
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 52.08333333333346 67
Completed Iteration #10
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae86d8> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 12.500000000000014 16
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 20.833333333333357 27
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 27.083333333333364 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 35.416666666666714 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 46.8750000000001 57
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 52.08333333333346 68
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d9b0> 4.166666666666671 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1da0> 8.333333333333343 12
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 12.500000000000014 17
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 20.833333333333357 28
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 27.083333333333364 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 35.416666666666714 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 46.8750000000001 58
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 52.08333333333346 69
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8c18> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 13.541666666666682 18
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 21.875000000000025 29
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 28.125000000000032 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 36.458333333333385 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 47.91666666666677 59
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 53.12500000000013 70
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff278> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affd30> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf98> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 14.58333333333335 19
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 22.916666666666693 30
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 29.1666666666667 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 37.50000000000006 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 48.95833333333344 60
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 54.1666666666668 71
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #5
root->3->3->0->18->6
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4b331d0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 15.625000000000018 20
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 23.95833333333336 31
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 30.208333333333368 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 38.54166666666673 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 50.000000000000114 61
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 55.20833333333347 72
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 16.666666666666686 21
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 25.00000000000003 32
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 31.250000000000036 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 39.5833333333334 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 51.041666666666785 62
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 56.25000000000014 73
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae85f8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8128> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 17.708333333333353 22
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 26.041666666666696 33
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 32.2916666666667 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 40.62500000000007 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 52.08333333333346 63
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 57.29166666666681 74
Completed Iteration #12
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fb00> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 18.75000000000002 23
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 27.083333333333364 34
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 33.33333333333337 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 41.66666666666674 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 53.12500000000013 64
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 58.333333333333485 75
Completed Iteration #13
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8160> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd7f0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 19.79166666666669 24
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 28.125000000000032 35
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 34.37500000000004 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 42.708333333333414 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 54.1666666666668 65
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 59.375000000000156 76
Completed Iteration #14
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92668> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75128> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 10.416666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 20.833333333333357 25
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 29.1666666666667 36
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 35.416666666666714 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 43.750000000000085 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 55.20833333333347 66
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 60.41666666666683 77
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8165518> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd7f0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 11.458333333333346 12
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 21.875000000000025 26
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 30.208333333333368 37
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 36.458333333333385 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 44.79166666666676 54
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 56.25000000000014 67
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 61.4583333333335 78
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6b00> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 12.500000000000014 13
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 22.916666666666693 27
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 31.250000000000036 38
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 37.50000000000006 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 45.83333333333343 55
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 57.29166666666681 68
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 62.50000000000017 79
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6978> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f111c033ba8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92668> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75128> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 13.541666666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 23.95833333333336 28
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 32.2916666666667 39
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 38.54166666666673 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 46.8750000000001 56
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 58.333333333333485 69
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 63.54166666666684 80
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8182748> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b751d0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b1d0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61cc0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf98> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 14.58333333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 25.00000000000003 29
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 33.33333333333337 40
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 39.5833333333334 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 47.91666666666677 57
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 59.375000000000156 70
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 64.58333333333351 81
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #6
root->3->3->0->18->6->18
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8143828> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affd30> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf98> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 10.416666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 15.625000000000018 16
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 26.041666666666696 30
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 34.37500000000004 41
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 40.62500000000007 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 48.95833333333344 58
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 60.41666666666683 71
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 65.62500000000018 82
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4affeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b657f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fb00> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 10.416666666666679 12
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 15.625000000000018 17
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 26.041666666666696 31
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 34.37500000000004 42
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 40.62500000000007 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 48.95833333333344 59
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 60.41666666666683 72
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 65.62500000000018 83
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
coverage_call_count 3000
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8137f60> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75e10> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf98> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 11.458333333333346 13
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 16.666666666666686 18
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 27.083333333333364 32
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 35.416666666666714 43
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 41.66666666666674 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 50.000000000000114 60
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 61.4583333333335 73
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 66.66666666666686 84
Completed Iteration #4
Best Reward: 1.0416666666666679
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6f98> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f0f0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf98> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 12.500000000000014 14
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 17.708333333333353 19
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 28.125000000000032 33
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 36.458333333333385 44
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 42.708333333333414 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 51.041666666666785 61
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 62.50000000000017 74
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 67.70833333333353 85
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8182588> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81659b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae85f8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8128> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 13.541666666666682 15
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 18.75000000000002 20
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 29.1666666666667 34
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 37.50000000000006 45
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 43.750000000000085 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 52.08333333333346 62
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 63.54166666666684 75
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 68.7500000000002 86
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8182390> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 14.58333333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 19.79166666666669 21
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 30.208333333333368 35
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 38.54166666666673 46
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 44.79166666666676 54
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 53.12500000000013 63
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 64.58333333333351 76
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 69.79166666666687 87
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8182668> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059780> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8137f60> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75e10> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf98> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 15.625000000000018 17
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 20.833333333333357 22
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 31.250000000000036 36
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 39.5833333333334 47
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 45.83333333333343 55
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 54.1666666666668 64
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 65.62500000000018 77
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 70.83333333333354 88
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143828> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4affd30> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf98> 8.333333333333343 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 15.625000000000018 18
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 20.833333333333357 23
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 31.250000000000036 37
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 39.5833333333334 48
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 45.83333333333343 56
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 54.1666666666668 65
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 65.62500000000018 78
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 70.83333333333354 89
Completed Iteration #17
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8124a58> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81659b0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae85f8> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8128> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 16.666666666666686 19
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 21.875000000000025 24
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 32.2916666666667 38
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 40.62500000000007 49
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 46.8750000000001 57
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 55.20833333333347 66
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 66.66666666666686 79
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 71.87500000000021 90
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #7
root->3->3->0->18->6->18->2
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6f60> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6da0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae85f8> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8128> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 17.708333333333353 20
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 22.916666666666693 25
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 33.33333333333337 39
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 41.66666666666674 50
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 47.91666666666677 58
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 56.25000000000014 67
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 67.70833333333353 80
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 72.91666666666688 91
Completed Iteration #1
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5da0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5470> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6f60> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6da0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae85f8> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8128> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 18.75000000000002 21
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 23.95833333333336 26
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 34.37500000000004 40
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 42.708333333333414 51
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 48.95833333333344 59
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 57.29166666666681 68
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 68.7500000000002 81
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 73.95833333333356 92
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8182710> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8128> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 19.79166666666669 22
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 25.00000000000003 27
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 35.416666666666714 41
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 43.750000000000085 52
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 50.000000000000114 60
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 58.333333333333485 69
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 69.79166666666687 82
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 75.00000000000023 93
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8202ba8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6da0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae85f8> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8128> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 20.833333333333357 23
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 26.041666666666696 28
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 36.458333333333385 42
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 44.79166666666676 53
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 51.041666666666785 61
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 59.375000000000156 70
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 70.83333333333354 83
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 76.0416666666669 94
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8128> 7.291666666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 8.333333333333343 10
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 20.833333333333357 24
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 26.041666666666696 29
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 36.458333333333385 43
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 44.79166666666676 54
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 51.041666666666785 62
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 59.375000000000156 71
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 70.83333333333354 84
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 76.0416666666669 95
Completed Iteration #8
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f45299e8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529e10> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 9.37500000000001 11
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 21.875000000000025 25
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 27.083333333333364 30
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 37.50000000000006 44
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 45.83333333333343 55
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 52.08333333333346 63
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 60.41666666666683 72
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 71.87500000000021 85
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 77.08333333333357 96
Completed Iteration #9
Best Reward: 1.0416666666666679
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8128> 8.333333333333343 10
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 10.416666666666679 12
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 22.916666666666693 26
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 28.125000000000032 31
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 38.54166666666673 45
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 46.8750000000001 56
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 53.12500000000013 64
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 61.4583333333335 73
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 72.91666666666688 86
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 78.12500000000024 97
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202cf8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f111c033c18> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8128> 9.37500000000001 11
backprop <src.mcts.MCTS_Node object at 0x7f10e8124da0> 11.458333333333346 13
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 23.95833333333336 27
backprop <src.mcts.MCTS_Node object at 0x7f10e8118940> 29.1666666666667 32
backprop <src.mcts.MCTS_Node object at 0x7f10eba62b70> 39.5833333333334 46
backprop <src.mcts.MCTS_Node object at 0x7f10e81b50f0> 47.91666666666677 57
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5e48> 54.1666666666668 65
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 62.50000000000017 74
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeda0> 73.95833333333356 87
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 79.16666666666691 98
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #8
root->3->3->0->18->6->18->2->11
Best Reward: 1.0416666666666679
iteration: 62
found coverage increase 1.0416666666666679
Current Total Coverage 28.125
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c059be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820d860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 28.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c033fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c04b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01780> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 28.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 28.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c04b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 28.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 3
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 4
Completed Iteration #3
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 5
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 6
Completed Iteration #5
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 1.0416666666666679 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 7
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 8
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 1.0416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 9
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 10
Completed Iteration #12
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 11
Completed Iteration #13
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 1.0416666666666679 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 12
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44372e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 13
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 1.0416666666666679 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 14
Completed Iteration #19
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44372e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 15
Completed Iteration #20
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 16
Completed Iteration #21
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 17
Completed Iteration #22
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 18
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 1.0416666666666679 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 1.0416666666666679 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 1.0416666666666679 19
Completed Iteration #0
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e80f09b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c18> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 2.0833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 2.0833333333333357 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 2.0833333333333357 20
Completed Iteration #1
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c18> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 2.0833333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 2.0833333333333357 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 2.0833333333333357 21
Completed Iteration #2
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f09b0> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c18> 1.0416666666666679 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 2.0833333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 2.0833333333333357 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 2.0833333333333357 22
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 2.0833333333333357 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 2.0833333333333357 23
Completed Iteration #5
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 2.0833333333333357 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 2.0833333333333357 24
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c047a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 2.0833333333333357 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 2.0833333333333357 25
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c18> 1.0416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 2.0833333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 2.0833333333333357 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 2.0833333333333357 26
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 2.0833333333333357 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 2.0833333333333357 27
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 2.0833333333333357 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 2.0833333333333357 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 2.0833333333333357 28
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #1
root->1
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c18> 1.0416666666666679 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 2.0833333333333357 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 2.0833333333333357 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 2.0833333333333357 29
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
coverage_call_count 3200
Completed Iteration #3
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 2.0833333333333357 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 2.0833333333333357 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 2.0833333333333357 30
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0f28> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 3.1250000000000036 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 3.1250000000000036 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 3.1250000000000036 31
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 4.166666666666671 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 4.166666666666671 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 4.166666666666671 32
Completed Iteration #7
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0f28> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 4.166666666666671 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 4.166666666666671 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 4.166666666666671 33
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 4.166666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 6.2500000000000036 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 6.2500000000000036 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 6.2500000000000036 34
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33898> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 5.208333333333336 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 7.291666666666671 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 7.291666666666671 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 7.291666666666671 35
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 5.208333333333336 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 7.291666666666671 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 7.291666666666671 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 7.291666666666671 36
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 5.208333333333336 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 6.2500000000000036 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 8.33333333333334 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 8.33333333333334 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 8.33333333333334 37
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82b38> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c18> 2.0833333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 9.375000000000007 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 9.375000000000007 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 9.375000000000007 38
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #2
root->1->2
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9e80> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 6.25 5
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 7.291666666666668 6
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 8.333333333333336 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 11.45833333333334 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 11.45833333333334 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 11.45833333333334 39
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ba8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9390> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9e80> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 8.333333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 9.375 7
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 10.416666666666668 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 13.541666666666671 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 13.541666666666671 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 13.541666666666671 40
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 8.333333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 9.375 8
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 10.416666666666668 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 13.541666666666671 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 13.541666666666671 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 13.541666666666671 41
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9e80> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 8.333333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 9.375 9
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 10.416666666666668 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 13.541666666666671 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 13.541666666666671 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 13.541666666666671 42
Completed Iteration #5
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0f28> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 10.416666666666668 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 13.541666666666671 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 13.541666666666671 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 13.541666666666671 43
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10eba55940> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 11.458333333333336 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 14.58333333333334 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 14.58333333333334 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 14.58333333333334 44
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55940> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 11.458333333333336 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 14.58333333333334 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 14.58333333333334 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 14.58333333333334 45
Completed Iteration #9
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0f28> 1.0416666666666679 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 11.458333333333336 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 14.58333333333334 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 14.58333333333334 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 14.58333333333334 46
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cc0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 12.500000000000004 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 15.625000000000007 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 15.625000000000007 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 15.625000000000007 47
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ac8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 13.541666666666671 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 16.666666666666675 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 16.666666666666675 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 16.666666666666675 48
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78fd0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 14.58333333333334 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 17.708333333333343 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 17.708333333333343 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 17.708333333333343 49
Completed Iteration #15
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90e48> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f908d0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78fd0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 15.625000000000007 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 18.75000000000001 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 18.75000000000001 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 18.75000000000001 50
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f908d0> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78fd0> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 15.625000000000007 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 18.75000000000001 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 18.75000000000001 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 18.75000000000001 51
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3fada20> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad438> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90e48> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f908d0> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78fd0> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 16.666666666666675 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 19.79166666666668 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 19.79166666666668 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 19.79166666666668 52
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33898> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 8.333333333333332 9
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 9.375 10
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 16.666666666666675 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 19.79166666666668 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 19.79166666666668 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 19.79166666666668 53
Completed Iteration #23
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90e48> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f908d0> 2.0833333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78fd0> 3.1250000000000036 6
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 16.666666666666675 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 19.79166666666668 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 19.79166666666668 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 19.79166666666668 54
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #3
root->1->2->6
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10eba55198> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417f60> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 10.416666666666668 11
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 17.708333333333343 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 20.833333333333346 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 20.833333333333346 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 20.833333333333346 55
Completed Iteration #1
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f4417fd0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458f60> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ba8> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9390> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9e80> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 7.291666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 9.375 10
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 11.458333333333336 12
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 18.75000000000001 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 21.875000000000014 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 21.875000000000014 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 21.875000000000014 56
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0cf8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0048> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 10.416666666666668 11
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 12.500000000000004 13
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 19.79166666666668 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 22.916666666666682 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 22.916666666666682 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 22.916666666666682 57
Completed Iteration #5
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 10.416666666666668 12
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 12.500000000000004 14
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 19.79166666666668 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 22.916666666666682 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 22.916666666666682 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 22.916666666666682 58
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f111c059710> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 9.374999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 12.5 13
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 14.583333333333336 15
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 21.87500000000001 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 25.000000000000014 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 25.000000000000014 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 25.000000000000014 59
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9080> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78c50> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 13.541666666666668 14
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 15.625000000000004 16
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 22.91666666666668 30
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 26.041666666666682 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 26.041666666666682 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 26.041666666666682 60
Completed Iteration #11
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33898> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 13.541666666666668 15
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 15.625000000000004 17
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 22.91666666666668 31
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 26.041666666666682 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 26.041666666666682 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 26.041666666666682 61
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0048> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 4.166666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 14.583333333333336 16
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 16.66666666666667 18
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 23.958333333333346 32
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 27.08333333333335 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 27.08333333333335 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 27.08333333333335 62
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 16.66666666666667 19
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 23.958333333333346 33
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 27.08333333333335 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 27.08333333333335 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 27.08333333333335 63
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa09e8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63fd0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0048> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 5.208333333333339 7
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 15.625000000000004 17
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 17.70833333333334 20
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 25.000000000000014 34
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 28.125000000000018 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 28.125000000000018 54
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 28.125000000000018 64
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52a58> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f522b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 18.750000000000007 21
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 26.041666666666682 35
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 29.166666666666686 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 29.166666666666686 55
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 29.166666666666686 65
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f826a0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0b8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059710> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 10.416666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 16.66666666666667 18
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 19.791666666666675 22
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 27.08333333333335 36
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 30.208333333333353 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 30.208333333333353 56
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 30.208333333333353 66
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417fd0> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458f60> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ba8> 3.125 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9390> 3.125 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9e80> 5.208333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 5.208333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 10.416666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 16.66666666666667 19
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 19.791666666666675 23
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 27.08333333333335 37
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 30.208333333333353 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 30.208333333333353 57
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 30.208333333333353 67
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9828> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78c50> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 6.250000000000007 8
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 17.70833333333334 20
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 20.833333333333343 24
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 28.125000000000018 38
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 31.25000000000002 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 31.25000000000002 58
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 31.25000000000002 68
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #4
root->1->2->6->18
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52cf8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0b8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f111c059710> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 11.458333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 18.750000000000007 21
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 21.87500000000001 25
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 29.166666666666686 39
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 32.291666666666686 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 32.291666666666686 59
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 32.291666666666686 69
Completed Iteration #2
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90f98> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 19.791666666666675 22
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 22.91666666666668 26
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 30.208333333333353 40
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 33.33333333333336 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 33.33333333333336 60
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 33.33333333333336 70
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52780> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90e48> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90f98> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 20.833333333333343 23
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 23.958333333333346 27
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 31.25000000000002 41
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 34.37500000000003 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 34.37500000000003 61
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 34.37500000000003 71
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca860> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90710> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33898> 2.0833333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 21.87500000000001 24
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 25.000000000000014 28
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 32.291666666666686 42
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 35.4166666666667 54
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 35.4166666666667 62
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 35.4166666666667 72
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbaef0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458f60> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ba8> 4.166666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9390> 4.166666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9e80> 6.25 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 6.25 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 12.5 11
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 22.91666666666668 25
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 26.041666666666682 29
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 33.33333333333336 43
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 36.45833333333337 55
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 36.45833333333337 63
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 36.45833333333337 73
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba358> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 23.958333333333346 26
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 27.08333333333335 30
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 34.37500000000003 44
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 37.50000000000004 56
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 37.50000000000004 64
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 37.50000000000004 74
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f525c0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90710> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33898> 3.1250000000000036 6
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 25.000000000000014 27
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 28.125000000000018 31
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 35.4166666666667 45
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 38.541666666666714 57
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 38.541666666666714 65
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 38.541666666666714 75
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3fade48> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 7.291666666666668 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 13.541666666666668 12
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 26.041666666666682 28
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 29.166666666666686 32
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 36.45833333333337 46
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 39.583333333333385 58
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 39.583333333333385 66
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 39.583333333333385 76
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90a20> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90e48> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90f98> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 27.08333333333335 29
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 30.208333333333353 33
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 37.50000000000004 47
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 40.62500000000006 59
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 40.62500000000006 67
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 40.62500000000006 77
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90048> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90390> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 14.583333333333336 13
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 28.125000000000018 30
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 31.25000000000002 34
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 38.541666666666714 48
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 41.66666666666673 60
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 41.66666666666673 68
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 41.66666666666673 78
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbac88> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba860> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9828> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78c50> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01198> 7.291666666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 29.166666666666686 31
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 32.291666666666686 35
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 39.583333333333385 49
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 42.7083333333334 61
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 42.7083333333334 69
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 42.7083333333334 79
Completed Iteration #24
Best Reward: 2.083333333333332
coverage_call_count 3300
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #5
root->1->2->6->18->7
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c50> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90390> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 15.625000000000004 14
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 30.208333333333353 32
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 33.33333333333336 36
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 40.62500000000006 50
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 43.75000000000007 62
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 43.75000000000007 70
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 43.75000000000007 80
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecec50> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 9.375 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 17.708333333333336 15
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 32.291666666666686 33
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 35.416666666666686 37
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 42.708333333333385 51
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 45.8333333333334 63
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 45.8333333333334 71
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 45.8333333333334 81
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c50> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90390> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 17.708333333333336 16
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 32.291666666666686 34
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 35.416666666666686 38
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 42.708333333333385 52
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 45.8333333333334 64
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 45.8333333333334 72
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 45.8333333333334 82
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de48> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509048> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 18.750000000000004 17
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 33.33333333333336 35
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 36.45833333333336 39
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 43.75000000000006 53
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 46.87500000000007 65
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 46.87500000000007 73
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 46.87500000000007 83
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f909e8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52588> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90048> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90390> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 19.79166666666667 18
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 34.37500000000003 36
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 37.50000000000003 40
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 44.79166666666673 54
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 47.91666666666674 66
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 47.91666666666674 74
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 47.91666666666674 84
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 4.166666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 19.79166666666667 19
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 34.37500000000003 37
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 37.50000000000003 41
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 44.79166666666673 55
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 47.91666666666674 67
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 47.91666666666674 75
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 47.91666666666674 85
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29320> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0b8> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f111c059710> 6.25 5
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 6.25 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 21.875000000000004 20
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 36.45833333333336 38
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 39.58333333333336 42
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 46.87500000000006 56
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 50.00000000000007 68
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 50.00000000000007 76
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 50.00000000000007 86
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d978> 6.25 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 21.875000000000004 21
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 36.45833333333336 39
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 39.58333333333336 43
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 46.87500000000006 57
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 50.00000000000007 69
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 50.00000000000007 77
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 50.00000000000007 87
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #6
root->1->2->6->18->7->3
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3f027b8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dac8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecec50> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 11.458333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 23.958333333333336 22
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 38.541666666666686 40
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 41.666666666666686 44
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 48.958333333333385 58
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 52.0833333333334 70
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 52.0833333333334 78
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 52.0833333333334 88
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb208> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 13.541666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 26.041666666666668 23
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 40.625000000000014 41
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 43.750000000000014 45
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 51.041666666666714 59
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 54.16666666666673 71
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 54.16666666666673 79
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 54.16666666666673 89
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbbe0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb390> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f027b8> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dac8> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecec50> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 14.583333333333332 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 27.083333333333336 24
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 41.666666666666686 42
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 44.791666666666686 46
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 52.083333333333385 60
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 55.2083333333334 72
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 55.2083333333334 80
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 55.2083333333334 90
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbbe0> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb390> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f027b8> 3.125 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dac8> 3.125 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecec50> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 14.583333333333332 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 27.083333333333336 25
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 41.666666666666686 43
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 44.791666666666686 47
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 52.083333333333385 61
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 55.2083333333334 73
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 55.2083333333334 81
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 55.2083333333334 91
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3f293c8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba470> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb208> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 16.666666666666664 14
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 29.166666666666668 26
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 43.750000000000014 44
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 46.875000000000014 48
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 54.166666666666714 62
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 57.29166666666673 74
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 57.29166666666673 82
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 57.29166666666673 92
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02400> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458f60> 4.166666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ba8> 6.25 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9390> 6.25 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9e80> 8.333333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 18.749999999999996 15
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 31.25 27
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 45.83333333333334 45
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 48.95833333333334 49
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 56.25000000000004 63
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 59.37500000000006 75
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 59.37500000000006 83
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 59.37500000000006 93
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc588> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcfd0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f293c8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba470> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb208> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 20.83333333333333 16
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 33.33333333333333 28
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 47.91666666666667 46
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 51.04166666666667 50
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 58.33333333333337 64
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 61.458333333333385 76
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 61.458333333333385 84
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 61.458333333333385 94
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca240> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d4e0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecec50> 7.291666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 22.91666666666666 17
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 35.41666666666666 29
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 50.0 47
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 53.125 51
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 60.4166666666667 65
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 63.541666666666714 77
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 63.541666666666714 85
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 63.541666666666714 95
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95978> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 24.999999999999993 18
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 37.499999999999986 30
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 52.08333333333333 48
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 55.20833333333333 52
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 62.50000000000003 66
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 65.62500000000004 78
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 65.62500000000004 86
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 65.62500000000004 96
Completed Iteration #21
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95b70> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 26.04166666666666 19
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 38.54166666666666 31
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 53.125 49
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 56.25 53
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 63.5416666666667 67
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 66.66666666666671 79
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 66.66666666666671 87
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 66.66666666666671 97
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1e696d8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dac8> 4.166666666666668 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecec50> 8.333333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 27.08333333333333 20
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 39.58333333333333 32
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 54.16666666666667 50
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 57.29166666666667 54
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 64.58333333333337 68
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 67.70833333333339 80
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 67.70833333333339 88
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 67.70833333333339 98
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #7
root->1->2->6->18->7->3->8
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1e690f0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69518> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f293c8> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba470> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb208> 7.291666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 28.124999999999996 21
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 40.625 33
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 55.20833333333334 51
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 58.33333333333334 55
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 65.62500000000004 69
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 68.75000000000006 81
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 68.75000000000006 89
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 68.75000000000006 99
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3edce80> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95fd0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc588> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcfd0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f293c8> 7.291666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba470> 7.291666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb208> 9.374999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 30.20833333333333 22
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 42.70833333333333 34
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 57.29166666666667 52
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 60.41666666666667 56
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 67.70833333333337 70
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 70.83333333333339 82
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 70.83333333333339 90
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 70.83333333333339 100
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29dd8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb7b8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb208> 11.458333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 32.29166666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 44.79166666666666 35
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 59.375 53
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 62.5 57
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 69.7916666666667 71
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 72.91666666666671 83
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 72.91666666666671 91
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 72.91666666666671 101
Completed Iteration #15
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02e10> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edce80> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95fd0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc588> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcfd0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f293c8> 9.374999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba470> 9.374999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb208> 13.54166666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 34.374999999999986 24
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 46.874999999999986 36
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 61.45833333333333 54
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 64.58333333333333 58
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 71.87500000000003 72
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 75.00000000000004 84
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 75.00000000000004 92
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 75.00000000000004 102
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69518> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f293c8> 9.374999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba470> 9.374999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb208> 13.54166666666666 9
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 34.374999999999986 25
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 46.874999999999986 37
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 61.45833333333333 55
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 64.58333333333333 59
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 71.87500000000003 73
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 75.00000000000004 85
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 75.00000000000004 93
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 75.00000000000004 103
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1ddd8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e952b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29dd8> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb7b8> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb208> 14.583333333333329 10
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 35.41666666666666 26
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 47.91666666666666 38
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 62.5 56
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 65.625 60
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 72.9166666666667 74
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 76.04166666666671 86
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 76.04166666666671 94
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 76.04166666666671 104
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d4a8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d3c8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02e10> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02eb8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3edce80> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95fd0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc588> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcfd0> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f293c8> 11.458333333333329 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba470> 11.458333333333329 8
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb208> 16.66666666666666 11
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 37.499999999999986 27
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 49.999999999999986 39
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 64.58333333333333 57
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 67.70833333333333 61
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 75.00000000000003 75
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 78.12500000000004 87
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 78.12500000000004 95
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 78.12500000000004 105
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96668> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e952b0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29dd8> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb7b8> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb208> 17.70833333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 38.54166666666666 28
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 51.04166666666666 40
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 65.625 58
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 68.75 62
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 76.0416666666667 76
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 79.16666666666671 88
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 79.16666666666671 96
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 79.16666666666671 106
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb208> 17.70833333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f10f4417a90> 38.54166666666666 29
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 51.04166666666666 41
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 65.625 59
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 68.75 63
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0400> 76.0416666666667 77
backprop <src.mcts.MCTS_Node object at 0x7f10f4446e80> 79.16666666666671 89
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 79.16666666666671 97
backprop <src.mcts.MCTS_Node object at 0x7f10f4446cf8> 79.16666666666671 107
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #8
root->1->2->6->18->7->3->8->3
Best Reward: 2.083333333333332
iteration: 67
found coverage increase 2.083333333333332
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1dda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e960f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 20
Completed Iteration #22
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e960f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69e10> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 30.208333333333332
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e969b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb39b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e961d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 30.208333333333332
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec48d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef10b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef19e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 30.208333333333332
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 2
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f758d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 9
Completed Iteration #15
Best Reward: 0
coverage_call_count 3600
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f758d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 30.208333333333332
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0063898> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb39b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e00d21d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00390b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e009de10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009de10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009de10> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c8d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f10e0039da0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00591d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00591d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00634e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e009d6a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 7
Completed Iteration #10
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f41d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c60f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 30.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e00596a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 30.208333333333332
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0f0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 30.208333333333332
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db795128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 30.208333333333332
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db7f44a8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 1.0416666666666679 3
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6390> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 2.0833333333333357 4
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4780> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778208> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6390> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 3.1250000000000036 5
Completed Iteration #7
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3470> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6d68> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f44a8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 4.166666666666671 6
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 4.166666666666671 7
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 4.166666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 4.166666666666671 8
Completed Iteration #15
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 4.166666666666671 7
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 4.166666666666671 9
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db723128> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 5.208333333333339 8
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 5.208333333333339 10
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 5.208333333333339 11
Completed Iteration #20
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db7f40b8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 6.250000000000007 9
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 6.250000000000007 12
Completed Iteration #21
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4780> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10db778208> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6390> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 6.250000000000007 10
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 6.250000000000007 13
Completed Iteration #22
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 7.291666666666675 11
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 7.291666666666675 14
Completed Iteration #23
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 7.291666666666675 15
Completed Iteration #24
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7786d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 7.291666666666675 16
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 7.291666666666675 12
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 7.291666666666675 17
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 7.291666666666675 13
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 7.291666666666675 18
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
coverage_call_count 4000
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db73a940> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 8.333333333333343 14
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 8.333333333333343 19
Completed Iteration #10
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4780> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f10db778208> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6390> 2.0833333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 8.333333333333343 15
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 8.333333333333343 20
Completed Iteration #11
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7198> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73aef0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6390> 3.1250000000000036 6
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 9.37500000000001 16
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 9.37500000000001 21
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 10.416666666666679 17
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 10.416666666666679 22
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #1
root->0
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6f28> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059978> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a940> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 11.458333333333346 18
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 11.458333333333346 23
Completed Iteration #9
Best Reward: 1.0416666666666679
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7860> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 12.500000000000014 19
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 12.500000000000014 24
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db742a58> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 13.541666666666682 20
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 13.541666666666682 25
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db73ae80> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 14.58333333333335 21
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 14.58333333333335 26
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7a20> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7438> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742a58> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 15.625000000000018 22
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 15.625000000000018 27
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #2
root->0->8
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db778ac8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2358> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 16.666666666666686 23
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 16.666666666666686 28
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e0059d68> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7438> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db742a58> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 10.416666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 17.708333333333353 24
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 17.708333333333353 29
Completed Iteration #13
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 10.416666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 11.458333333333346 12
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 18.75000000000002 25
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 18.75000000000002 30
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #3
root->0->8->2
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 11.458333333333346 12
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 12.500000000000014 13
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 19.79166666666669 26
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 19.79166666666669 31
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e009d198> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2358> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 12.500000000000014 13
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 13.541666666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 20.833333333333357 27
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 20.833333333333357 32
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Completed Iteration #10
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6a90> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 13.541666666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 14.58333333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 21.875000000000025 28
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 21.875000000000025 33
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6b70> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 14.58333333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 15.625000000000018 16
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 22.916666666666693 29
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 22.916666666666693 34
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7cc0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 15.625000000000018 16
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 16.666666666666686 17
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 23.95833333333336 30
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 23.95833333333336 35
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db7234e0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2358> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 16.666666666666686 17
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 17.708333333333353 18
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 25.00000000000003 31
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 25.00000000000003 36
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db795390> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2358> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 10.416666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 17.708333333333353 18
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 18.75000000000002 19
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 26.041666666666696 32
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 26.041666666666696 37
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #4
root->0->8->2->1
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6a58> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 11.458333333333346 12
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 18.75000000000002 19
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 19.79166666666669 20
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 27.083333333333364 33
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 27.083333333333364 38
Completed Iteration #1
Best Reward: 1.0416666666666679
coverage_call_count 4100
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2630> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 12.500000000000014 13
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 19.79166666666669 20
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 20.833333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 28.125000000000032 34
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 28.125000000000032 39
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e009da58> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 13.541666666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 20.833333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 21.875000000000025 22
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 29.1666666666667 35
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 29.1666666666667 40
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75898> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75e80> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7cc0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 14.58333333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 21.875000000000025 22
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 22.916666666666693 23
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 30.208333333333368 36
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 30.208333333333368 41
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc710> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 10.416666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 15.625000000000018 16
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 22.916666666666693 23
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 23.95833333333336 24
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 31.250000000000036 37
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 31.250000000000036 42
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #5
root->0->8->2->1->0
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb5c0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb588> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009da58> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 11.458333333333346 12
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 16.666666666666686 17
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 23.95833333333336 24
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 25.00000000000003 25
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 32.2916666666667 38
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 32.2916666666667 43
Completed Iteration #20
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10db795dd8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 12.500000000000014 13
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 17.708333333333353 18
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 25.00000000000003 25
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 26.041666666666696 26
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 33.33333333333337 39
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 33.33333333333337 44
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #6
root->0->8->2->1->0->27
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcf28> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75f98> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 13.541666666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 18.75000000000002 19
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 26.041666666666696 26
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 27.083333333333364 27
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 34.37500000000004 40
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 34.37500000000004 45
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2748> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75f98> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 14.58333333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 19.79166666666669 20
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 27.083333333333364 27
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 28.125000000000032 28
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 35.416666666666714 41
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 35.416666666666714 46
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Completed Iteration #5
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e009def0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75f98> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 15.625000000000018 16
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 20.833333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 28.125000000000032 28
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 29.1666666666667 29
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 36.458333333333385 42
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 36.458333333333385 47
Completed Iteration #6
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2828> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b9b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6a90> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 10.416666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 16.666666666666686 17
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 21.875000000000025 22
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 29.1666666666667 29
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 30.208333333333368 30
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 37.50000000000006 43
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 37.50000000000006 48
Completed Iteration #7
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1de10> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75f98> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 10.416666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 11.458333333333346 12
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 17.708333333333353 18
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 22.916666666666693 23
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 30.208333333333368 30
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 31.250000000000036 31
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 38.54166666666673 44
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 38.54166666666673 49
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb7b8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc400> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009da58> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 11.458333333333346 12
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 12.500000000000014 13
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 18.75000000000002 19
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 23.95833333333336 24
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 31.250000000000036 31
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 32.2916666666667 32
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 39.5833333333334 45
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 39.5833333333334 50
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63cc0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 12.500000000000014 13
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 13.541666666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 19.79166666666669 20
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 25.00000000000003 25
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 32.2916666666667 32
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 33.33333333333337 33
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 40.62500000000007 46
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 40.62500000000007 51
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcc50> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f49e8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63cc0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 13.541666666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 14.58333333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 20.833333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 26.041666666666696 26
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 33.33333333333337 33
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 34.37500000000004 34
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 41.66666666666674 47
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 41.66666666666674 52
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10e00d23c8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f49e8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63cc0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 14.58333333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 15.625000000000018 16
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 21.875000000000025 22
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 27.083333333333364 27
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 34.37500000000004 34
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 35.416666666666714 35
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 42.708333333333414 48
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 42.708333333333414 53
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #7
root->0->8->2->1->0->27->0
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02748> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6eb8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 15.625000000000018 16
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 16.666666666666686 17
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 22.916666666666693 23
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 28.125000000000032 28
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 35.416666666666714 35
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 36.458333333333385 36
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 43.750000000000085 49
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 43.750000000000085 54
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d278> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75f98> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 16.666666666666686 17
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 17.708333333333353 18
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 23.95833333333336 24
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 29.1666666666667 29
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 36.458333333333385 36
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 37.50000000000006 37
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 44.79166666666676 50
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 44.79166666666676 55
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba780> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75f98> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 17.708333333333353 18
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 18.75000000000002 19
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 25.00000000000003 25
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 30.208333333333368 30
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 37.50000000000006 37
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 38.54166666666673 38
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 45.83333333333343 51
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 45.83333333333343 56
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadfd0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6eb8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e69e8> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6940> 18.75000000000002 19
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 19.79166666666669 20
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 26.041666666666696 26
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 31.250000000000036 31
backprop <src.mcts.MCTS_Node object at 0x7f10db73a9b0> 38.54166666666673 38
backprop <src.mcts.MCTS_Node object at 0x7f10e009d978> 39.5833333333334 39
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2e80> 46.8750000000001 52
backprop <src.mcts.MCTS_Node object at 0x7f10e00590f0> 46.8750000000001 57
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #8
root->0->8->2->1->0->27->0->9
Best Reward: 1.0416666666666679
iteration: 91
found coverage increase 1.0416666666666679
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eceb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7420f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7420f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecae80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f027f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f027f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f027f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad198> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f787b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0710> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba55320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f785f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e954e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f785f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78eb8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 31.25
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f826a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82240> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba55048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fadb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e954e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e954e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c0470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f905c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 31.25
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45190b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e14e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e14e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 31.25
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f905c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa01d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0630> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45095f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c04b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e82029b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e82028d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82024e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c059e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c033be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f11913d0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c059780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82024e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82024e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c059cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c03e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c059be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 31.25
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c059c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c03ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81827b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c033be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e82024e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81827b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c04b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c059be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f293c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c033f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f905c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f11dfacfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b335f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c033f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b335f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b335f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a60f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b335f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f11913e2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f905c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 31.25
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8124320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81245f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81245f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81245f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81245f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f11913e20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b756d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b756d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c03ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4427978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bdb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4affac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4afff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4afff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4affba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f11dfae2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c02b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e958d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f5c0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4affe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4beec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4babcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 4700
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f11dfae22e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c0c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4afff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4babb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4affe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1193740278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4afff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b92978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab6a0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45294a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8118ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8118be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 31.25
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b105f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45299e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b105f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8159dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 16
Completed Iteration #17
Best Reward: 0
coverage_call_count 4800
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1fafc18> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e43470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81dd240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 31.25
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c02b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4babfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4babfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8159d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4babfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4afff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4affac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4babfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8137438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae89e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8202128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 10
Completed Iteration #13
Best Reward: 0
coverage_call_count 4900
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8159b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bd3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4babb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e958d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e958d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba62a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e694e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e694e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b109b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b109b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dfd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f4affdd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 31.25
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f016a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f019e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f016a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e962b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d470> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 8
Completed Iteration #11
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f015f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f015f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f015f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f015f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1e10> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba62a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ef1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba62a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 21
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1d30> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 31.25
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1faf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcecf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e002c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b0b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 1.0416666666666714 14
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 1.0416666666666714 15
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 1.0416666666666714 16
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 1.0416666666666714 17
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 1.0416666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 1.0416666666666714 18
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 1.0416666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 1.0416666666666714 19
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f010b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 1.0416666666666714 7
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 1.0416666666666714 20
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 2.083333333333343 8
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 2.083333333333343 21
Completed Iteration #4
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 2.083333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 2.083333333333343 22
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 2.083333333333343 10
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 2.083333333333343 23
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 2.083333333333343 11
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 2.083333333333343 24
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6e05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 2.083333333333343 12
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 2.083333333333343 25
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 2.083333333333343 13
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 2.083333333333343 26
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 2.083333333333343 14
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 2.083333333333343 27
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 2.083333333333343 15
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 2.083333333333343 28
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0dd8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0b70> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 3.125000000000014 16
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 3.125000000000014 29
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d93141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 3.125000000000014 17
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 3.125000000000014 30
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0b70> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 3.125000000000014 18
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 3.125000000000014 31
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d93143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d93149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 3.125000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 3.125000000000014 19
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 3.125000000000014 32
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9314f98> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 4.166666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 4.166666666666686 20
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 4.166666666666686 33
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d93212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 4.166666666666686 21
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 4.166666666666686 34
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #1
root->2
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 4.166666666666686 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 4.166666666666686 22
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 4.166666666666686 35
Completed Iteration #1
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10db76afd0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01748> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314f98> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 5.208333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 5.208333333333357 23
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 5.208333333333357 36
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 5.208333333333357 10
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 5.208333333333357 24
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 5.208333333333357 37
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10e0063320> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0780> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314f98> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 5.208333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 6.250000000000028 11
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 6.250000000000028 25
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 6.250000000000028 38
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 6.250000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 7.2916666666667 12
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 7.2916666666667 26
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 7.2916666666667 39
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9314d30> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 7.2916666666667 9
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 8.333333333333371 13
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 8.333333333333371 27
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 8.333333333333371 40
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9321a20> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 8.333333333333371 10
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 9.375000000000043 14
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 9.375000000000043 28
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 9.375000000000043 41
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9321cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01748> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314f98> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 8.333333333333371 11
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 9.375000000000043 15
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 9.375000000000043 29
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 9.375000000000043 42
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d933b160> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321fd0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 10.416666666666714 16
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 10.416666666666714 30
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 10.416666666666714 43
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d933b518> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321048> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0063320> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0780> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314f98> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 9.375000000000043 12
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 11.458333333333385 17
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 11.458333333333385 31
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 11.458333333333385 44
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d933bac8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933bb38> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 10.416666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 12.500000000000057 18
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 12.500000000000057 32
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 12.500000000000057 45
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321fd0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 12.500000000000057 19
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 12.500000000000057 33
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 12.500000000000057 46
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #2
root->2->19
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 10.416666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 12.500000000000057 20
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 12.500000000000057 34
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 12.500000000000057 47
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9314c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 10.416666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 12.500000000000057 21
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 12.500000000000057 35
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 12.500000000000057 48
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9321390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f01748> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9314f98> 4.166666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 10.416666666666714 16
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 12.500000000000057 22
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 12.500000000000057 36
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 12.500000000000057 49
Completed Iteration #10
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 2.083333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 10.416666666666714 17
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 12.500000000000057 23
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 12.500000000000057 37
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 12.500000000000057 50
Completed Iteration #11
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d933bc88> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933b5c0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314d30> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 11.458333333333385 18
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 13.541666666666728 24
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 13.541666666666728 38
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 13.541666666666728 51
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5940> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314470> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0dd8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0b70> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 3.125000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 12.500000000000057 19
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 14.5833333333334 25
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 14.5833333333334 39
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 14.5833333333334 52
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5c18> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314470> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0dd8> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0b70> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 4.166666666666686 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 13.541666666666728 20
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 15.625000000000071 26
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 15.625000000000071 40
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 15.625000000000071 53
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92c52b0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 14.5833333333334 21
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 16.666666666666742 27
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 16.666666666666742 41
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 16.666666666666742 54
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0b70> 3.125000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa12b0> 4.166666666666686 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 14.5833333333334 22
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 16.666666666666742 28
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 16.666666666666742 42
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 16.666666666666742 55
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8710> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e84a8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321a20> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 15.625000000000071 23
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 17.708333333333414 29
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 17.708333333333414 43
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 17.708333333333414 56
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #3
root->2->19->4
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933bb38> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 6.250000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 15.625000000000071 24
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 17.708333333333414 30
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 17.708333333333414 44
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 17.708333333333414 57
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8240> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 7.2916666666667 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 16.666666666666742 25
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 18.750000000000085 31
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 18.750000000000085 45
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 18.750000000000085 58
Completed Iteration #1
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933bc88> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d933b5c0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314d30> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 5.208333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 7.2916666666667 10
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 16.666666666666742 26
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 18.750000000000085 32
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 18.750000000000085 46
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 18.750000000000085 59
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5b70> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314b00> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 8.333333333333371 11
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 17.708333333333414 27
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 19.791666666666757 33
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 19.791666666666757 47
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 19.791666666666757 60
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
coverage_call_count 5200
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8828> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8128> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8240> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 6.250000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 9.375000000000043 12
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 18.750000000000085 28
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 20.833333333333428 34
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 20.833333333333428 48
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 20.833333333333428 61
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 7.2916666666667 9
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 10.416666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 19.791666666666757 29
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 21.8750000000001 35
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 21.8750000000001 49
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 21.8750000000001 62
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5b70> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314b00> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 10.416666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 19.791666666666757 30
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 21.8750000000001 36
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 21.8750000000001 50
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 21.8750000000001 63
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 10.416666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 19.791666666666757 31
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 21.8750000000001 37
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 21.8750000000001 51
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 21.8750000000001 64
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5b70> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9314b00> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 10.416666666666714 16
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 19.791666666666757 32
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 21.8750000000001 38
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 21.8750000000001 52
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 21.8750000000001 65
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 8.333333333333371 10
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 11.458333333333385 17
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 20.833333333333428 33
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 22.91666666666677 39
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 22.91666666666677 53
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 22.91666666666677 66
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc588> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314240> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8710> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e84a8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9321a20> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 9.375000000000043 11
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 12.500000000000057 18
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 21.8750000000001 34
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 23.958333333333442 40
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 23.958333333333442 54
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 23.958333333333442 67
Completed Iteration #21
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc9b0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933b4e0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5b70> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9314b00> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 13.541666666666728 19
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 22.91666666666677 35
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 25.000000000000114 41
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 25.000000000000114 55
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 25.000000000000114 68
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4e80> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933bb38> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 14.5833333333334 20
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 23.958333333333442 36
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 26.041666666666785 42
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 26.041666666666785 56
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 26.041666666666785 69
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5cf8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5978> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4e80> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d933bb38> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 15.625000000000071 21
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 25.000000000000114 37
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 27.083333333333456 43
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 27.083333333333456 57
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 27.083333333333456 70
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #4
root->2->19->4->1
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8d68> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 10.416666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 16.666666666666742 22
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 26.041666666666785 38
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 28.125000000000128 44
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 28.125000000000128 58
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 28.125000000000128 71
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4550> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4320> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 11.458333333333385 13
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 17.708333333333414 23
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 27.083333333333456 39
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 29.1666666666668 45
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 29.1666666666668 59
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 29.1666666666668 72
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc5f8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 12.500000000000057 14
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 18.750000000000085 24
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 28.125000000000128 40
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 30.20833333333347 46
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 30.20833333333347 60
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 30.20833333333347 73
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92fcf98> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92fce80> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8d68> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 13.541666666666728 15
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 19.791666666666757 25
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 29.1666666666668 41
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 31.250000000000142 47
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 31.250000000000142 61
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 31.250000000000142 74
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8828> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8128> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8240> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 13.541666666666728 16
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 19.791666666666757 26
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 29.1666666666668 42
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 31.250000000000142 48
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 31.250000000000142 62
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 31.250000000000142 75
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d929e198> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 14.5833333333334 17
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 20.833333333333428 27
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 30.20833333333347 43
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 32.29166666666681 49
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 32.29166666666681 63
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 32.29166666666681 76
Completed Iteration #19
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8d68> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 14.5833333333334 18
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 20.833333333333428 28
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 30.20833333333347 44
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 32.29166666666681 50
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 32.29166666666681 64
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 32.29166666666681 77
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929e198> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 14.5833333333334 19
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 20.833333333333428 29
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 30.20833333333347 45
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 32.29166666666681 51
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 32.29166666666681 65
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 32.29166666666681 78
Completed Iteration #21
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92916a0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4320> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 15.625000000000071 20
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 21.8750000000001 30
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 31.250000000000142 46
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 33.333333333333485 52
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 33.333333333333485 66
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 33.333333333333485 79
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8630> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 16.666666666666742 21
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 22.91666666666677 31
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 32.29166666666681 47
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 34.375000000000156 53
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 34.375000000000156 67
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 34.375000000000156 80
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #5
root->2->19->4->1->0
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9291e48> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c18> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 17.708333333333414 22
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 23.958333333333442 32
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 33.333333333333485 48
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 35.41666666666683 54
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 35.41666666666683 68
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 35.41666666666683 81
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9291ba8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c18> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 18.750000000000085 23
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 25.000000000000114 33
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 34.375000000000156 49
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 36.4583333333335 55
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 36.4583333333335 69
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 36.4583333333335 82
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8630> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 7.2916666666667 9
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 18.750000000000085 24
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 25.000000000000114 34
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 34.375000000000156 50
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 36.4583333333335 56
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 36.4583333333335 70
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 36.4583333333335 83
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d929ed68> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929ee10> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291e48> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c18> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 8.333333333333371 10
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 19.791666666666757 25
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 26.041666666666785 35
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 35.41666666666683 51
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 37.50000000000017 57
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 37.50000000000017 71
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 37.50000000000017 84
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c18> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 8.333333333333371 11
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 19.791666666666757 26
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 26.041666666666785 36
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 35.41666666666683 52
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 37.50000000000017 58
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 37.50000000000017 72
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 37.50000000000017 85
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6080> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 5.208333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 9.375000000000043 12
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 20.833333333333428 27
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 27.083333333333456 37
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 36.4583333333335 53
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 38.54166666666684 59
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 38.54166666666684 73
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 38.54166666666684 86
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6080> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 5.208333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 9.375000000000043 13
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 20.833333333333428 28
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 27.083333333333456 38
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 36.4583333333335 54
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 38.54166666666684 60
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 38.54166666666684 74
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 38.54166666666684 87
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92447b8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244828> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 10.416666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 21.8750000000001 29
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 28.125000000000128 39
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 37.50000000000017 55
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 39.58333333333351 61
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 39.58333333333351 75
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 39.58333333333351 88
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4a20> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291278> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6080> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 7.2916666666667 10
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 11.458333333333385 15
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 22.91666666666677 30
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 29.1666666666668 40
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 38.54166666666684 56
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 40.625000000000185 62
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 40.625000000000185 76
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 40.625000000000185 89
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #6
root->2->19->4->1->0->0
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6080> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 7.2916666666667 11
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 11.458333333333385 16
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 22.91666666666677 31
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 29.1666666666668 41
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 38.54166666666684 57
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 40.625000000000185 63
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 40.625000000000185 77
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 40.625000000000185 90
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc780> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b68d0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8630> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 8.333333333333371 12
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 12.500000000000057 17
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 23.958333333333442 32
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 30.20833333333347 42
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 39.58333333333351 58
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 41.666666666666856 64
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 41.666666666666856 78
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 41.666666666666856 91
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92448d0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4320> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 9.375000000000043 13
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 13.541666666666728 18
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 25.000000000000114 33
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 31.250000000000142 43
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 40.625000000000185 59
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 42.70833333333353 65
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 42.70833333333353 79
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 42.70833333333353 92
Completed Iteration #11
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9244da0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 10.416666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 14.5833333333334 19
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 26.041666666666785 34
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 32.29166666666681 44
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 41.666666666666856 60
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 43.7500000000002 66
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 43.7500000000002 80
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 43.7500000000002 93
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc780> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92b68d0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8630> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 10.416666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 14.5833333333334 20
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 26.041666666666785 35
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 32.29166666666681 45
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 41.666666666666856 61
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 43.7500000000002 67
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 43.7500000000002 81
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 43.7500000000002 94
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92e42e8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 11.458333333333385 16
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 15.625000000000071 21
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 27.083333333333456 36
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 33.333333333333485 46
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 42.70833333333353 62
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 44.79166666666687 68
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 44.79166666666687 82
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 44.79166666666687 95
Completed Iteration #18
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d925e8d0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e4a8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e42e8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 12.500000000000057 17
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 16.666666666666742 22
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 28.125000000000128 37
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 34.375000000000156 47
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 43.7500000000002 63
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 45.83333333333354 69
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 45.83333333333354 83
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 45.83333333333354 96
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8630> 2.083333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 12.500000000000057 18
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 16.666666666666742 23
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 28.125000000000128 38
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 34.375000000000156 48
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 43.7500000000002 64
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 45.83333333333354 70
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 45.83333333333354 84
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 45.83333333333354 97
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #7
root->2->19->4->1->0->0->4
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 5.208333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 12.500000000000057 19
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 16.666666666666742 24
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 28.125000000000128 39
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 34.375000000000156 49
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 43.7500000000002 65
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 45.83333333333354 71
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 45.83333333333354 85
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 45.83333333333354 98
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d925e438> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e47b8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92448d0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4320> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 6.250000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 13.541666666666728 20
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 17.708333333333414 25
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 29.1666666666668 40
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 35.41666666666683 50
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 44.79166666666687 66
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 46.87500000000021 72
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 46.87500000000021 86
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 46.87500000000021 99
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9273080> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4320> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 7.2916666666667 9
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 14.5833333333334 21
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 18.750000000000085 26
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 30.20833333333347 41
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 36.4583333333335 51
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 45.83333333333354 67
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 47.916666666666885 73
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 47.916666666666885 87
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 47.916666666666885 100
Completed Iteration #11
Best Reward: 1.0416666666666714
coverage_call_count 5300
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9273710> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273518> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92916a0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4320> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 8.333333333333371 10
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 15.625000000000071 22
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 19.791666666666757 27
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 31.250000000000142 42
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 37.50000000000017 52
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 46.87500000000021 68
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 48.958333333333556 74
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 48.958333333333556 88
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 48.958333333333556 101
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92447b8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9244828> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 8.333333333333371 11
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 15.625000000000071 23
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 19.791666666666757 28
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 31.250000000000142 43
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 37.50000000000017 53
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 46.87500000000021 69
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 48.958333333333556 75
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 48.958333333333556 89
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 48.958333333333556 102
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273710> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273518> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92916a0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4320> 6.250000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 8.333333333333371 12
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 15.625000000000071 24
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 19.791666666666757 29
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 31.250000000000142 44
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 37.50000000000017 54
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 46.87500000000021 70
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 48.958333333333556 76
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 48.958333333333556 90
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 48.958333333333556 103
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 8.333333333333371 13
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 15.625000000000071 25
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 19.791666666666757 30
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 31.250000000000142 45
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 37.50000000000017 55
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 46.87500000000021 71
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 48.958333333333556 77
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 48.958333333333556 91
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 48.958333333333556 104
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9244a90> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273518> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92916a0> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4320> 7.2916666666667 9
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 9.375000000000043 14
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 16.666666666666742 26
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 20.833333333333428 31
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 32.29166666666681 46
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 38.54166666666684 56
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 47.916666666666885 72
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 50.00000000000023 78
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 50.00000000000023 92
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 50.00000000000023 105
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9291518> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e978> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273080> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4320> 8.333333333333371 10
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4eb8> 10.416666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4c50> 17.708333333333414 27
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 21.8750000000001 32
backprop <src.mcts.MCTS_Node object at 0x7f10d9314fd0> 33.333333333333485 47
backprop <src.mcts.MCTS_Node object at 0x7f10d9314400> 39.58333333333351 57
backprop <src.mcts.MCTS_Node object at 0x7f10e1bce240> 48.958333333333556 73
backprop <src.mcts.MCTS_Node object at 0x7f10db76ae48> 51.0416666666669 79
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f518> 51.0416666666669 93
backprop <src.mcts.MCTS_Node object at 0x7f10db756a20> 51.0416666666669 106
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #8
root->2->19->4->1->0->0->4->14
Best Reward: 1.0416666666666714
iteration: 127
found coverage increase 1.0416666666666714
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92736d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92736d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92736d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92736d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9226978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9226da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9226fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92732b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9226908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273390> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925eb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9226160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 32.29166666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92265f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9226ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9226f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9226fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9226320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92917f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92917f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92269b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92269b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92269b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92269b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92269b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d962e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d962e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da78d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96668> 0.0 25
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 32.29166666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d968d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d968d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d803c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d968d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d803c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9226978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d723c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d059e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d059e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d059e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b70> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9226b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d724e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d726d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d724e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d642e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d642e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d311d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d056a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92144e0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80438> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 32.29166666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8c830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8c833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8c837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8c837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8c837b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8c837b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f296a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce59b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce50f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4427940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92fcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d929eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9314358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e43c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 32.29166666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9314828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9314c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9314748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9314c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d93147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d93143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d93143c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d93144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9314320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9321ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9321358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d93144a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d93147b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d933b898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8f98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9314b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9321860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d93216a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9321c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d93212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d93216a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d93212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e818d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9321208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9321358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d93212e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d933bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d93147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d93210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9314208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d93140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e818db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8048> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 32.29166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d93141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e84a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f292e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d93211d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9314630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d93144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f29e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9321ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d933bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 19
Completed Iteration #22
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e8518> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 32.29166666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 1.0416666666666572 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 1.0416666666666572 3
Completed Iteration #2
Best Reward: 1.0416666666666572
Completed Iteration #3
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 2.0833333333333144 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 2.0833333333333144 4
Completed Iteration #4
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 2.0833333333333144 5
Completed Iteration #5
Best Reward: 1.0416666666666572
Completed Iteration #6
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10db6e05c0> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0320> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 3.1249999999999716 6
Completed Iteration #7
Best Reward: 1.0416666666666572
Completed Iteration #8
Best Reward: 1.0416666666666572
Completed Iteration #9
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9314710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0320> 1.0416666666666572 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 3.1249999999999716 7
Completed Iteration #10
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10f4b10208> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4a90> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6e05c0> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0320> 2.0833333333333144 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 4.166666666666629 8
Completed Iteration #11
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 4.166666666666629 9
Completed Iteration #12
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4a90> 1.0416666666666572 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6e05c0> 2.0833333333333144 4
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0320> 2.0833333333333144 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 4.166666666666629 10
Completed Iteration #13
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 2.0833333333333144 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 4.166666666666629 11
Completed Iteration #14
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3f978> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 3.1249999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 3.1249999999999716 6
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 5.208333333333286 12
Completed Iteration #15
Best Reward: 1.0416666666666572
Completed Iteration #16
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e3fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 5.208333333333286 13
Completed Iteration #17
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b105f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 5.208333333333286 14
Completed Iteration #18
Best Reward: 1.0416666666666572
Completed Iteration #19
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ec4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 3.1249999999999716 7
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 5.208333333333286 15
Completed Iteration #20
Best Reward: 1.0416666666666572
Completed Iteration #21
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6e0320> 2.0833333333333144 6
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 5.208333333333286 16
Completed Iteration #22
Best Reward: 1.0416666666666572
Completed Iteration #23
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 3.1249999999999716 8
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 5.208333333333286 17
Completed Iteration #24
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 5.208333333333286 18
Completed Iteration #25
Best Reward: 1.0416666666666572
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666572
Completed Iteration #0
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5cc0> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 3.1249999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 4.166666666666629 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 4.166666666666629 9
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 6.249999999999943 19
Completed Iteration #1
Best Reward: 1.0416666666666572
Completed Iteration #2
Best Reward: 1.0416666666666572
Completed Iteration #3
Best Reward: 1.0416666666666572
Completed Iteration #4
Best Reward: 1.0416666666666572
Completed Iteration #5
Best Reward: 1.0416666666666572
Completed Iteration #6
Best Reward: 1.0416666666666572
Completed Iteration #7
Best Reward: 1.0416666666666572
Completed Iteration #8
Best Reward: 1.0416666666666572
Completed Iteration #9
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e002c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 4.166666666666629 10
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 6.249999999999943 20
Completed Iteration #10
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 4.166666666666629 11
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 6.249999999999943 21
Completed Iteration #11
Best Reward: 1.0416666666666572
Completed Iteration #12
Best Reward: 1.0416666666666572
Completed Iteration #13
Best Reward: 1.0416666666666572
Completed Iteration #14
Best Reward: 1.0416666666666572
Completed Iteration #15
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10d92e46a0> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 4.166666666666629 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 5.208333333333286 6
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 5.208333333333286 12
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 7.2916666666666 22
Completed Iteration #16
Best Reward: 1.0416666666666572
Completed Iteration #17
Best Reward: 1.0416666666666572
Completed Iteration #18
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 5.208333333333286 13
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 7.2916666666666 23
Completed Iteration #19
Best Reward: 1.0416666666666572
Completed Iteration #20
Best Reward: 1.0416666666666572
Completed Iteration #21
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 5.208333333333286 14
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 7.2916666666666 24
Completed Iteration #22
Best Reward: 1.0416666666666572
Completed Iteration #23
Best Reward: 1.0416666666666572
Completed Iteration #24
Best Reward: 1.0416666666666572
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0063128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 5.208333333333286 15
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 7.2916666666666 25
Completed Iteration #25
Best Reward: 1.0416666666666572
Completed MCTS Level/Depth: #1
root->1
Best Reward: 1.0416666666666572
Completed Iteration #0
Best Reward: 1.0416666666666572
Completed Iteration #1
Best Reward: 1.0416666666666572
Completed Iteration #2
Best Reward: 1.0416666666666572
Completed Iteration #3
Best Reward: 1.0416666666666572
Completed Iteration #4
Best Reward: 1.0416666666666572
Completed Iteration #5
Best Reward: 1.0416666666666572
Completed Iteration #6
Best Reward: 1.0416666666666572
Completed Iteration #7
Best Reward: 1.0416666666666572
Completed Iteration #8
Best Reward: 1.0416666666666572
Completed Iteration #9
Best Reward: 1.0416666666666572
Completed Iteration #10
Best Reward: 1.0416666666666572
Completed Iteration #11
Best Reward: 1.0416666666666572
Completed Iteration #12
Best Reward: 1.0416666666666572
Completed Iteration #13
Best Reward: 1.0416666666666572
Completed Iteration #14
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10d929ea90> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 5.208333333333286 6
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 6.249999999999943 7
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 6.249999999999943 16
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 8.333333333333258 26
Completed Iteration #15
Best Reward: 1.0416666666666572
Completed Iteration #16
Best Reward: 1.0416666666666572
Completed Iteration #17
Best Reward: 1.0416666666666572
Completed Iteration #18
Best Reward: 1.0416666666666572
Completed Iteration #19
Best Reward: 1.0416666666666572
Completed Iteration #20
Best Reward: 1.0416666666666572
Completed Iteration #21
Best Reward: 1.0416666666666572
Completed Iteration #22
Best Reward: 1.0416666666666572
Completed Iteration #23
Best Reward: 1.0416666666666572
Completed Iteration #24
Best Reward: 1.0416666666666572
Completed Iteration #25
Best Reward: 1.0416666666666572
Completed MCTS Level/Depth: #2
root->1->26
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 6.249999999999943 7
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 7.2916666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 7.2916666666666 17
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 9.374999999999915 27
Completed Iteration #0
Best Reward: 1.0416666666666572
Completed Iteration #1
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e1e697f0> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 3.1249999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 7.2916666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 8.333333333333258 9
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 8.333333333333258 18
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 10.416666666666572 28
Completed Iteration #2
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e1fa1940> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 8.333333333333258 9
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 9.374999999999915 10
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 9.374999999999915 19
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 11.45833333333323 29
Completed Iteration #3
Best Reward: 1.0416666666666572
Completed Iteration #4
Best Reward: 1.0416666666666572
Completed Iteration #5
Best Reward: 1.0416666666666572
Completed Iteration #6
Best Reward: 1.0416666666666572
Completed Iteration #7
Best Reward: 1.0416666666666572
Completed Iteration #8
Best Reward: 1.0416666666666572
Completed Iteration #9
Best Reward: 1.0416666666666572
Completed Iteration #10
Best Reward: 1.0416666666666572
Completed Iteration #11
Best Reward: 1.0416666666666572
Completed Iteration #12
Best Reward: 1.0416666666666572
Completed Iteration #13
Best Reward: 1.0416666666666572
Completed Iteration #14
Best Reward: 1.0416666666666572
Completed Iteration #15
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e81b59b0> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 3.1249999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 4.166666666666629 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 9.374999999999915 10
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 10.416666666666572 11
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 10.416666666666572 20
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 12.499999999999886 30
Completed Iteration #16
Best Reward: 1.0416666666666572
Completed Iteration #17
Best Reward: 1.0416666666666572
Completed Iteration #18
Best Reward: 1.0416666666666572
Completed Iteration #19
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5d080> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 4.166666666666629 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 5.208333333333286 6
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 10.416666666666572 11
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 11.45833333333323 12
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 11.45833333333323 21
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 13.541666666666544 31
Completed Iteration #20
Best Reward: 1.0416666666666572
coverage_call_count 5900
Completed Iteration #21
Best Reward: 1.0416666666666572
Completed Iteration #22
Best Reward: 1.0416666666666572
Completed Iteration #23
Best Reward: 1.0416666666666572
Completed Iteration #24
Best Reward: 1.0416666666666572
Completed Iteration #25
Best Reward: 1.0416666666666572
Completed MCTS Level/Depth: #3
root->1->26->0
Best Reward: 1.0416666666666572
Completed Iteration #0
Best Reward: 1.0416666666666572
Completed Iteration #1
Best Reward: 1.0416666666666572
Completed Iteration #2
Best Reward: 1.0416666666666572
Completed Iteration #3
Best Reward: 1.0416666666666572
Completed Iteration #4
Best Reward: 1.0416666666666572
Completed Iteration #5
Best Reward: 1.0416666666666572
Completed Iteration #6
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3780> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 3.1249999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 5.208333333333286 6
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 6.249999999999943 7
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 11.45833333333323 12
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 12.499999999999886 13
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 12.499999999999886 22
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 14.5833333333332 32
Completed Iteration #7
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69f28> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 6.249999999999943 7
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 7.2916666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 12.499999999999886 13
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 13.541666666666544 14
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 13.541666666666544 23
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 15.624999999999858 33
Completed Iteration #8
Best Reward: 1.0416666666666572
Completed Iteration #9
Best Reward: 1.0416666666666572
Completed Iteration #10
Best Reward: 1.0416666666666572
Completed Iteration #11
Best Reward: 1.0416666666666572
Completed Iteration #12
Best Reward: 1.0416666666666572
Completed Iteration #13
Best Reward: 1.0416666666666572
Completed Iteration #14
Best Reward: 1.0416666666666572
Completed Iteration #15
Best Reward: 1.0416666666666572
Completed Iteration #16
Best Reward: 1.0416666666666572
Completed Iteration #17
Best Reward: 1.0416666666666572
Completed Iteration #18
Best Reward: 1.0416666666666572
Completed Iteration #19
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5cc0> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d710> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69f28> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 7.2916666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 8.333333333333258 9
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 13.541666666666544 14
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 14.5833333333332 15
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 14.5833333333332 24
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 16.666666666666515 34
Completed Iteration #20
Best Reward: 1.0416666666666572
Completed Iteration #21
Best Reward: 1.0416666666666572
Completed Iteration #22
Best Reward: 1.0416666666666572
Completed Iteration #23
Best Reward: 1.0416666666666572
Completed Iteration #24
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a630> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 3.1249999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 4.166666666666629 5
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 8.333333333333258 9
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 9.374999999999915 10
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 14.5833333333332 15
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 15.624999999999858 16
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 15.624999999999858 25
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 17.708333333333172 35
Completed Iteration #25
Best Reward: 1.0416666666666572
Completed MCTS Level/Depth: #4
root->1->26->0->0
Best Reward: 1.0416666666666572
Completed Iteration #0
Best Reward: 1.0416666666666572
Completed Iteration #1
Best Reward: 1.0416666666666572
Completed Iteration #2
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10f4beeeb8> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 9.374999999999915 10
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 10.416666666666572 11
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 15.624999999999858 16
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 16.666666666666515 17
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 16.666666666666515 26
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 18.74999999999983 36
Completed Iteration #3
Best Reward: 1.0416666666666572
Completed Iteration #4
Best Reward: 1.0416666666666572
Completed Iteration #5
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1438> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 10.416666666666572 11
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 11.45833333333323 12
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 16.666666666666515 17
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 17.708333333333172 18
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 17.708333333333172 27
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 19.791666666666487 37
Completed Iteration #6
Best Reward: 1.0416666666666572
Completed Iteration #7
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab710> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 11.45833333333323 12
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 12.499999999999886 13
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 17.708333333333172 18
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 18.74999999999983 19
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 18.74999999999983 28
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 20.833333333333144 38
Completed Iteration #8
Best Reward: 1.0416666666666572
Completed Iteration #9
Best Reward: 1.0416666666666572
Completed Iteration #10
Best Reward: 1.0416666666666572
Completed Iteration #11
Best Reward: 1.0416666666666572
Completed Iteration #12
Best Reward: 1.0416666666666572
Completed Iteration #13
Best Reward: 1.0416666666666572
Completed Iteration #14
Best Reward: 1.0416666666666572
Completed Iteration #15
Best Reward: 1.0416666666666572
Completed Iteration #16
Best Reward: 1.0416666666666572
Completed Iteration #17
Best Reward: 1.0416666666666572
Completed Iteration #18
Best Reward: 1.0416666666666572
Completed Iteration #19
Best Reward: 1.0416666666666572
Completed Iteration #20
Best Reward: 1.0416666666666572
Completed Iteration #21
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d748> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 4.166666666666629 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 5.208333333333286 6
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 12.499999999999886 13
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 13.541666666666544 14
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 18.74999999999983 19
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 19.791666666666487 20
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 19.791666666666487 29
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 21.8749999999998 39
Completed Iteration #22
Best Reward: 1.0416666666666572
Completed Iteration #23
Best Reward: 1.0416666666666572
Completed Iteration #24
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a3c8> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d710> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69f28> 3.1249999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 13.541666666666544 14
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 14.5833333333332 15
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 19.791666666666487 20
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 20.833333333333144 21
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 20.833333333333144 30
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 22.91666666666646 40
Completed Iteration #25
Best Reward: 1.0416666666666572
Completed MCTS Level/Depth: #5
root->1->26->0->0->0
Best Reward: 1.0416666666666572
Completed Iteration #0
Best Reward: 1.0416666666666572
Completed Iteration #1
Best Reward: 1.0416666666666572
Completed Iteration #2
Best Reward: 1.0416666666666572
Completed Iteration #3
Best Reward: 1.0416666666666572
Completed Iteration #4
Best Reward: 1.0416666666666572
Completed Iteration #5
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1a90> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 5.208333333333286 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 6.249999999999943 7
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 14.5833333333332 15
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 15.624999999999858 16
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 20.833333333333144 21
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 21.8749999999998 22
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 21.8749999999998 31
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 23.958333333333115 41
Completed Iteration #6
Best Reward: 1.0416666666666572
Completed Iteration #7
Best Reward: 1.0416666666666572
Completed Iteration #8
Best Reward: 1.0416666666666572
Completed Iteration #9
Best Reward: 1.0416666666666572
Completed Iteration #10
Best Reward: 1.0416666666666572
Completed Iteration #11
Best Reward: 1.0416666666666572
Completed Iteration #12
Best Reward: 1.0416666666666572
Completed Iteration #13
Best Reward: 1.0416666666666572
Completed Iteration #14
Best Reward: 1.0416666666666572
Completed Iteration #15
Best Reward: 1.0416666666666572
Completed Iteration #16
Best Reward: 1.0416666666666572
Completed Iteration #17
Best Reward: 1.0416666666666572
Completed Iteration #18
Best Reward: 1.0416666666666572
Completed Iteration #19
Best Reward: 1.0416666666666572
Completed Iteration #20
Best Reward: 1.0416666666666572
Completed Iteration #21
Best Reward: 1.0416666666666572
Completed Iteration #22
Best Reward: 1.0416666666666572
Completed Iteration #23
Best Reward: 1.0416666666666572
Completed Iteration #24
Best Reward: 1.0416666666666572
Completed Iteration #25
Best Reward: 1.0416666666666572
Completed MCTS Level/Depth: #6
root->1->26->0->0->0->5
Best Reward: 1.0416666666666572
Completed Iteration #0
Best Reward: 1.0416666666666572
Completed Iteration #1
Best Reward: 1.0416666666666572
Completed Iteration #2
Best Reward: 1.0416666666666572
Completed Iteration #3
Best Reward: 1.0416666666666572
Completed Iteration #4
Best Reward: 1.0416666666666572
Completed Iteration #5
Best Reward: 1.0416666666666572
Completed Iteration #6
Best Reward: 1.0416666666666572
Completed Iteration #7
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33128> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 6.249999999999943 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 7.2916666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 15.624999999999858 16
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 16.666666666666515 17
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 21.8749999999998 22
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 22.91666666666646 23
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 22.91666666666646 32
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 24.999999999999773 42
Completed Iteration #8
Best Reward: 1.0416666666666572
Completed Iteration #9
Best Reward: 1.0416666666666572
Completed Iteration #10
Best Reward: 1.0416666666666572
Completed Iteration #11
Best Reward: 1.0416666666666572
Completed Iteration #12
Best Reward: 1.0416666666666572
Completed Iteration #13
Best Reward: 1.0416666666666572
Completed Iteration #14
Best Reward: 1.0416666666666572
Completed Iteration #15
Best Reward: 1.0416666666666572
Completed Iteration #16
Best Reward: 1.0416666666666572
Completed Iteration #17
Best Reward: 1.0416666666666572
coverage_call_count 6000
Completed Iteration #18
Best Reward: 1.0416666666666572
Completed Iteration #19
Best Reward: 1.0416666666666572
Completed Iteration #20
Best Reward: 1.0416666666666572
Completed Iteration #21
Best Reward: 1.0416666666666572
Completed Iteration #22
Best Reward: 1.0416666666666572
Completed Iteration #23
Best Reward: 1.0416666666666572
Completed Iteration #24
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10f4b1f0f0> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 7.2916666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 8.333333333333258 9
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 16.666666666666515 17
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 17.708333333333172 18
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 22.91666666666646 23
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 23.958333333333115 24
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 23.958333333333115 33
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 26.04166666666643 43
Completed Iteration #25
Best Reward: 1.0416666666666572
Completed MCTS Level/Depth: #7
root->1->26->0->0->0->5->0
Best Reward: 1.0416666666666572
Completed Iteration #0
Best Reward: 1.0416666666666572
Completed Iteration #1
Best Reward: 1.0416666666666572
Completed Iteration #2
Best Reward: 1.0416666666666572
Completed Iteration #3
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f111c04b668> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3780> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 8.333333333333258 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 9.374999999999915 10
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 17.708333333333172 18
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 18.74999999999983 19
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 23.958333333333115 24
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 24.999999999999773 25
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 24.999999999999773 34
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 27.083333333333087 44
Completed Iteration #4
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d2e8> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65080> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f111c04b668> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3780> 3.1249999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 9.374999999999915 10
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 10.416666666666572 11
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 18.74999999999983 19
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 19.791666666666487 20
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 24.999999999999773 25
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 26.04166666666643 26
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 26.04166666666643 35
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 28.124999999999744 45
Completed Iteration #5
Best Reward: 1.0416666666666572
Completed Iteration #6
Best Reward: 1.0416666666666572
Completed Iteration #7
Best Reward: 1.0416666666666572
Completed Iteration #8
Best Reward: 1.0416666666666572
Completed Iteration #9
Best Reward: 1.0416666666666572
Completed Iteration #10
Best Reward: 1.0416666666666572
Completed Iteration #11
Best Reward: 1.0416666666666572
Completed Iteration #12
Best Reward: 1.0416666666666572
Completed Iteration #13
Best Reward: 1.0416666666666572
Completed Iteration #14
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10f3f90fd0> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65080> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f111c04b668> 3.1249999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 3.1249999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3780> 4.166666666666629 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 10.416666666666572 11
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 11.45833333333323 12
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 19.791666666666487 20
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 20.833333333333144 21
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 26.04166666666643 26
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 27.083333333333087 27
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 27.083333333333087 36
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 29.1666666666664 46
Completed Iteration #15
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10e8143048> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b33438> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3d2e8> 2.0833333333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b65080> 3.1249999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f111c04b668> 4.166666666666629 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 4.166666666666629 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3780> 5.208333333333286 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 11.45833333333323 12
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 12.499999999999886 13
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 20.833333333333144 21
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 21.8749999999998 22
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 27.083333333333087 27
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 28.124999999999744 28
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 28.124999999999744 37
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 30.20833333333306 47
Completed Iteration #16
Best Reward: 1.0416666666666572
Completed Iteration #17
Best Reward: 1.0416666666666572
Completed Iteration #18
Best Reward: 1.0416666666666572
Completed Iteration #19
Best Reward: 1.0416666666666572
Completed Iteration #20
Best Reward: 1.0416666666666572
Completed Iteration #21
Best Reward: 1.0416666666666572
Completed Iteration #22
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10eba62dd8> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 5.208333333333286 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3780> 6.249999999999943 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 12.499999999999886 13
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 13.541666666666544 14
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 21.8749999999998 22
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 22.91666666666646 23
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 28.124999999999744 28
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 29.1666666666664 29
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 29.1666666666664 38
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 31.249999999999716 48
Completed Iteration #23
Best Reward: 1.0416666666666572
Completed Iteration #24
Best Reward: 1.0416666666666572
Reward: 1.0416666666666572
backprop <src.mcts.MCTS_Node object at 0x7f10f4529c88> 1.0416666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95198> 6.249999999999943 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1be3780> 7.2916666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1f61710> 13.541666666666544 14
backprop <src.mcts.MCTS_Node object at 0x7f10e1e69128> 14.5833333333332 15
backprop <src.mcts.MCTS_Node object at 0x7f111c02b080> 22.91666666666646 23
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4898> 23.958333333333115 24
backprop <src.mcts.MCTS_Node object at 0x7f10d92e4630> 29.1666666666664 29
backprop <src.mcts.MCTS_Node object at 0x7f10d92fc7b8> 30.20833333333306 30
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5da0> 30.20833333333306 39
backprop <src.mcts.MCTS_Node object at 0x7f10d8ce5518> 32.29166666666637 49
Completed Iteration #25
Best Reward: 1.0416666666666572
Completed MCTS Level/Depth: #8
root->1->26->0->0->0->5->0->0
Best Reward: 1.0416666666666572
iteration: 147
found coverage increase 1.0416666666666572
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81829e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c04b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81659b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81659b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d929e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81373c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba30358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8202828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81659b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c033c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4aff4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81659b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8182240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c0470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f3deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e5db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165da0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c03e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c04b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fa09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44e19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4529710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10eba30f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4417908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81828d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 6100
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45190f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f45190f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4446b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44729e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f820b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fda90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd208> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f82eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ece898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f02ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fbae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4458978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c033fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f11ec737898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8124a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e90978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4bc1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8143d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44bde80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f111c03ed30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f637f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e82026d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4509400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4529710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75400> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95780> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00390b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00390b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c03ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1df60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1e8bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3efbeb8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81dde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f637f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f759e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f637f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f637f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c033fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4509358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e8165d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44172e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f637f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e81828d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bcef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8143d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dd30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44e1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f020f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00392b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10eba3e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7f48d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f020f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3eca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8165d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f05c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f52c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f05c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e80f05c0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6d22e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e81655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f255c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f45190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4472908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f255c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4417080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc93c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 6400
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6c75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6c70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d24e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6c77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db756be0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f111c033fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4b75320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f1d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f44589b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10eba555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3edcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0039940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e820dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 6500
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7782b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db76ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7782e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7782b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db778a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00593c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0059978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00597b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db778c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00597b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1ed21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009def0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10e00594e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3e906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3efb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e0059710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7f4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1e96e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e8182390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e0039940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f44174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4ae1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4446048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db76a9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10f3f63b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6c7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4458208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00d27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d317b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d317b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d312b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f1dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d312b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9291f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9291550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9291c50> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d31588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db73a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3f78470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db73acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4529550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3ecee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7f41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1eb3ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4437f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d925e0b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e009d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4472438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e820dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7239e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db756e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92735f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d961d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9273550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9273128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92739e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db742240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92732e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1edc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92739e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e80f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4458240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 2
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92918d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d925eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db795c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e009db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8cf3080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9244240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e00c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db7e6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd90b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 17
Completed Iteration #22
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d77b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db6d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1bf28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 1.0416666666666714 11
Completed Iteration #11
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10e1bf3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 1.0416666666666714 12
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9273710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 1.0416666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 1.0416666666666714 13
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d9214278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92c54e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 1.0416666666666714 14
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10db723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 1.0416666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 1.0416666666666714 15
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8dcbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 1.0416666666666714 16
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd94e0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 2.083333333333343 7
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 2.083333333333343 17
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 2.083333333333343 18
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 2.083333333333343 8
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 2.083333333333343 19
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 2.083333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 2.083333333333343 20
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9214a58> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5f60> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd94e0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 3.125000000000014 10
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 3.125000000000014 21
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d927acc0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9048> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd94e0> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 4.166666666666686 11
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 4.166666666666686 22
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b2e8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 5.208333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 5.208333333333357 12
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 5.208333333333357 23
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05f28> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 6.250000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 6.250000000000028 13
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 6.250000000000028 24
Completed Iteration #10
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b70> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 7.2916666666667 14
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 7.2916666666667 25
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d925e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 7.2916666666667 15
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 7.2916666666667 26
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8d80cf8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05c88> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b70> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 8.333333333333371 16
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 8.333333333333371 27
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7710> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 7.2916666666667 10
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 9.375000000000043 17
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 9.375000000000043 28
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 9.375000000000043 18
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 9.375000000000043 29
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 8.333333333333371 11
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 10.416666666666714 19
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 10.416666666666714 30
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9048> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd94e0> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 7.2916666666667 9
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 8.333333333333371 12
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 10.416666666666714 20
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 10.416666666666714 31
Completed Iteration #21
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 10.416666666666714 21
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 10.416666666666714 32
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42208> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9048> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd94e0> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 8.333333333333371 10
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 9.375000000000043 13
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 11.458333333333385 22
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 11.458333333333385 33
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 11.458333333333385 23
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 11.458333333333385 34
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d423c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7b70> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 11.458333333333385 24
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 11.458333333333385 35
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #1
root->2
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8d420f0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42160> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7710> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 9.375000000000043 11
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 10.416666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 12.500000000000057 25
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 12.500000000000057 36
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8da73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b2e8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 9.375000000000043 12
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 10.416666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 12.500000000000057 26
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 12.500000000000057 37
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75748> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10db742080> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9214a58> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5f60> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd94e0> 5.208333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 10.416666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 11.458333333333385 16
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 13.541666666666728 27
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 13.541666666666728 38
Completed Iteration #4
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b860> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64e48> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 12.500000000000057 17
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 14.5833333333334 28
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 14.5833333333334 39
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d927af60> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8da76d8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b860> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64e48> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 13.541666666666728 18
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 15.625000000000071 29
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 15.625000000000071 40
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b00> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 11.458333333333385 14
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 14.5833333333334 19
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 16.666666666666742 30
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 16.666666666666742 41
Completed Iteration #19
Best Reward: 1.0416666666666714
coverage_call_count 6900
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92268d0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226160> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75748> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10db742080> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9214a58> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5f60> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd94e0> 6.250000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 12.500000000000057 15
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 15.625000000000071 20
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 17.708333333333414 31
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 17.708333333333414 42
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72748> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72630> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b00> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 13.541666666666728 16
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 16.666666666666742 21
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 18.750000000000085 32
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 18.750000000000085 43
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #2
root->2->18
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d727b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42208> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9048> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd94e0> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 13.541666666666728 17
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 16.666666666666742 22
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 18.750000000000085 33
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 18.750000000000085 44
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72748> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72630> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b00> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 13.541666666666728 18
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 16.666666666666742 23
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 18.750000000000085 34
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 18.750000000000085 45
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b2e8> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 13.541666666666728 19
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 16.666666666666742 24
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 18.750000000000085 35
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 18.750000000000085 46
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83320> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 14.5833333333334 20
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 17.708333333333414 25
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 19.791666666666757 36
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 19.791666666666757 47
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d420f0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42160> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7710> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 14.5833333333334 21
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 17.708333333333414 26
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 19.791666666666757 37
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 19.791666666666757 48
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05908> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d1b550> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d927acc0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10f3fc9048> 3.125000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd94e0> 7.2916666666667 10
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 15.625000000000071 22
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 18.750000000000085 27
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 20.833333333333428 38
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 20.833333333333428 49
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226160> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75748> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10db742080> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9214a58> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5f60> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd94e0> 7.2916666666667 11
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 15.625000000000071 23
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 18.750000000000085 28
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 20.833333333333428 39
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 20.833333333333428 50
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d925ef60> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6400> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05f28> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 16.666666666666742 24
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 19.791666666666757 29
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 21.8750000000001 40
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 21.8750000000001 51
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9226908> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72d68> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 17.708333333333414 25
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 20.833333333333428 30
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 22.91666666666677 41
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 22.91666666666677 52
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d92260b8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226f60> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d420f0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42160> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7710> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 18.750000000000085 26
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 21.8750000000001 31
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 23.958333333333442 42
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 23.958333333333442 53
Completed Iteration #18
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64128> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d960b8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d420f0> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42160> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8da7710> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 19.791666666666757 27
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 22.91666666666677 32
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 25.000000000000114 43
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 25.000000000000114 54
Completed Iteration #19
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83630> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83dd8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10e1f75748> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10db742080> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9214a58> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10d92c5f60> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10d8dd94e0> 8.333333333333371 12
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 20.833333333333428 28
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 23.958333333333442 33
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 26.041666666666785 44
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 26.041666666666785 55
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83f98> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72d68> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 21.8750000000001 29
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 25.000000000000114 34
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 27.083333333333456 45
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 27.083333333333456 56
Completed Iteration #21
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3efa470> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3efa2b0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64b00> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 22.91666666666677 30
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 26.041666666666785 35
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 28.125000000000128 46
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 28.125000000000128 57
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3efa828> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72d68> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 23.958333333333442 31
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 27.083333333333456 36
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 29.1666666666668 47
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 29.1666666666668 58
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #3
root->2->18->1
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3efadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3efacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83f98> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72d68> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 23.958333333333442 32
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 27.083333333333456 37
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 29.1666666666668 48
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 29.1666666666668 59
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9226d68> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 5.208333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 25.000000000000114 33
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 28.125000000000128 38
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 30.20833333333347 49
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 30.20833333333347 60
Completed Iteration #4
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226d68> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 5.208333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 25.000000000000114 34
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 28.125000000000128 39
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 30.20833333333347 50
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 30.20833333333347 61
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83f98> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72d68> 3.125000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 5.208333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 25.000000000000114 35
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 28.125000000000128 40
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 30.20833333333347 51
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 30.20833333333347 62
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9226e48> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 6.250000000000028 10
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 26.041666666666785 36
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 29.1666666666668 41
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 31.250000000000142 52
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 31.250000000000142 63
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3efa128> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42c88> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226d68> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 7.2916666666667 11
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 27.083333333333456 37
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 30.20833333333347 42
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 32.29166666666681 53
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 32.29166666666681 64
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3efafd0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 8.333333333333371 12
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 28.125000000000128 38
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 31.250000000000142 43
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 33.333333333333485 54
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 33.333333333333485 65
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b3c8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b208> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226e48> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 5.208333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 9.375000000000043 13
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 29.1666666666668 39
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 32.29166666666681 44
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 34.375000000000156 55
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 34.375000000000156 66
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b898> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b6d8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83f98> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72d68> 4.166666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 10.416666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 30.20833333333347 40
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 33.333333333333485 45
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 35.41666666666683 56
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 35.41666666666683 67
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9e2e8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72d68> 5.208333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 11.458333333333385 15
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 31.250000000000142 41
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 34.375000000000156 46
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 36.4583333333335 57
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 36.4583333333335 68
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9e630> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 6.250000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 12.500000000000057 16
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 32.29166666666681 42
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 35.41666666666683 47
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 37.50000000000017 58
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 37.50000000000017 69
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ecf8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72d68> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 13.541666666666728 17
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 33.333333333333485 43
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 36.4583333333335 48
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 38.54166666666684 59
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 38.54166666666684 70
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9244630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3efa128> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d42c88> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226d68> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 13.541666666666728 18
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 33.333333333333485 44
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 36.4583333333335 49
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 38.54166666666684 60
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 38.54166666666684 71
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #4
root->2->18->1->1
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 7.2916666666667 10
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 14.5833333333334 19
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 34.375000000000156 45
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 37.50000000000017 50
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 39.58333333333351 61
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 39.58333333333351 72
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3efaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3efa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226e48> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 7.2916666666667 11
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 14.5833333333334 20
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 34.375000000000156 46
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 37.50000000000017 51
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 39.58333333333351 62
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 39.58333333333351 73
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3efafd0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 7.2916666666667 12
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 14.5833333333334 21
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 34.375000000000156 47
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 37.50000000000017 52
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 39.58333333333351 63
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 39.58333333333351 74
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83710> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 8.333333333333371 13
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 15.625000000000071 22
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 35.41666666666683 48
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 38.54166666666684 53
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 40.625000000000185 64
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 40.625000000000185 75
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ed30> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ec50> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3efafd0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 9.375000000000043 14
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 16.666666666666742 23
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 36.4583333333335 49
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 39.58333333333351 54
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 41.666666666666856 65
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 41.666666666666856 76
Completed Iteration #10
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6390> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb61d0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83710> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 10.416666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 17.708333333333414 24
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 37.50000000000017 50
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 40.625000000000185 55
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 42.70833333333353 66
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 42.70833333333353 77
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6da0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 11.458333333333385 16
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 18.750000000000085 25
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 38.54166666666684 51
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 41.666666666666856 56
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 43.7500000000002 67
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 43.7500000000002 78
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9eef0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb67f0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ed30> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ec50> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3efafd0> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 12.500000000000057 17
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 19.791666666666757 26
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 39.58333333333351 52
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 42.70833333333353 57
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 44.79166666666687 68
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 44.79166666666687 79
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8bf28> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 13.541666666666728 18
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 20.833333333333428 27
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 40.625000000000185 53
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 43.7500000000002 58
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 45.83333333333354 69
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 45.83333333333354 80
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d8d05f60> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 14.5833333333334 19
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 21.8750000000001 28
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 41.666666666666856 54
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 44.79166666666687 59
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 46.87500000000021 70
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 46.87500000000021 81
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #5
root->2->18->1->1->7
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6da0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 14.5833333333334 20
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 21.8750000000001 29
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 41.666666666666856 55
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 44.79166666666687 60
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 46.87500000000021 71
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 46.87500000000021 82
Completed Iteration #1
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3efad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 4.166666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 14.5833333333334 21
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 21.8750000000001 30
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 41.666666666666856 56
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 44.79166666666687 61
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 46.87500000000021 72
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 46.87500000000021 83
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 4.166666666666686 8
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 14.5833333333334 22
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 21.8750000000001 31
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 41.666666666666856 57
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 44.79166666666687 62
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 46.87500000000021 73
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 46.87500000000021 84
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41780> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 5.208333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 15.625000000000071 23
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 22.91666666666677 32
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 42.70833333333353 58
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 45.83333333333354 63
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 47.916666666666885 74
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 47.916666666666885 85
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41780> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 4.166666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 5.208333333333357 10
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 15.625000000000071 24
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 22.91666666666677 33
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 42.70833333333353 59
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 45.83333333333354 64
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 47.916666666666885 75
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 47.916666666666885 86
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b438> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b278> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41780> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 5.208333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 6.250000000000028 11
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 16.666666666666742 25
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 23.958333333333442 34
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 43.7500000000002 60
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 46.87500000000021 65
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 48.958333333333556 76
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 48.958333333333556 87
Completed Iteration #10
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b940> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b780> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b438> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b278> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41780> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 7.2916666666667 12
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 17.708333333333414 26
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 25.000000000000114 35
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 44.79166666666687 61
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 47.916666666666885 66
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 50.00000000000023 77
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 50.00000000000023 88
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3efa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6da0> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 6.250000000000028 10
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 7.2916666666667 13
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 17.708333333333414 27
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 25.000000000000114 36
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 44.79166666666687 62
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 47.916666666666885 67
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 50.00000000000023 78
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 50.00000000000023 89
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 7.2916666666667 11
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 8.333333333333371 14
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 18.750000000000085 28
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 26.041666666666785 37
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 45.83333333333354 63
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 48.958333333333556 68
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 51.0416666666669 79
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 51.0416666666669 90
Completed Iteration #18
Best Reward: 1.0416666666666714
coverage_call_count 7000
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b4e0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6a58> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 8.333333333333371 12
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 9.375000000000043 15
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 19.791666666666757 29
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 27.083333333333456 38
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 46.87500000000021 64
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 50.00000000000023 69
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 52.08333333333357 80
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 52.08333333333357 91
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b390> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b550> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b940> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b780> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b438> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b278> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41780> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 9.375000000000043 13
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 10.416666666666714 16
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 20.833333333333428 30
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 28.125000000000128 39
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 47.916666666666885 65
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 51.0416666666669 70
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 53.12500000000024 81
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 53.12500000000024 92
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #6
root->2->18->1->1->7->10
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5bd68> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 10.416666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 11.458333333333385 17
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 21.8750000000001 31
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 29.1666666666668 40
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 48.958333333333556 66
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 52.08333333333357 71
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 54.16666666666691 82
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 54.16666666666691 93
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d9226780> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b278> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41780> 5.208333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 11.458333333333385 15
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 12.500000000000057 18
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 22.91666666666677 32
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 30.20833333333347 41
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 50.00000000000023 67
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 53.12500000000024 72
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 55.208333333333584 83
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 55.208333333333584 94
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e61d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6390> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb61d0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d8c83710> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 11.458333333333385 16
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 12.500000000000057 19
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 22.91666666666677 33
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 30.20833333333347 42
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 50.00000000000023 68
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 53.12500000000024 73
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 55.208333333333584 84
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 55.208333333333584 95
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03a90> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 12.500000000000057 17
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 13.541666666666728 20
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 23.958333333333442 34
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 31.250000000000142 43
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 51.0416666666669 69
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 54.16666666666691 74
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 56.250000000000256 85
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 56.250000000000256 96
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5bba8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226630> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b4e0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6a58> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 13.541666666666728 18
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 14.5833333333334 21
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 25.000000000000114 35
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 32.29166666666681 44
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 52.08333333333357 70
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 55.208333333333584 75
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 57.29166666666693 86
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 57.29166666666693 97
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e61f60> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6a58> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 14.5833333333334 19
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 15.625000000000071 22
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 26.041666666666785 36
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 33.333333333333485 45
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 53.12500000000024 71
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 56.250000000000256 76
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 58.3333333333336 87
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 58.3333333333336 98
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #7
root->2->18->1->1->7->10->8
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8bf98> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d9226630> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b4e0> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6a58> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 15.625000000000071 20
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 16.666666666666742 23
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 27.083333333333456 37
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 34.375000000000156 46
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 54.16666666666691 72
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 57.29166666666693 77
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 59.37500000000027 88
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 59.37500000000027 99
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e036d8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03a20> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e61f60> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6a58> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 16.666666666666742 21
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 17.708333333333414 24
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 28.125000000000128 38
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 35.41666666666683 47
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 55.208333333333584 73
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 58.3333333333336 78
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 60.41666666666694 89
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 60.41666666666694 100
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120f0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03ef0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5bba8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d9226630> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5b4e0> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6a58> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 17.708333333333414 22
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 18.750000000000085 25
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 29.1666666666668 39
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 36.4583333333335 48
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 56.250000000000256 74
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 59.37500000000027 79
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 61.45833333333361 90
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 61.45833333333361 101
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12cf8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6a58> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 8.333333333333371 9
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 18.750000000000085 23
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 19.791666666666757 26
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 30.20833333333347 40
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 37.50000000000017 49
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 57.29166666666693 75
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 60.41666666666694 80
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 62.500000000000284 91
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 62.500000000000284 102
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b400> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b4a8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12cf8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6a58> 8.333333333333371 9
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 9.375000000000043 10
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 19.791666666666757 24
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 20.833333333333428 27
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 31.250000000000142 41
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 38.54166666666684 50
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 58.3333333333336 76
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 61.45833333333361 81
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 63.541666666666956 92
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 63.541666666666956 103
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e036d8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03a20> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e61f60> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6a58> 8.333333333333371 10
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 9.375000000000043 11
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 19.791666666666757 25
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 20.833333333333428 28
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 31.250000000000142 42
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 38.54166666666684 51
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 58.3333333333336 77
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 61.45833333333361 82
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 63.541666666666956 93
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 63.541666666666956 104
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03da0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03a20> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e61f60> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6a58> 9.375000000000043 11
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 10.416666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 20.833333333333428 26
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 21.8750000000001 29
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 32.29166666666681 43
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 39.58333333333351 52
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 59.37500000000027 78
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 62.500000000000284 83
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 64.58333333333363 94
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 64.58333333333363 105
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e61470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03da0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03a20> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3e61f60> 3.125000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6a58> 9.375000000000043 12
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 10.416666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 20.833333333333428 27
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 21.8750000000001 30
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 32.29166666666681 44
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 39.58333333333351 53
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 59.37500000000027 79
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 62.500000000000284 84
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 64.58333333333363 95
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 64.58333333333363 106
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03898> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3eb6a58> 10.416666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7f10d3e9ee10> 11.458333333333385 14
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b588> 21.8750000000001 28
backprop <src.mcts.MCTS_Node object at 0x7f10d8d72898> 22.91666666666677 31
backprop <src.mcts.MCTS_Node object at 0x7f10d9226cf8> 33.333333333333485 45
backprop <src.mcts.MCTS_Node object at 0x7f10d92b6be0> 40.625000000000185 54
backprop <src.mcts.MCTS_Node object at 0x7f10d927a978> 60.41666666666694 80
backprop <src.mcts.MCTS_Node object at 0x7f10e1f25cf8> 63.541666666666956 85
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7898> 65.6250000000003 96
backprop <src.mcts.MCTS_Node object at 0x7f10db7d7c88> 65.6250000000003 107
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #8
root->2->18->1->1->7->10->8->10
Best Reward: 1.0416666666666714
iteration: 179
found coverage increase 1.0416666666666714
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e5bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d8d720b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e61748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 34.375
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e122e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e122e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e8b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37efbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3efa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e41f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef780> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 34.375
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e61748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e120b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e61c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 34.375
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e122b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 34.375
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37512b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3751630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3751a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3751a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3751ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3751860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3751d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b26d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3751978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2550> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3751e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37c73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3751c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5e48> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37604e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37072b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37efcc0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3716240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37167f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3716470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37078d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37078d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37078d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3716240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3716470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3716240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37078d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37321d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37327b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37329b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37329b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3716eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37325c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37167f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3716eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37326a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3716400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c36d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d37322e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3716e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37070f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37070f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37070f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37079e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e1b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e03cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3751908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37070f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3707a58> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e616a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3751278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e616a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37a52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36990b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3699390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3699550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3699710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36884e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3699da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e038d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36997b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e038d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e038d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3716a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e038d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e12b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e038d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d3699940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e61e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3751e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37606a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3751278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3751278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3751278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37607f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37607f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37607f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d8d64da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3760f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3751278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3707f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37606a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37607f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3760630> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36996d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3699be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3699358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36996d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aaa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36996d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3699a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aaa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36996d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d3688390> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 34.375
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3670588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3670080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3670710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d360b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660828> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d360b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3670d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3670400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3670588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3670470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3670da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3670fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3670128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3670da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36708d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3699b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36881d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3670da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d360b1d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3670630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3670cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3699550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3670160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3670cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36706a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3670cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699198> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d360b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d360b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d360ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d360bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36376a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3637860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3637908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3637b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3637438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360bc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3637a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3637ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3688dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3637e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d360b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31c9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31c9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31c9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31de390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d360bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31c90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3637dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31de7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31c9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36379e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31c90b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36379e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36379e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31c94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31ded68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3637eb8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3637438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37a58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3637860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31de518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31decc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 7600
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d360be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d360bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d360b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36376d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3797cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31c9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36f7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360b8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e61e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36376d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3637be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3707b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d360bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31f2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31f22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3760f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31f2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31f2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3193080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31f2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3688748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3193780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3193940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3660cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31f2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3193b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36aaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d360bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3688588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 34.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3193da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3193cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3193908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3193e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3193e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31a5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3193ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3193f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3670908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3751e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3688be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3699390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3660b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31a59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31f2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31938d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3193390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31a52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3193588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3193160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31a59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31938d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31f2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31a52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31a59b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3193e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31a5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31a5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37070f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d31938d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31a59b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3193e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f10d31a5ef0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3193160> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 2.0833333333333286 22
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #0
root
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31bc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3193160> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 2.0833333333333286 23
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3193978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31bc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3193160> 2.0833333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 2.0833333333333286 24
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31f25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3193160> 2.0833333333333286 6
backprop <src.mcts.MCTS_Node object at 0x7f10d31f29b0> 2.0833333333333286 25
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #1
root->7
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
coverage_call_count 7700
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #2
root->7->26
Best Reward: 2.0833333333333286
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 2.0833333333333286
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10f4519668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3193048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31bcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31bc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10f4519b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3716668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3716a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31bcdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31bcdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d31bcf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3732a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d3732128> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37b26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37321d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d37c7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d3e3a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d31bcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f10d3732518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f10d37b2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f10d36c3898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 36.45833333333333
initial coverage: 5.20833
time passed (minutes): 60.1338
iterations: 206
number of new inputs: 832
final coverage: 36.4583
total coverage increase: 31.25
