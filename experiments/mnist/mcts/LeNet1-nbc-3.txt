Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f886c653f28>, tc2=<function tc2 at 0x7f886c664048>, tc3=<function tc3 at 0x7f886c664158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 29.1667
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8769fd0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f87777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f873d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8777278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e37f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e37f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f873d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3b38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86979e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86975f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f873d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f49b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8777278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f873db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86978d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86978d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86522e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e35c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86529b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86522e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86529b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865ff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f865f3c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86527b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86527b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86527b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd860> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86520b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86520b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 200
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8652898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87880f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87880f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87881d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87880f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87880f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87966d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8796a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87967f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87441d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87441d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87447f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87968d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87880f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87445c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87441d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d8744208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f873d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f87775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f87775c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f873d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f87775c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8777748> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f865fda0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87444e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87188d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc88> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f87775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fc50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 8
Completed Iteration #11
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf9e8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ca20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1b70> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788860> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 6
Completed Iteration #7
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86529b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86529b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652470> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8648c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8648748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8756160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8756240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8756048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744dd8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f875ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8769080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8769da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304b4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304b4f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886ecae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f875ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f875f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f873db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86527f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f875f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304b4f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f873d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8777780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652be0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8769a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c74a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87960b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c74a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8769da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c74a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86482e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d868cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86482e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d868cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8718668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86527f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86527f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f873d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87188d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87188d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87188d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87183c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 800
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a55f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdc88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8777400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f873d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8718c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 900
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86615f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86615f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86615f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beef9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86615f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87d86614a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87beeb47f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee541d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87447b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87bee54668> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f87690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f875fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876f940> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 1100
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1086d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1082e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1082e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1086d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86619e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86619e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86619e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86619e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86619e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea198> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f70f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cc0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0877f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0877f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c97b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdda0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0491d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0491d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0491d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0491d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0496d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eadd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1182b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901309e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901309e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c94a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901309e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901303c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901306d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee549e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee549e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc087b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901437b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901437b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900faac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901437b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901437b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901139e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 29.166666666666668
coverage_call_count 1500
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901137f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901132e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901137f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900faac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901133c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900facf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900facf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900facf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901133c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a59e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0493c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a56d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0493c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 15
Completed Iteration #22
Best Reward: 0
coverage_call_count 1600
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900714a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900b8198> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 6
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900807f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 8
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8769278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 9
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8769278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f87848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f87848d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef90f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f87848d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef90f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beef90f0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8790080f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87880f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f875fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8796518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87880f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8838950470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304b4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304b4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8838950470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304b4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87886a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87886a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867cb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87442b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87442b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8756240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8756080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8756080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8756048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8886edf5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 1800
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8756198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900716a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8661940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f87776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb49e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb49e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb45c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8777400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8438> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86486a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87447f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87447f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87447f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86526d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86486a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d8652940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8718da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 21
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8718da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bee42c50> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1086a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1086a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee424a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc1085f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc1086a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1189b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7908> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87186d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130748> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86978d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0677f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0677f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86978d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87bc0675c0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 6
Completed Iteration #10
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8777400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc067da0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0493c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b0f0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1189b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900a5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790143240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901439b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87961d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0875f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ece80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0493c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faaba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb90f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f570f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f570f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fad68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fad68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faab00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0872e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113710> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f689e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f689e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f689e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f689e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c88> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aba8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900faac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f686a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f879015bb00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e862e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efa7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e862e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e862e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e86518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781efaf98> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e862e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e862e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e862e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781e95390> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 2600
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900faac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900faac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4a8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e955f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781e750f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 13
Completed Iteration #19
Best Reward: 0
coverage_call_count 2700
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e568d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e637f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781e75080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d872e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d872b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d872b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d872b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d872b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d871d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d967b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780d962e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901135c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901135c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 10
Completed Iteration #16
Best Reward: 0
coverage_call_count 2800
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d961d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86974a8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901439b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901439b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790113d68> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0673c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0673c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901132e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0673c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901132e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901132e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc067ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc1083c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc108c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bee42780> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee429b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901303c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 2900
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901134e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0381d0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87186d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879016a358> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d964a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee429b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d964a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee429b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8756278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f88304c74a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8648e10> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8756198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 3
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8744a58> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86529e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8769d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86529e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86529e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86527b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86527b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900802b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900802b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091a58> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86529b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8756240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900719e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900911d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8781f68780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df75f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e860f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e75358> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e86b70> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e868d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f574a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e868d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8652e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0876d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0876d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790091a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0872b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900faac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec04e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f577b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f577b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 14
Completed Iteration #20
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f68c50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e639b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e639b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e639b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e569e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1860> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1f60> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 3600
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec00f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec00f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8790071898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804836a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804836a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804839b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804839b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804afc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804af908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804839b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804839b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804839b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049fbe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804d4a58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 3700
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804750b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804753c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804758d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804758d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8648ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804654e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804afe48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804038d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d48d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d48d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d48d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d48d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d48d0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804035f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804347b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804343c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804343c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767feaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804344a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767feac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767feadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767feae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767feaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feaa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804346d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767feacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f878049f9b0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 3900
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb49b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804032e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f837b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb49b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f434a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b208> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f836a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f435c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f831d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f831d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f836a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f435c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f831d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87804751d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f255c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f255c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f309e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f25048> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f83710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f305f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4100
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8aeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8aeb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a4a8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8afd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767efb7f0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c8d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ca20> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e496d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 21
Completed Iteration #24
Best Reward: 0
coverage_call_count 4200
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e073c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e073c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e079b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e079b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e079b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e077b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e077b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901135c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804afb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e95198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781e95278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee542b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c67f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cdfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c88> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e07240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87901131d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 13
Completed Iteration #20
Best Reward: 0
coverage_call_count 4400
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0876d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f579b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e860f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781f57f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f579b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f579b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781f57860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781faaba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901135c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e959e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc087358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a198> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8652a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 4
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e754a8> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87cf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee54a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e070f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bee54a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f879015b588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc87b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc87b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c18> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900913c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8777780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790071f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8661eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87446d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8777780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87446d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900913c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87901306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900913c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900913c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cda58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0498d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efaa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900b83c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 4700
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d872a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee42ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc049c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc067198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0499e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aa58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc067080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790071a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8784860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8788208> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f878049f7b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df76a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d870b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d870b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d870b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c4a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900916a0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d964a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a5e80> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767feaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804030b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feaef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767feae10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 4900
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d867c1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beef9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87900a50f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767feaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780db1470> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8780475fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804d42b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 5000
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780483b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8788208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ba8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790113a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804752b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd59e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f433c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f436a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f433c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5fd0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f430f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f430f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f430f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fd53c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f256a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f302b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f830b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f256a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f256a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fea320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e185f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a5f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670935c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670937b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080a58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 5300
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87670cba90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f302e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670806a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706da20> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876706d550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cb0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b62b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876700f3c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876703ea58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 2
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766badc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766badf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670809b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766badf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766badba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f25b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766badba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b643c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b643c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766badd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b565f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766badb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766badf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766baddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766baddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766badf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 5600
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876703ec88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b114a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b118d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b114a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b114a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766b11518> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b117f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b117f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 5700
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b647f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2048> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b560f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b560f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aefb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b560f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aefba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aefe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aeff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a849e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a849e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a849e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a92f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a920f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a929b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a92f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a846a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aefda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aefd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766badef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766badf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aeffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aefd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766aef668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a846d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa97f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa97f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aefdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a92208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a92208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a84630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a75470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a75240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a75b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a75470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c470> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a842b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4ea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a92668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a636a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a636a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
coverage_call_count 5900
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aefd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a114a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a92668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aefd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75dd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766badf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87663c1668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663ebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663ebeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663ebeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87663d09e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8784ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b80f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86f49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b80f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d0048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900b8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbb38> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879016ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd3c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016ae10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ee80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670807f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670807f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670807f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767080518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670807f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670a6470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc087780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b644e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 6100
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bbba90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bbba90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87663d0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efbdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87663d0cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f302e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f302e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f30f28> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f258d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8648160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f258d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f43a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f257f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767080710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f257f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f30828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767093588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8718d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86e1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfdb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900b80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 6200
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804833c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767feab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804833c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4dd8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f25fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d968d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780db15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d968d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780403b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780403128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc05add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b64828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b6a0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f30b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f258d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8796780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f258d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780403a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fd5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767f258d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d875c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 22
Completed Iteration #22
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780434fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780434c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d873c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670cb358> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc108a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc067a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee42438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790091080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df77b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f875fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804d4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780dd15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc108be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780df7128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f88304c70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790091710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc049828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879011b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c96a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781faa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879016a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8796780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc038e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beef9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790130588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767093588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670cbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670b69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767efb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f257f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f257f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790080c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 6400
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8777668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8756278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8777780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bee54358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8661eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87bca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d868c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8652ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8886edf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bfd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86cf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8700dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d86617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804af320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767efb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f879015bd30> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790080710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879016a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f879015b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f6e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8700780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d876ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804aff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87d87440b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d87c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f8697cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f865fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d96f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 6500
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767feac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780df7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bbb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780db1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee425f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc118550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc118be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e86470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780483048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bee425f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b64860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87beeb4a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781faa208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049fef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767feac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f865fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d872afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780dd1be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e95ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f2a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bd27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e75908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8661898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780d87cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc038e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc1088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e56be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0495c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8744710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d876f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f878049fc18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790130ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 6600
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb44a8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e184e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e184e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e184e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c748> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e18e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d868c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663d0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879011bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f879015b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790113c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87670a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781efa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781efa320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bd2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f300f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767feaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f300f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f8769128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f1e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876703e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804c6668> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e6ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f68240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e072b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e072b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8790143fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a113c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f57ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e072b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d8652908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87f86cdf28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aefe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aefc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aefcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790071a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aefac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8652908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a118d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aefac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aefcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87804757b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aefcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a118d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aefc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781f57ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781f68240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11ba8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a117b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e56a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87901434e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d8744b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d867c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e072b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a112b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900fa7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4cf8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766badef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e6a668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fb48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e5ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e86ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f878049ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e18d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e75860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87bc0f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767fc8b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780d96860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780475e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e49940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766badc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766badac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87900ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f833c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766badc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766badc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87900ecf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f87691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663c1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781ec0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8780465b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87f86cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd3c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87804c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e07f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a11978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767f83c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e07dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b2c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b2ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b114a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fc86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b114a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b114a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec59b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a75cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a75b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a75e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a75cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a756d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a925c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a756d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87d87a5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876706d828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9a90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a925c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a92908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a75b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b114a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a756d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b110f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876703e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876707e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a756d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a92908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c208> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8780475898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766badac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a11dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a75a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a630f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87658353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766aa99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87658356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a630f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a630f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a752e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766b112e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651cd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651cd390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651cd390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87658352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651cd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765835630> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781fb9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b116d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766bdd4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e588> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766badc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b110f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a925c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a925c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766badc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ff4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876700f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766badc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766badc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a925c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b110f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a752e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ffc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a752e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a92240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e072b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ffef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651fff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ffb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e072b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651fff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e072b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e072b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e072b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518ec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a4eb00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ba908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ba6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aa9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651bab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ba6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651bab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876700f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ba470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b3c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a4128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766aef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ba470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87651a4e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ff0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ff198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a929e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767ec5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a929e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b110f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ff6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a929e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a929e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ff198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ff198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876518e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876518e2e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651baeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651bae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767fb4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87663eb898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ff240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765835b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87658356a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765111390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765111710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765111b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765111eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765111fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765168a90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 29.166666666666668
coverage_call_count 7300
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651baeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8790143f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a84390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767f83f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ba588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ff160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651fff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ff160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651a40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765111da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651215c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b11588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765087588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765087630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 20
Completed Iteration #23
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650f2208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87650e3400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651215c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876517fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b116d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a75748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651bac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765111a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765111278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651bac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87663eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876706d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765111da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a84390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765087908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765087358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650f2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765087cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651a47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765087198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765087550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650bea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650be6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650be470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650be470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650494a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650be240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8767e8a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650be748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650beda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765049390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8781efa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f876505e198> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8767e9cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a63ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b11d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650be588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651ffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087cf8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765111a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765087940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a4e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765087c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765018470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766b56860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650beac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650c6c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765018278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ff0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765018898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a634e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765018c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765018e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765018c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650270f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765018828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765018c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765037470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765037630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765037588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765037278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765037ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650276a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765018780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650376a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650183c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765037208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765037240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766b56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650279b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765018ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765018ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765018940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765037eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650375c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765018c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765037198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765018a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765168fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876518e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650bee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a847f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876707e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765018a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765087198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650bee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a63240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765168c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f876505e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766a751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765121f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650182b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bcea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bcef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bcefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bceda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764bce518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b81080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b81358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b81518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bceeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b81898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b81a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b81668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765049ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b81198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bceeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bceda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764bce518> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8765111208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 297
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b81828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b81128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bceb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765087c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e320> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 298
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b81630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765111908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b81ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bcefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650e3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650f2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87651cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876517fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87651ff0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f876505e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765121630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bcea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8766bad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8766a634e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 299
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765018828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765087240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b812e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bacdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b81a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bacf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765087fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bacd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bacef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b8e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bacac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b53550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bacac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b53710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b53208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b53a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8765027d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b539e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bacef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764bce978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8765037780> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 300
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b53cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b53860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b630b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b63e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b53518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b53a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b636a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f87650beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b636a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b53320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b537b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b630b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b53860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b53860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b81908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b636a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 301
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b63400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b0f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b0f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b0f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b0f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b534e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b0fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b0f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b0fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b0feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b0ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b1e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b0f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b1e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b0f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fb70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b63240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b63c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f748> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 302
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765027d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b0f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b53860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b635c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b53a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b53b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b0f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b0f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 7800
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b637b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b53748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b0f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b53be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764bac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b63eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8765835c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b53b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8764b6f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f87650bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8764b6fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8764b63eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8764b63ac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 303
found coverage increase 0
Current Total Coverage 29.166666666666668
initial coverage: 29.1667
time passed (minutes): 60.3631
iterations: 304
number of new inputs: 0
final coverage: 29.1667
total coverage increase: 0
