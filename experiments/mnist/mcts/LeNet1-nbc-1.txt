Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f0763450f28>, tc2=<function tc2 at 0x7f0763461048>, tc3=<function tc3 at 0x7f0763461158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 29.1667
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86635f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86bd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86bd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86bd0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86bd0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86f72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86bd0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86f72b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f8663ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87e51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86746d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86746d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86746d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5828> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863df60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d874b8d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 200
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87286d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8719cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87282b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d879c0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86995f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86824a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19b0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87196d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87620b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 400
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87620b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87196d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86adba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86addd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86821d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86adcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87196d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86adac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86997b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4d68> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67981d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0080> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab940> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab940> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab940> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab940> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab940> 0.0 7
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b59aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab940> 0.0 8
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab940> 0.0 9
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b59aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab940> 0.0 10
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f650fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab940> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab940> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f6635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab940> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8704e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8704940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f6631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8704dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8704940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8704ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8704ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8704a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8704ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8704ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8704940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f072f663198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 600
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f87048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d62e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67831d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67831d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67832b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67832b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67832b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67832b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67834e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67835f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d873bc88> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f7873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f87048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f663208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8704f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67839e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67839e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863dd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87620b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f864ae80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86992b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87624e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f6632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f876f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f876f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8704eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87286d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67839e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f663898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67839e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67839e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86f72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f876f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 29.166666666666668
coverage_call_count 800
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86740f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86826a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86826a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86829e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86748d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86748d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f663898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8704f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 16
Completed Iteration #21
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682588> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86adc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8719cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5c0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8704f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87280b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 1000
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87917f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41944a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41949b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41949b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b673dbe0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca90> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca90> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67838d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4194160> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41157f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41159b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41159b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b70> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41051d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41051d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41051d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b414f710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41245f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41245f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41245f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b412a710> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 12
Completed Iteration #11
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a90> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40750f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f876f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41946d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40948d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 4
Completed Iteration #7
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045358> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40524a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96bda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40455c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4052dd8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40520b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40520b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f98> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93eba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41246a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af97cac8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9192e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40456d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40456d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673df98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ab38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af919ba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c9e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 17
Completed Iteration #24
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ace80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f078a97e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87df28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41155f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b41155f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4075588> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 15
Completed Iteration #22
Best Reward: 0
coverage_call_count 1700
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87190b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0b38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86adeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca20> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40750f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87913c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8704fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87195f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40756a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40756a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 1800
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87285c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8704d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8704f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f864a630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86bd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40757f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41944a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412aa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40751d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40751d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f7104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b59af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f7104a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67834a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40751d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f7104a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86f10b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86d61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b59af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f663048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f6630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40754e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40754e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40754e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4075518> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af86c4a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b41059e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41059e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41056a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41059e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f6630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f6631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f6631d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40526a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f650ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40945f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af919588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4045860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045860> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86630f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86630f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f650ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86630f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40665f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8aca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8aca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ae80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b6798a20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f6631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a20> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 2200
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b414fb00> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f663048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40666a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40666a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b40668d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41247f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41247f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af90cb00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 2300
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41246d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f663048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41246d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af956668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8295f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8295f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8290b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4066860> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf247b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8292b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8292b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24240> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf247b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 2400
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8297b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066cf24898> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ceddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ceddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ceddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd320> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce998d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce998d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cedd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 29.166666666666668
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ceddcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066ce99470> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf249e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce735f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce73668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919208> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf26a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddda58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 16
Completed Iteration #24
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddd4a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce73780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829eb8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf29e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ceddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf26d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf29e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fda7f28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 2700
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ceddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebdd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebdd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f663048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f663128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86999e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab240> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab240> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41944a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41944a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41944a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41159b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86d60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67835f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f86d60f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40752e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f650fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f650fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f072f650fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699630> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f663160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864a668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4cc0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86820b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412af28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f8674470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f864ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8663518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783908> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f874d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f874d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f874d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f874d3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f874d3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f874d3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40522b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41246a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06d8699898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f87048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f650fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdddcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d866c860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93eb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c588> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af97c898> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f07200dd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af829e10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f87048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86c6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4045e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebdfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebdfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd860> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5160> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f065fddd240> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd469e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ceddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddc88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ceddda0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41056a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41056a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41056a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf60> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41058d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b414f4e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6745c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6745c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6197f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f619b00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ceddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065f63b978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef982e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef850b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef850b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef856a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff79b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef85780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f63b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef853c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f674ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f674cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef51cc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6749e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f67fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f6745f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 3900
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff75c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef360f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef368d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef368d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef360f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef360f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619d30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee34e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee34e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee982e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee982e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee982e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb32e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3828> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee767f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee767f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee767f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee76940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef362e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef362e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee898d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee769e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee89a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee76f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2db38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ee98550> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 4200
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e985518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec87f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff72e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef985c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef857f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8704f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba8d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bdd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd463c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd463c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ceddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4066be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4066f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af90c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced00b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cfd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced00b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cedd400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ceddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced04a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af88fa20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 29.166666666666668
coverage_call_count 4500
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af9196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8728780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af919438> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce73860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06af919be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066ce991d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce99080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf244a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf244a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf244a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ceddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41245c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4052a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f864a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 4700
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791438> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41242b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad2e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f710470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67834a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066cf24da0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8299e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8299e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f77e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af8298d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8663da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 14
Completed Iteration #15
Best Reward: 0
coverage_call_count 4800
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86636d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce439e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce439e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4194b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d86825c0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41154a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41154a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41154a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e9e52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f077b5b1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41942e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40526a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2deb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee2deb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce733c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e9e54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e54a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e54a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e54a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2deb8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 3
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 4
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c1d0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 5000
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1add8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1add8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1add8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee769b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee769b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cdd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee767f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb34e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee764a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee764a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee989b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee989b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee989b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f6741d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce437b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fddd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f780> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9858d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9858d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 19
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9857b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9857b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a20> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9852e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0523c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0523c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0523c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ee41630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 5200
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef51240> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee41710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86746d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0010b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e052780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1af60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e052780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee41240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0101d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0101d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b58d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0107f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0107f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e001b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0017b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0299b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e029b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee419e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0386a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0388d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0388d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0386a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee419e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee417f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db809e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db804e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbea2e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0386a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e052b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0011d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0526a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e052b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db495f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db495f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db495f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db495f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbda0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db634e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db634e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db497f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db497f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db497f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 21
Completed Iteration #22
Best Reward: 0
coverage_call_count 5500
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db636d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db055f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db052b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db052b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05390> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dacecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dacea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daceef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daceef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daceef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daceef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dacee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0386a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0386a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0386a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0109b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0109b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbb38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa40f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da969e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dab4668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dab4cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa40b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065daa4b70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daceb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daceb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daceb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daceb00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db75128> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da734e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da731d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da730f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dab4a58> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da290b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73668> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da29400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7dda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da739e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da150f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da739e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da152b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da739e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0524e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da29f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da29f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da297b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da297b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da297b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0524e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db492b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db492b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db492b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfbe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5883c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5883c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5881d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5887b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da29b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da29ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59be48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da155c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d59b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d560048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d560908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d560ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d59b518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d560d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d560e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d560a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d560208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d560518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5608d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5608d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4194eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f710470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560860> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d560f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6798668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6798710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4105748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd469e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da7d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d560710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd469e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd46240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db057b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db057b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db057b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbd30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e001b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0012b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0296a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0108d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0108d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0108d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0296a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0296a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0108d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e029240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b6783668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db49b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db494e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d560080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e010278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d560588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 4
Completed Iteration #7
Best Reward: 0
coverage_call_count 6100
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5603c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da7de48> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee89940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f63b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065dbbba20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4075320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee984e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eee3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eeb3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4075710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ee985f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da7d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee98c18> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b6783470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 6200
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db49da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d560550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4094ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e001240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b4105e48> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce437f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4094630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f77e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86636d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e001908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdc60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b673d588> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e029e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd7de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db05a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0101d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d866c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 6
Completed Iteration #8
Best Reward: 0
coverage_call_count 6300
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4115550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41157f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db051d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eeb34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fda71d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d554048> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86dfef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cea5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b412ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d873b5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d51d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b413cf28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8791f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d866c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d874b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d873b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b412af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4052b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b413cef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41158d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd7db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db051d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e010e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af829ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db051d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f874d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86ad8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8719b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bddd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eee3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cf24b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f06af8acb38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af97c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af919b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87d908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af88f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b673d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af93e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef51c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdf2860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af93e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af919780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d879cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86cc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af93edd8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f863d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af86ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af956898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d879c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce99080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ced0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf24940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b67d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f8674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db75e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066ce43e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8791f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8762898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f63bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41151d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee2d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db75358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4124f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db75e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4115550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065f67f710> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 6500
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cedd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92acf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af92ac88> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d864fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b41943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b40d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eff7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62b0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e029438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee98748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f8674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d86f19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef85710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd3e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af92a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065f62bda0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef5f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b40527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f874d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da7d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ced0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67c04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbbbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f67f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eff7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b4045ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b413c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdf29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f6193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8acef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d864fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b414f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f62b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06b67abe10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fddde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af92a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af8bd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9852b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d874b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b414f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e985a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9852b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bd30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd46cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cea5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fdba2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdbac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9850f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cedd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d554550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fdba828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af97ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af956cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd2b438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f072f6652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41154a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d87285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41154a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41154a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af829860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41154a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef36da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06b41154a8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e0b5f28> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 29.166666666666668
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da156a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da156a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da156a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da151d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d86998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8719be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da153c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af90c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef983c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef98208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef98390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e985320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9f39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ef6eb70> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4045cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cebdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06f86d6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8728470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec84e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec84e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065f619cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da15c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af8acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f066cebda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd2bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dacec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dacef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af9566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065daa4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee0c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4be0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef98860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8682240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066cf245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f619c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af90c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065eec8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce73438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d59b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db802b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db805f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06d8699ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da737f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fda72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fdbac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dacea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da737f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f06d8699a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db80b00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dace9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee76828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee762b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbea240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dadc390> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee89940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db634a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af86c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da73a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef2a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dab4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef36320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065db80048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a58> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da29e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da29f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da29da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dace668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da15898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da29080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 13
Completed Iteration #18
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0522e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3efd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da96940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e052400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da29198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e052390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da29dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef36320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da29278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e052390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e052400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e052390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0389e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e038748> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dadcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e052208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e052208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da15898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dbeafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db91160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db3e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065da96f98> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d59b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db634a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db634a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5884a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d573240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d573320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d573860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 7100
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d573240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5883c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d573fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dbeaf98> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd1ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dacea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5dca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d588ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da96d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f86d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f86d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d573eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d573c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0529b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db91160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065daa4c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f62b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065db63550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dab48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065da96550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065dadcd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d588e10> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb060b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb064a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb069b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb061d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb231d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c978> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb23828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb23a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb23c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb23978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb23080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb237f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb353c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb239b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb23c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb237f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 15
Completed Iteration #14
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb353c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb23a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb23278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb237f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb23160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb232b0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb23320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb23f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb061d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af96b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e9e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb56f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb56f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e038390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb061d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee1a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065e038390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065db3ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dacea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d573ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d573ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d573ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d588748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d573ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d588748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065daa4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e0384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb358d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d573ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065da73a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d573ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cafb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cafb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cafb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cafb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cafba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cafbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cafba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cafb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafbb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cafbb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 8
Completed Iteration #11
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cafb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cafbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cafb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f066ce736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c2b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5887f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0529b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5887f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0529b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb23cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e0529b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06af87dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065dacea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ee41e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb56860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cafb160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb56860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb56860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c7f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca64518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca64518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca646a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca64518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca64320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca76208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e038390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca64160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca64518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca64518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca76518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca64400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 7400
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca649b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca64400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca649b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065f67f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cafba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca64400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca76160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d588748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb35940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb35d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb23128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065e9e53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065d5f8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca76438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb06390> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca76cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca331d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca33470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca33518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca33860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca762b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca33908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca33fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca33e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca33c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca33d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac41d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca330f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca33a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffcf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffcf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffcf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca33ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca33f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcf748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcf518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcf748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffcf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcf2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffcff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3eb00> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca332e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca33438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca33898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca337f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065fd5dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffcf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca76048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca33898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca76f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca76860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca33898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca760f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca33da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfb70> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cac4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca76630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffcfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca334e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ffb05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff48cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff48da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff48588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ee48> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca9b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff48c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff484e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff485c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff484e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff485c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb56b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ecf8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065e052ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ee41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f06b4124f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca8c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca76828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca64cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065eec8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb06da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff48940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca339b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ef85a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca339b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca76048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 297
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca33da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 6
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 7
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 298
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff27048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff27358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff27400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff27978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff273c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff27a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff27c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff27198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff273c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff27320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff272e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff37320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff27e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff279e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff27b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff279e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff27f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff27f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cac4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff27f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff273c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a1d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 299
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff27cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff27d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff27da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff272b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065d5734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca3e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff27cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca76fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca5aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca33588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065ca9bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f065ca8cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff0a0b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 300
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ffe9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff37940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff37dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff377f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff37f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063fee7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff37fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff37470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff5f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063fee72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff8f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f063fee7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ffb0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f065cb7c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f063ff9e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f063ff48438> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 301
found coverage increase 0
Current Total Coverage 29.166666666666668
initial coverage: 29.1667
time passed (minutes): 60.2306
iterations: 302
number of new inputs: 0
final coverage: 29.1667
total coverage increase: 0
