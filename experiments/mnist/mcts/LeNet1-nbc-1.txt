Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fe7ff63bf28>, tc2=<function tc2 at 0x7fe7ff64a048>, tc3=<function tc3 at 0x7fe7ff64a158>, tfc_threshold=33000000, time_period=3600, verbose=True)
initial coverage: 5.20833
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0564e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0564e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 5.208333333333334
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 3.1249999999999982 14
Completed Iteration #17
Best Reward: 3.1249999999999982
Completed Iteration #18
Best Reward: 3.1249999999999982
Completed Iteration #19
Best Reward: 3.1249999999999982
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 6.2499999999999964 15
Completed Iteration #20
Best Reward: 3.1249999999999982
Completed Iteration #21
Best Reward: 3.1249999999999982
Completed Iteration #22
Best Reward: 3.1249999999999982
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e4e0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 8.333333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 8.333333333333329 16
Completed Iteration #23
Best Reward: 3.1249999999999982
Completed Iteration #24
Best Reward: 3.1249999999999982
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ec18> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e9b0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e4e0> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 7.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 7.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 10.41666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 10.41666666666666 17
Completed Iteration #25
Best Reward: 3.1249999999999982
Completed MCTS Level/Depth: #0
root
Best Reward: 3.1249999999999982
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 9.374999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 9.374999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 12.499999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 12.499999999999993 18
Completed Iteration #0
Best Reward: 3.1249999999999982
Completed Iteration #1
Best Reward: 3.1249999999999982
Completed Iteration #2
Best Reward: 3.1249999999999982
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028518> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 12.499999999999995 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 15.624999999999991 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 15.624999999999991 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 15.624999999999991 19
Completed Iteration #3
Best Reward: 3.1249999999999982
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028860> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028710> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 16.666666666666657 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 16.666666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 16.666666666666657 20
Completed Iteration #4
Best Reward: 3.1249999999999982
Completed Iteration #5
Best Reward: 3.1249999999999982
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028e80> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 8.333333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 13.541666666666663 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 16.66666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 20.83333333333332 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 20.83333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 20.83333333333332 21
Completed Iteration #6
Best Reward: 4.166666666666666
Completed Iteration #7
Best Reward: 4.166666666666666
Completed Iteration #8
Best Reward: 4.166666666666666
Completed Iteration #9
Best Reward: 4.166666666666666
Completed Iteration #10
Best Reward: 4.166666666666666
Completed Iteration #11
Best Reward: 4.166666666666666
Completed Iteration #12
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 20.83333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 20.83333333333332 11
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 20.83333333333332 22
Completed Iteration #13
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 20.83333333333332 12
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 20.83333333333332 23
Completed Iteration #14
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 20.83333333333332 13
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 20.83333333333332 24
Completed Iteration #15
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028518> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 16.66666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 20.83333333333332 11
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 20.83333333333332 14
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 20.83333333333332 25
Completed Iteration #16
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028860> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028710> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 20.83333333333332 12
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 20.83333333333332 15
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 20.83333333333332 26
Completed Iteration #17
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 20.83333333333332 16
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 20.83333333333332 27
Completed Iteration #18
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028358> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030240> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 16.66666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 19.791666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 23.95833333333332 13
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 23.95833333333332 17
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 23.95833333333332 28
Completed Iteration #19
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 23.95833333333332 18
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 23.95833333333332 29
Completed Iteration #20
Best Reward: 4.166666666666666
Completed Iteration #21
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028518> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 19.791666666666657 10
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 23.95833333333332 14
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 23.95833333333332 19
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 23.95833333333332 30
Completed Iteration #22
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 23.95833333333332 20
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 23.95833333333332 31
Completed Iteration #23
Best Reward: 4.166666666666666
Completed Iteration #24
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 23.95833333333332 21
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 23.95833333333332 32
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #1
root->3
Best Reward: 4.166666666666666
Completed Iteration #0
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028358> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030240> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 5.208333333333331 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 5.208333333333331 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 16.66666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 19.791666666666657 11
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 23.95833333333332 15
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 23.95833333333332 22
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 23.95833333333332 33
Completed Iteration #1
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d668> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d128> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028358> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030240> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 19.791666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 22.916666666666657 12
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 27.08333333333332 16
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 27.08333333333332 23
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 27.08333333333332 34
Completed Iteration #2
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030240> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 19.791666666666657 10
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 22.916666666666657 13
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 27.08333333333332 17
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 27.08333333333332 24
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 27.08333333333332 35
Completed Iteration #3
Best Reward: 4.166666666666666
Completed Iteration #4
Best Reward: 4.166666666666666
Completed Iteration #5
Best Reward: 4.166666666666666
Completed Iteration #6
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e9b0> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e4e0> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 8.333333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 19.791666666666657 11
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 22.916666666666657 14
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 27.08333333333332 18
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 27.08333333333332 25
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 27.08333333333332 36
Completed Iteration #7
Best Reward: 4.166666666666666
Completed Iteration #8
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047b38> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0473c8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028518> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 26.041666666666657 15
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 30.20833333333332 19
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 30.20833333333332 26
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 30.20833333333332 37
Completed Iteration #9
Best Reward: 4.166666666666666
Completed Iteration #10
Best Reward: 4.166666666666666
Completed Iteration #11
Best Reward: 4.166666666666666
Completed Iteration #12
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047b38> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0473c8> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028518> 6.2499999999999964 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 26.041666666666657 16
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 30.20833333333332 20
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 30.20833333333332 27
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 30.20833333333332 38
Completed Iteration #13
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028710> 1.041666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 30.20833333333332 21
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 30.20833333333332 28
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 30.20833333333332 39
Completed Iteration #14
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0569b0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028ac8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ec18> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e9b0> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e4e0> 6.249999999999999 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 10.416666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 21.87499999999999 12
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 28.12499999999999 17
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 32.29166666666666 22
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 32.29166666666666 29
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 32.29166666666666 40
Completed Iteration #15
Best Reward: 4.166666666666666
Completed Iteration #16
Best Reward: 4.166666666666666
Completed Iteration #17
Best Reward: 4.166666666666666
Completed Iteration #18
Best Reward: 4.166666666666666
Completed Iteration #19
Best Reward: 4.166666666666666
Completed Iteration #20
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01eda0> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028128> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028e80> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 14.58333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 26.041666666666657 13
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 32.29166666666666 18
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 36.45833333333332 23
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 36.45833333333332 30
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 36.45833333333332 41
Completed Iteration #21
Best Reward: 4.166666666666666
coverage_call_count 100
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030320> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028710> 3.124999999999999 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 38.54166666666666 24
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 38.54166666666666 31
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 38.54166666666666 42
Completed Iteration #22
Best Reward: 4.166666666666666
Completed Iteration #23
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028860> 1.041666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028710> 3.124999999999999 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 38.54166666666666 25
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 38.54166666666666 32
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 38.54166666666666 43
Completed Iteration #24
Best Reward: 4.166666666666666
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #2
root->3->14
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01eda0> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028128> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028e80> 8.333333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 14.58333333333333 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 26.041666666666657 14
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 32.29166666666666 19
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 38.54166666666666 26
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 38.54166666666666 33
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 38.54166666666666 44
Completed Iteration #0
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01eda0> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028128> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028e80> 8.333333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 14.58333333333333 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 26.041666666666657 15
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 32.29166666666666 20
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 38.54166666666666 27
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 38.54166666666666 34
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 38.54166666666666 45
Completed Iteration #1
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0569b0> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028ac8> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ec18> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e9b0> 4.166666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e4e0> 6.249999999999999 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 14.58333333333333 10
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 26.041666666666657 16
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 32.29166666666666 21
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 38.54166666666666 28
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 38.54166666666666 35
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 38.54166666666666 46
Completed Iteration #2
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7518> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 11.458333333333327 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 29.166666666666657 17
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 35.41666666666666 22
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 41.66666666666666 29
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 41.66666666666666 36
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 41.66666666666666 47
Completed Iteration #3
Best Reward: 4.166666666666666
Completed Iteration #4
Best Reward: 4.166666666666666
Completed Iteration #5
Best Reward: 4.166666666666666
Completed Iteration #6
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7c50> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d79e8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7518> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 14.583333333333325 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 32.29166666666666 18
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 38.54166666666666 23
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 44.79166666666666 30
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 44.79166666666666 37
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 44.79166666666666 48
Completed Iteration #7
Best Reward: 4.166666666666666
Completed Iteration #8
Best Reward: 4.166666666666666
Completed Iteration #9
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 14.583333333333325 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 32.29166666666666 19
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 38.54166666666666 24
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 44.79166666666666 31
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 44.79166666666666 38
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 44.79166666666666 49
Completed Iteration #10
Best Reward: 4.166666666666666
Completed Iteration #11
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e630> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e9b0> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01eda0> 6.249999999999999 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028128> 6.249999999999999 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028e80> 10.416666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 16.666666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 34.37499999999999 20
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 40.62499999999999 25
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 46.87499999999999 32
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 46.87499999999999 39
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 46.87499999999999 50
Completed Iteration #12
Best Reward: 4.166666666666666
Completed Iteration #13
Best Reward: 4.166666666666666
Completed Iteration #14
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ec50> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 42.70833333333333 26
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 48.95833333333333 33
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 48.95833333333333 40
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 48.95833333333333 51
Completed Iteration #15
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ec50> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 42.70833333333333 27
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 48.95833333333333 34
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 48.95833333333333 41
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 48.95833333333333 52
Completed Iteration #16
Best Reward: 4.166666666666666
Completed Iteration #17
Best Reward: 4.166666666666666
Completed Iteration #18
Best Reward: 4.166666666666666
Completed Iteration #19
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047b38> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0473c8> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028518> 6.2499999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 42.70833333333333 28
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 48.95833333333333 35
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 48.95833333333333 42
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 48.95833333333333 53
Completed Iteration #20
Best Reward: 4.166666666666666
Completed Iteration #21
Best Reward: 4.166666666666666
Completed Iteration #22
Best Reward: 4.166666666666666
Completed Iteration #23
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef4e0> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7a90> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047b38> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0473c8> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028518> 9.374999999999995 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 45.83333333333333 29
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 52.08333333333333 36
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 52.08333333333333 43
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 52.08333333333333 54
Completed Iteration #24
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef4e0> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7a90> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047b38> 6.2499999999999964 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0473c8> 6.2499999999999964 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028518> 9.374999999999995 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 45.83333333333333 30
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 52.08333333333333 37
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 52.08333333333333 44
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 52.08333333333333 55
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #3
root->3->14->3
Best Reward: 4.166666666666666
Completed Iteration #0
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efb38> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efa20> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 9.374999999999995 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 15.624999999999991 10
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 35.41666666666666 21
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 46.87499999999999 31
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 53.12499999999999 38
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 53.12499999999999 45
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 53.12499999999999 56
Completed Iteration #1
Best Reward: 4.166666666666666
Completed Iteration #2
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a198> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 18.749999999999996 12
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 37.49999999999999 22
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 48.95833333333333 32
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 55.20833333333333 39
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 55.20833333333333 46
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 55.20833333333333 57
Completed Iteration #3
Best Reward: 4.166666666666666
Completed Iteration #4
Best Reward: 4.166666666666666
Completed Iteration #5
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a978> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a9e8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d668> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d128> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028358> 10.416666666666663 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030240> 10.416666666666663 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 13.54166666666666 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 19.791666666666657 11
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 41.66666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 53.12499999999999 33
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 59.37499999999999 40
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 59.37499999999999 47
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 59.37499999999999 58
Completed Iteration #6
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028128> 6.249999999999999 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028e80> 10.416666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 18.749999999999996 13
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 41.66666666666666 24
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 53.12499999999999 34
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 59.37499999999999 41
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 59.37499999999999 48
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 59.37499999999999 59
Completed Iteration #7
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efb38> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efa20> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 13.54166666666666 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 19.791666666666657 12
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 41.66666666666666 25
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 53.12499999999999 35
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 59.37499999999999 42
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 59.37499999999999 49
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 59.37499999999999 60
Completed Iteration #8
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056240> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e438> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a198> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 20.83333333333333 14
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 43.74999999999999 26
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 55.20833333333333 36
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 61.45833333333333 43
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 61.45833333333333 50
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 61.45833333333333 61
Completed Iteration #9
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7c88> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7f60> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7c50> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d79e8> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7518> 8.333333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 21.87499999999999 13
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 45.83333333333333 27
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 57.291666666666664 37
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 63.541666666666664 44
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 63.541666666666664 51
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 63.541666666666664 62
Completed Iteration #10
Best Reward: 4.166666666666666
Completed Iteration #11
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef5f8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 23.95833333333333 15
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 48.95833333333333 28
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 60.416666666666664 38
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 66.66666666666666 45
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 66.66666666666666 52
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 66.66666666666666 63
Completed Iteration #12
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d79e8> 7.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7518> 10.41666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 23.95833333333332 14
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 51.041666666666664 29
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 62.5 39
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 68.74999999999999 46
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 68.74999999999999 53
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 68.74999999999999 64
Completed Iteration #13
Best Reward: 4.166666666666666
Completed Iteration #14
Best Reward: 4.166666666666666
Completed Iteration #15
Best Reward: 4.166666666666666
Completed Iteration #16
Best Reward: 4.166666666666666
Completed Iteration #17
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab70> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab00> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a978> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a9e8> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d668> 8.33333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d128> 8.33333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028358> 11.458333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030240> 11.458333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 14.583333333333327 10
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 24.999999999999986 15
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 52.08333333333333 30
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 63.541666666666664 40
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 69.79166666666666 47
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 69.79166666666666 54
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 69.79166666666666 65
Completed Iteration #18
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794320> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794160> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d79e8> 9.374999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7518> 12.499999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 27.083333333333318 16
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 54.166666666666664 31
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 65.625 41
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 71.87499999999999 48
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 71.87499999999999 55
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 71.87499999999999 66
Completed Iteration #19
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7947f0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794630> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056240> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e438> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a198> 6.249999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e550> 26.04166666666666 16
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 56.25 32
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 67.70833333333333 42
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 73.95833333333331 49
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 73.95833333333331 56
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 73.95833333333331 67
Completed Iteration #20
Best Reward: 4.166666666666666
Completed Iteration #21
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ee48> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030240> 13.54166666666666 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 16.66666666666666 11
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 29.16666666666665 17
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 58.333333333333336 33
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 69.79166666666666 43
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 76.04166666666664 50
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 76.04166666666664 57
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 76.04166666666664 68
Completed Iteration #22
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028b70> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef358> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7c88> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7f60> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7c50> 8.333333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d79e8> 12.499999999999995 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7518> 15.624999999999991 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 32.29166666666665 18
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 61.458333333333336 34
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 72.91666666666666 44
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 79.16666666666664 51
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 79.16666666666664 58
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 79.16666666666664 69
Completed Iteration #23
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028b70> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef358> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7c88> 5.208333333333331 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7f60> 5.208333333333331 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7c50> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d79e8> 12.499999999999995 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7518> 15.624999999999991 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 32.29166666666665 19
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 61.458333333333336 35
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 72.91666666666666 45
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 79.16666666666664 52
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 79.16666666666664 59
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 79.16666666666664 70
Completed Iteration #24
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a278> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a9e8> 8.33333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d668> 11.458333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d128> 11.458333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028358> 14.583333333333327 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030240> 16.666666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 19.791666666666657 12
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 35.41666666666665 20
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 64.58333333333333 36
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 76.04166666666666 46
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 82.29166666666664 53
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 82.29166666666664 60
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 82.29166666666664 71
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #4
root->3->14->3->29
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77af98> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d79e8> 14.583333333333329 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7518> 17.708333333333325 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 37.499999999999986 21
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 66.66666666666666 37
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 78.12499999999999 47
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 84.37499999999997 54
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 84.37499999999997 61
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 84.37499999999997 72
Completed Iteration #0
Best Reward: 4.166666666666666
Completed Iteration #1
Best Reward: 4.166666666666666
Completed Iteration #2
Best Reward: 4.166666666666666
Completed Iteration #3
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 37.499999999999986 22
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 66.66666666666666 38
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 78.12499999999999 48
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 84.37499999999997 55
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 84.37499999999997 62
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 84.37499999999997 73
Completed Iteration #4
Best Reward: 4.166666666666666
Completed Iteration #5
Best Reward: 4.166666666666666
Completed Iteration #6
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7358> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 40.624999999999986 23
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 69.79166666666666 39
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 81.24999999999999 49
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 87.49999999999997 56
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 87.49999999999997 63
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 87.49999999999997 74
Completed Iteration #7
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab240> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7358> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 41.66666666666665 24
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 70.83333333333333 40
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 82.29166666666666 50
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 88.54166666666664 57
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 88.54166666666664 64
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 88.54166666666664 75
Completed Iteration #8
Best Reward: 4.166666666666666
Completed Iteration #9
Best Reward: 4.166666666666666
Completed Iteration #10
Best Reward: 4.166666666666666
Completed Iteration #11
Best Reward: 4.166666666666666
Completed Iteration #12
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 41.66666666666665 25
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 70.83333333333333 41
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 82.29166666666666 51
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 88.54166666666664 58
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 88.54166666666664 65
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 88.54166666666664 76
Completed Iteration #13
Best Reward: 4.166666666666666
Completed Iteration #14
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 19.791666666666657 13
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 41.66666666666665 26
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 70.83333333333333 42
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 82.29166666666666 52
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 88.54166666666664 59
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 88.54166666666664 66
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 88.54166666666664 77
Completed Iteration #15
Best Reward: 4.166666666666666
Completed Iteration #16
Best Reward: 4.166666666666666
Completed Iteration #17
Best Reward: 4.166666666666666
Completed Iteration #18
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028b70> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef358> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7c88> 5.208333333333331 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7f60> 5.208333333333331 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7c50> 8.333333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d79e8> 14.583333333333329 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7518> 17.708333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 41.66666666666665 27
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 70.83333333333333 43
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 82.29166666666666 53
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 88.54166666666664 60
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 88.54166666666664 67
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 88.54166666666664 78
Completed Iteration #19
Best Reward: 4.166666666666666
Completed Iteration #20
Best Reward: 4.166666666666666
Completed Iteration #21
Best Reward: 4.166666666666666
Completed Iteration #22
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 44.79166666666665 28
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 73.95833333333333 44
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 85.41666666666666 54
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 91.66666666666664 61
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 91.66666666666664 68
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 91.66666666666664 79
Completed Iteration #23
Best Reward: 4.166666666666666
Completed Iteration #24
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a20> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7949b0> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 47.91666666666665 29
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 77.08333333333333 45
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 88.54166666666666 55
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 94.79166666666664 62
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 94.79166666666664 69
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 94.79166666666664 80
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #5
root->3->14->3->29->0
Best Reward: 4.166666666666666
Completed Iteration #0
Best Reward: 4.166666666666666
Completed Iteration #1
Best Reward: 4.166666666666666
Completed Iteration #2
Best Reward: 4.166666666666666
Completed Iteration #3
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a20> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7949b0> 3.1249999999999982 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 47.91666666666665 30
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 77.08333333333333 46
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 88.54166666666666 56
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 94.79166666666664 63
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 94.79166666666664 70
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 94.79166666666664 81
Completed Iteration #4
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030208> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028eb8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a20> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7949b0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 9.374999999999995 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 51.04166666666665 31
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 80.20833333333333 47
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 91.66666666666666 57
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 97.91666666666664 64
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 97.91666666666664 71
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 97.91666666666664 82
Completed Iteration #5
Best Reward: 4.166666666666666
Completed Iteration #6
Best Reward: 4.166666666666666
Completed Iteration #7
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5ba8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7949b0> 7.2916666666666625 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 52.083333333333314 32
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 81.25 48
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 92.70833333333333 58
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 98.95833333333331 65
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 98.95833333333331 72
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 98.95833333333331 83
Completed Iteration #8
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5f98> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5dd8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030208> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028eb8> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a20> 9.374999999999995 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7949b0> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 13.541666666666659 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 55.208333333333314 33
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 84.375 49
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 95.83333333333333 59
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 102.08333333333331 66
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 102.08333333333331 73
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 102.08333333333331 84
Completed Iteration #9
Best Reward: 4.166666666666666
Completed Iteration #10
Best Reward: 4.166666666666666
Completed Iteration #11
Best Reward: 4.166666666666666
Completed Iteration #12
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5710> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028eb8> 9.374999999999995 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a20> 12.499999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7949b0> 13.541666666666659 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 16.666666666666657 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 58.333333333333314 34
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 87.5 50
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 98.95833333333333 60
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 105.20833333333331 67
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 105.20833333333331 74
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 105.20833333333331 85
Completed Iteration #13
Best Reward: 4.166666666666666
Completed Iteration #14
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab898> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ae10> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5710> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028eb8> 11.458333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a20> 14.583333333333325 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7949b0> 15.624999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 18.74999999999999 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 60.41666666666665 35
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 89.58333333333333 51
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 101.04166666666666 61
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 107.29166666666664 68
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 107.29166666666664 75
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 107.29166666666664 86
Completed Iteration #15
Best Reward: 4.166666666666666
Completed Iteration #16
Best Reward: 4.166666666666666
Completed Iteration #17
Best Reward: 4.166666666666666
Completed Iteration #18
Best Reward: 4.166666666666666
Completed Iteration #19
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab898> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ae10> 2.083333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5710> 5.208333333333331 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028eb8> 11.458333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a20> 14.583333333333325 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7949b0> 15.624999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 18.74999999999999 10
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 60.41666666666665 36
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 89.58333333333333 52
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 101.04166666666666 62
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 107.29166666666664 69
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 107.29166666666664 76
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 107.29166666666664 87
Completed Iteration #20
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 18.74999999999999 11
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 60.41666666666665 37
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 89.58333333333333 53
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 101.04166666666666 63
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 107.29166666666664 70
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 107.29166666666664 77
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 107.29166666666664 88
Completed Iteration #21
Best Reward: 4.166666666666666
coverage_call_count 200
Completed Iteration #22
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 22.916666666666657 12
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 64.58333333333331 38
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 93.75 54
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 105.20833333333333 64
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 111.45833333333331 71
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 111.45833333333331 78
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 111.45833333333331 89
Completed Iteration #23
Best Reward: 4.166666666666666
Completed Iteration #24
Best Reward: 4.166666666666666
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #6
root->3->14->3->29->0->4
Best Reward: 4.166666666666666
Completed Iteration #0
Best Reward: 4.166666666666666
Completed Iteration #1
Best Reward: 4.166666666666666
Completed Iteration #2
Best Reward: 4.166666666666666
Completed Iteration #3
Best Reward: 4.166666666666666
Completed Iteration #4
Best Reward: 4.166666666666666
Completed Iteration #5
Best Reward: 4.166666666666666
Completed Iteration #6
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d940> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 6.249999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 6.249999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 24.99999999999999 13
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 66.66666666666664 39
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 95.83333333333333 55
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 107.29166666666666 65
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 113.54166666666664 72
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 113.54166666666664 79
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 113.54166666666664 90
Completed Iteration #7
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75deb8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 6.249999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 10.416666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 10.416666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 29.166666666666657 14
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 70.83333333333331 40
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 100.0 56
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 111.45833333333333 66
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 117.70833333333331 73
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 117.70833333333331 80
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 117.70833333333331 91
Completed Iteration #8
Best Reward: 4.166666666666666
Completed Iteration #9
Best Reward: 4.166666666666666
Completed Iteration #10
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794ac8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d588> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d940> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 8.333333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 12.499999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 12.499999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 31.24999999999999 15
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 72.91666666666664 41
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 102.08333333333333 57
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 113.54166666666666 67
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 119.79166666666664 74
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 119.79166666666664 81
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 119.79166666666664 92
Completed Iteration #11
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769898> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 11.45833333333333 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 15.624999999999995 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 15.624999999999995 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 34.374999999999986 16
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 76.04166666666664 42
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 105.20833333333333 58
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 116.66666666666666 68
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 122.91666666666664 75
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 122.91666666666664 82
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 122.91666666666664 93
Completed Iteration #12
Best Reward: 4.166666666666666
Completed Iteration #13
Best Reward: 4.166666666666666
Completed Iteration #14
Best Reward: 4.166666666666666
Completed Iteration #15
Best Reward: 4.166666666666666
Completed Iteration #16
Best Reward: 4.166666666666666
Completed Iteration #17
Best Reward: 4.166666666666666
Completed Iteration #18
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efa58> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794ac8> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d588> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d940> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 12.499999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 16.66666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 16.66666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 35.41666666666665 17
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 77.08333333333331 43
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 106.25 59
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 117.70833333333333 69
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 123.95833333333331 76
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 123.95833333333331 83
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 123.95833333333331 94
Completed Iteration #19
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df98> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dba8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769898> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 14.583333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 18.749999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 18.749999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 37.499999999999986 18
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 79.16666666666664 44
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 108.33333333333333 60
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 119.79166666666666 70
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 126.04166666666664 77
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 126.04166666666664 84
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 126.04166666666664 95
Completed Iteration #20
Best Reward: 4.166666666666666
Completed Iteration #21
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748f60> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748240> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75deb8> 6.249999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 16.66666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 20.833333333333325 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 20.833333333333325 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 39.58333333333332 19
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 81.24999999999997 45
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 110.41666666666666 61
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 121.87499999999999 71
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 128.12499999999997 78
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 128.12499999999997 85
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 128.12499999999997 96
Completed Iteration #22
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7691d0> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748240> 6.249999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75deb8> 10.416666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 20.83333333333333 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 24.999999999999993 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 24.999999999999993 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 43.749999999999986 20
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 85.41666666666664 46
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 114.58333333333333 62
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 126.04166666666666 72
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 132.29166666666663 79
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 132.29166666666663 86
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 132.29166666666663 97
Completed Iteration #23
Best Reward: 4.166666666666666
Completed Iteration #24
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769e10> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769c50> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df98> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dba8> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769898> 7.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 22.91666666666666 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 27.083333333333325 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 27.083333333333325 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 45.83333333333332 21
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 87.49999999999997 47
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 116.66666666666666 63
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 128.125 73
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 134.37499999999997 80
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 134.37499999999997 87
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 134.37499999999997 98
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #7
root->3->14->3->29->0->4->5
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe3c8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 27.08333333333333 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 31.249999999999993 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 31.249999999999993 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 49.999999999999986 22
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 91.66666666666664 48
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 120.83333333333333 64
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 132.29166666666666 74
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 138.54166666666663 81
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 138.54166666666663 88
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 138.54166666666663 99
Completed Iteration #0
Best Reward: 4.166666666666666
Completed Iteration #1
Best Reward: 4.166666666666666
Completed Iteration #2
Best Reward: 4.166666666666666
Completed Iteration #3
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6febe0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748390> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 32.29166666666666 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 32.29166666666666 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 51.04166666666665 23
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 92.70833333333331 49
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 121.875 65
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 133.33333333333331 75
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 139.5833333333333 82
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 139.5833333333333 89
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 139.5833333333333 100
Completed Iteration #4
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6febe0> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748390> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 32.29166666666666 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 32.29166666666666 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 51.04166666666665 24
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 92.70833333333331 50
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 121.875 66
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 133.33333333333331 76
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 139.5833333333333 83
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 139.5833333333333 90
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 139.5833333333333 101
Completed Iteration #5
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe3c8> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 27.08333333333333 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 32.29166666666666 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 32.29166666666666 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 51.04166666666665 25
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 92.70833333333331 51
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 121.875 67
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 133.33333333333331 77
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 139.5833333333333 84
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 139.5833333333333 91
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 139.5833333333333 102
Completed Iteration #6
Best Reward: 4.166666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794ac8> 3.124999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d588> 3.124999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d940> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 27.08333333333333 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 32.29166666666666 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 32.29166666666666 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 51.04166666666665 26
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 92.70833333333331 52
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 121.875 68
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 133.33333333333331 78
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 139.5833333333333 85
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 139.5833333333333 92
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 139.5833333333333 103
Completed Iteration #7
Best Reward: 4.166666666666666
Completed Iteration #8
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f28> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748390> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 33.33333333333332 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 33.33333333333332 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 52.083333333333314 27
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 93.74999999999999 53
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 122.91666666666667 69
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 134.37499999999997 79
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 140.62499999999994 86
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 140.62499999999994 93
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 140.62499999999994 104
Completed Iteration #9
Best Reward: 4.166666666666666
Completed Iteration #10
Best Reward: 4.166666666666666
Completed Iteration #11
Best Reward: 4.166666666666666
Completed Iteration #12
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe5f8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe4e0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f28> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748390> 3.1249999999999982 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 34.374999999999986 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 34.374999999999986 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 53.12499999999998 28
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 94.79166666666666 54
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 123.95833333333334 70
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 135.41666666666663 80
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 141.6666666666666 87
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 141.6666666666666 94
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 141.6666666666666 105
Completed Iteration #13
Best Reward: 4.166666666666666
Completed Iteration #14
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719160> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d940> 7.291666666666665 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 29.16666666666666 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 36.45833333333332 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 36.45833333333332 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 55.208333333333314 29
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 96.87499999999999 55
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 126.04166666666667 71
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 137.49999999999997 81
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 143.74999999999994 88
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 143.74999999999994 95
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 143.74999999999994 106
Completed Iteration #15
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719668> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fea58> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe3c8> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 30.20833333333333 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 37.499999999999986 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 37.499999999999986 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 56.24999999999998 30
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 97.91666666666666 56
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 127.08333333333334 72
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 138.54166666666663 82
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 144.7916666666666 89
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 144.7916666666666 96
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 144.7916666666666 107
Completed Iteration #16
Best Reward: 4.166666666666666
Completed Iteration #17
Best Reward: 4.166666666666666
Completed Iteration #18
Best Reward: 4.166666666666666
Completed Iteration #19
Best Reward: 4.166666666666666
Completed Iteration #20
Best Reward: 4.166666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769320> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748d30> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748f60> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748240> 7.291666666666665 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75deb8> 11.45833333333333 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 31.249999999999993 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 38.54166666666665 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 38.54166666666665 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 57.29166666666664 31
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 98.95833333333333 57
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 128.125 73
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 139.5833333333333 83
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 145.83333333333326 90
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 145.83333333333326 97
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 145.83333333333326 108
Completed Iteration #21
Best Reward: 4.166666666666666
Completed Iteration #22
Best Reward: 4.166666666666666
Completed Iteration #23
Best Reward: 4.166666666666666
Completed Iteration #24
Best Reward: 4.166666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719080> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fecc0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769e10> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769c50> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df98> 6.249999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dba8> 6.249999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769898> 9.374999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9b0> 33.33333333333333 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 40.624999999999986 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c18> 40.624999999999986 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 59.37499999999998 32
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef28> 101.04166666666666 58
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d978> 130.20833333333334 74
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d2e8> 141.66666666666663 84
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d8d0> 147.9166666666666 91
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d7f0> 147.9166666666666 98
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d9b0> 147.9166666666666 109
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #8
root->3->14->3->29->0->4->5->29
Best Reward: 4.166666666666666
iteration: 1
found coverage increase 4.166666666666666
Current Total Coverage 9.375
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7199e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7199e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75db38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7199e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7199e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7199e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 9.375
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 17
Completed Iteration #18
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697f0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 9.375
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db5c0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 9.375
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 9.375
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 2.083333333333332 4
Completed Iteration #5
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 4.166666666666664 5
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cac8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 6.2499999999999964 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 6.2499999999999964 6
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 6.2499999999999964 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 6.2499999999999964 7
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 6.2499999999999964 8
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0f60> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b9e8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cac8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 8.333333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 8.333333333333329 9
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6f60> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6c88> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0f60> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b9e8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cac8> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 10.41666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 10.41666666666666 10
Completed Iteration #21
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6a90> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6198> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0f60> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b9e8> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cac8> 7.291666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 7.291666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 9.374999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 9.374999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 11.458333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 11.458333333333329 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 11.458333333333329 11
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719908> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b9e8> 8.333333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cac8> 10.416666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 10.416666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 12.499999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 12.499999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 14.583333333333329 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 14.583333333333329 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 14.583333333333329 12
Completed Iteration #24
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 14.583333333333329 13
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #0
root
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae898> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b9e8> 10.416666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cac8> 12.499999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 12.499999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 14.583333333333329 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 14.583333333333329 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 16.66666666666666 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 16.66666666666666 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 16.66666666666666 14
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aef98> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 15.624999999999996 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 17.70833333333333 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 17.70833333333333 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 19.79166666666666 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 19.79166666666666 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 19.79166666666666 15
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649860> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 19.79166666666666 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 21.874999999999993 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 21.874999999999993 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 21.874999999999993 16
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 21.874999999999993 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 23.958333333333325 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 23.958333333333325 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 23.958333333333325 17
Completed Iteration #12
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 23.958333333333325 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 23.958333333333325 18
Completed Iteration #13
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 23.958333333333325 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 23.958333333333325 19
Completed Iteration #14
Best Reward: 3.125
coverage_call_count 400
Completed Iteration #15
Best Reward: 3.125
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769080> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731128> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6a90> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6198> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0f60> 6.25 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b9e8> 11.458333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cac8> 13.541666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 16.666666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 18.749999999999996 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 22.91666666666666 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 24.999999999999993 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 24.999999999999993 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 24.999999999999993 20
Completed Iteration #16
Best Reward: 3.125
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0240> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae048> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aef98> 7.291666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 20.83333333333333 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 22.916666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 27.08333333333333 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 29.166666666666657 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 29.166666666666657 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 29.166666666666657 21
Completed Iteration #17
Best Reward: 4.166666666666666
Completed Iteration #18
Best Reward: 4.166666666666666
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649710> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 22.91666666666666 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 24.999999999999996 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 29.16666666666666 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 31.24999999999999 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 31.24999999999999 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 31.24999999999999 22
Completed Iteration #19
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 6.249999999999998 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 33.33333333333333 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 35.41666666666666 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 35.41666666666666 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 35.41666666666666 23
Completed Iteration #20
Best Reward: 4.166666666666666
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719438> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae048> 7.291666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aef98> 10.416666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 26.04166666666666 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 28.124999999999996 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 36.45833333333333 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 38.54166666666666 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 38.54166666666666 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 38.54166666666666 24
Completed Iteration #21
Best Reward: 4.166666666666666
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feef0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbc18> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 30.20833333333333 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 38.54166666666666 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 40.624999999999986 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 40.624999999999986 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 40.624999999999986 25
Completed Iteration #22
Best Reward: 4.166666666666666
Completed Iteration #23
Best Reward: 4.166666666666666
Completed Iteration #24
Best Reward: 4.166666666666666
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f400> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f0b8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719908> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b9e8> 13.541666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cac8> 15.624999999999996 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 28.124999999999993 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 32.29166666666666 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 40.624999999999986 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 42.708333333333314 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 42.708333333333314 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 42.708333333333314 26
Completed Iteration #25
Best Reward: 4.166666666666666
Completed MCTS Level/Depth: #1
root->6
Best Reward: 4.166666666666666
Completed Iteration #0
Best Reward: 4.166666666666666
Completed Iteration #1
Best Reward: 4.166666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 10.416666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 44.79166666666665 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 46.87499999999998 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 46.87499999999998 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 46.87499999999998 27
Completed Iteration #2
Best Reward: 4.166666666666666
Reward: 5.208333333333334
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 5.208333333333334 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 5.208333333333334 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 9.375 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 9.375 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 13.541666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 13.541666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 15.624999999999998 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 49.999999999999986 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 52.083333333333314 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 52.083333333333314 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 52.083333333333314 28
Completed Iteration #3
Best Reward: 5.208333333333334
Reward: 6.25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f9b0> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 11.458333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 11.458333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 15.625 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 15.625 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 19.791666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 19.791666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 21.875 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 56.249999999999986 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 58.333333333333314 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 58.333333333333314 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 58.333333333333314 29
Completed Iteration #4
Best Reward: 6.25
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db7f0> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db550> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f9b0> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 18.75 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 18.75 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 22.916666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 22.916666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 27.08333333333333 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 27.08333333333333 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 29.166666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 63.54166666666665 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 65.62499999999997 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 65.62499999999997 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 65.62499999999997 30
Completed Iteration #5
Best Reward: 7.291666666666664
Completed Iteration #6
Best Reward: 7.291666666666664
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ca58> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769a20> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649710> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 30.208333333333325 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 34.374999999999986 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 65.62499999999999 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 67.7083333333333 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 67.7083333333333 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 67.7083333333333 31
Completed Iteration #7
Best Reward: 7.291666666666664
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa90> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f588> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 30.20833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 30.20833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 34.37499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 34.37499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 36.45833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 72.91666666666666 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 74.99999999999997 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 74.99999999999997 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 74.99999999999997 32
Completed Iteration #8
Best Reward: 7.291666666666664
Completed Iteration #9
Best Reward: 7.291666666666664
Completed Iteration #10
Best Reward: 7.291666666666664
Completed Iteration #11
Best Reward: 7.291666666666664
Completed Iteration #12
Best Reward: 7.291666666666664
Completed Iteration #13
Best Reward: 7.291666666666664
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769860> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f710> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 76.04166666666664 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 76.04166666666664 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 76.04166666666664 33
Completed Iteration #14
Best Reward: 7.291666666666664
Completed Iteration #15
Best Reward: 7.291666666666664
Completed Iteration #16
Best Reward: 7.291666666666664
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661b00> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 32.29166666666666 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 36.458333333333314 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 74.99999999999999 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 78.12499999999997 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 78.12499999999997 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 78.12499999999997 34
Completed Iteration #17
Best Reward: 7.291666666666664
Completed Iteration #18
Best Reward: 7.291666666666664
Completed Iteration #19
Best Reward: 7.291666666666664
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661f60> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd278> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 80.2083333333333 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 80.2083333333333 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 80.2083333333333 35
Completed Iteration #20
Best Reward: 7.291666666666664
Completed Iteration #21
Best Reward: 7.291666666666664
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd470> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd320> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661f60> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd278> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 82.29166666666663 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 82.29166666666663 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 82.29166666666663 36
Completed Iteration #22
Best Reward: 7.291666666666664
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd8d0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd710> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd470> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd320> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661f60> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd278> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 84.37499999999996 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 84.37499999999996 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 84.37499999999996 37
Completed Iteration #23
Best Reward: 7.291666666666664
Completed Iteration #24
Best Reward: 7.291666666666664
Completed Iteration #25
Best Reward: 7.291666666666664
Completed MCTS Level/Depth: #2
root->6->19
Best Reward: 7.291666666666664
Completed Iteration #0
Best Reward: 7.291666666666664
Completed Iteration #1
Best Reward: 7.291666666666664
Completed Iteration #2
Best Reward: 7.291666666666664
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdcc0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd3c8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 37.499999999999986 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 76.04166666666666 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 85.41666666666663 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 85.41666666666663 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 85.41666666666663 38
Completed Iteration #3
Best Reward: 7.291666666666664
Completed Iteration #4
Best Reward: 7.291666666666664
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4ac8> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4b38> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db7f0> 14.583333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db550> 14.583333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f9b0> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 26.041666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 26.041666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 37.49999999999999 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 37.49999999999999 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 41.66666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 41.66666666666666 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 43.74999999999999 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 83.33333333333331 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 92.70833333333329 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 92.70833333333329 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 92.70833333333329 39
Completed Iteration #5
Best Reward: 7.291666666666664
Completed Iteration #6
Best Reward: 7.291666666666664
Completed Iteration #7
Best Reward: 7.291666666666664
Completed Iteration #8
Best Reward: 7.291666666666664
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aec88> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fb70> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cac8> 17.70833333333333 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 34.374999999999986 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 39.583333333333314 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 85.41666666666664 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 94.79166666666661 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 94.79166666666661 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 94.79166666666661 40
Completed Iteration #9
Best Reward: 7.291666666666664
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649c18> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661358> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719438> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae048> 10.416666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aef98> 13.541666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 37.499999999999986 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 42.708333333333314 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 88.54166666666664 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 97.91666666666661 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 97.91666666666661 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 97.91666666666661 41
Completed Iteration #10
Best Reward: 7.291666666666664
Completed Iteration #11
Best Reward: 7.291666666666664
Completed Iteration #12
Best Reward: 7.291666666666664
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd630> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0400> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649860> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 91.66666666666664 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 101.04166666666661 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 101.04166666666661 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 101.04166666666661 42
Completed Iteration #13
Best Reward: 7.291666666666664
Completed Iteration #14
Best Reward: 7.291666666666664
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4b70> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd828> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649c18> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661358> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719438> 13.541666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae048> 17.70833333333333 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aef98> 20.83333333333333 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 44.79166666666665 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 49.99999999999998 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 98.95833333333331 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 108.33333333333329 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 108.33333333333329 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 108.33333333333329 43
Completed Iteration #15
Best Reward: 7.291666666666664
Completed Iteration #16
Best Reward: 7.291666666666664
Completed Iteration #17
Best Reward: 7.291666666666664
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae048> 20.83333333333333 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aef98> 23.95833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c208> 47.91666666666665 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 53.12499999999998 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 102.08333333333331 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 111.45833333333329 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 111.45833333333329 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 111.45833333333329 44
Completed Iteration #18
Best Reward: 7.291666666666664
Completed Iteration #19
Best Reward: 7.291666666666664
Completed Iteration #20
Best Reward: 7.291666666666664
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c66d8> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 28.124999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 33.33333333333333 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 33.33333333333333 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 44.79166666666666 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 44.79166666666666 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 48.95833333333332 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 48.95833333333332 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 51.04166666666666 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 109.37499999999997 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 118.74999999999994 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 118.74999999999994 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 118.74999999999994 45
Completed Iteration #21
Best Reward: 7.291666666666664
Completed Iteration #22
Best Reward: 7.291666666666664
Reward: 6.25
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2198> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661978> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4ac8> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4b38> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db7f0> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db550> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f9b0> 27.08333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 34.37499999999999 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 39.58333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 39.58333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 51.04166666666666 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 51.04166666666666 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 55.20833333333332 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 55.20833333333332 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 57.29166666666666 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 115.62499999999997 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 124.99999999999994 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 124.99999999999994 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 124.99999999999994 46
Completed Iteration #23
Best Reward: 7.291666666666664
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7847e29e8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2828> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcc0> 55.208333333333314 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 117.7083333333333 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 127.08333333333327 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 127.08333333333327 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 127.08333333333327 47
Completed Iteration #24
Best Reward: 7.291666666666664
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4668> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 119.79166666666663 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 129.1666666666666 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 129.1666666666666 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 129.1666666666666 48
Completed Iteration #25
Best Reward: 7.291666666666664
Completed MCTS Level/Depth: #3
root->6->19->0
Best Reward: 7.291666666666664
Completed Iteration #0
Best Reward: 7.291666666666664
Completed Iteration #1
Best Reward: 7.291666666666664
Reward: 6.25
backprop <src.mcts.MCTS_Node object at 0x7fe7847bda58> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdbe0> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa90> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f588> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 57.29166666666666 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 57.29166666666666 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 61.45833333333332 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 61.45833333333332 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 63.54166666666666 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 126.04166666666663 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 135.4166666666666 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 135.4166666666666 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 135.4166666666666 49
Completed Iteration #2
Best Reward: 7.291666666666664
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fef0> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2198> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661978> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4ac8> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4b38> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db7f0> 28.124999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db550> 28.124999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f9b0> 34.37499999999999 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 41.66666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 46.87499999999999 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 46.87499999999999 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 64.58333333333331 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 64.58333333333331 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 68.74999999999999 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 68.74999999999999 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 70.83333333333331 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 133.3333333333333 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 142.70833333333326 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 142.70833333333326 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 142.70833333333326 50
Completed Iteration #3
Best Reward: 7.291666666666664
Reward: 5.208333333333334
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649400> 5.208333333333334 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 69.79166666666664 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 73.95833333333331 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 73.95833333333331 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 76.04166666666664 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 138.54166666666663 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 147.9166666666666 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 147.9166666666666 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 147.9166666666666 51
Completed Iteration #4
Best Reward: 7.291666666666664
Completed Iteration #5
Best Reward: 7.291666666666664
Completed Iteration #6
Best Reward: 7.291666666666664
Completed Iteration #7
Best Reward: 7.291666666666664
Completed Iteration #8
Best Reward: 7.291666666666664
Completed Iteration #9
Best Reward: 7.291666666666664
Completed Iteration #10
Best Reward: 7.291666666666664
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2d30> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2da0> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db7f0> 35.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db550> 35.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f9b0> 41.66666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 48.95833333333332 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 54.16666666666666 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 54.16666666666666 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 71.87499999999997 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 77.08333333333331 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 81.24999999999997 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 81.24999999999997 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 83.33333333333331 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 145.8333333333333 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 155.20833333333326 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 155.20833333333326 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 155.20833333333326 52
Completed Iteration #11
Best Reward: 7.291666666666664
Completed Iteration #12
Best Reward: 7.291666666666664
Completed Iteration #13
Best Reward: 7.291666666666664
Completed Iteration #14
Best Reward: 7.291666666666664
Completed Iteration #15
Best Reward: 7.291666666666664
Completed Iteration #16
Best Reward: 7.291666666666664
Completed Iteration #17
Best Reward: 7.291666666666664
Completed Iteration #18
Best Reward: 7.291666666666664
Completed Iteration #19
Best Reward: 7.291666666666664
Completed Iteration #20
Best Reward: 7.291666666666664
Completed Iteration #21
Best Reward: 7.291666666666664
Completed Iteration #22
Best Reward: 7.291666666666664
Completed Iteration #23
Best Reward: 7.291666666666664
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe78477f978> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fef0> 14.583333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2198> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661978> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4ac8> 28.124999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4b38> 28.124999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db7f0> 42.70833333333332 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db550> 42.70833333333332 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f9b0> 48.95833333333332 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 56.249999999999986 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 61.45833333333332 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 61.45833333333332 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 79.16666666666663 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 84.37499999999997 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 88.54166666666663 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 88.54166666666663 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 90.62499999999997 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 153.12499999999994 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 162.49999999999991 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 162.49999999999991 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 162.49999999999991 53
Completed Iteration #24
Best Reward: 7.291666666666664
Completed Iteration #25
Best Reward: 7.291666666666664
Completed MCTS Level/Depth: #4
root->6->19->0->11
Best Reward: 7.291666666666664
Reward: 6.25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f438> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4470> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649400> 11.458333333333334 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 90.62499999999997 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 94.79166666666663 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 94.79166666666663 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 96.87499999999997 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 159.37499999999994 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 168.74999999999991 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 168.74999999999991 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 168.74999999999991 54
Completed Iteration #0
Best Reward: 7.291666666666664
Reward: 8.333333333333336
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649240> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8b38> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bda58> 14.583333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdbe0> 14.583333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa90> 21.875 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f588> 21.875 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 87.49999999999997 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 98.95833333333331 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 103.12499999999997 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 103.12499999999997 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 105.20833333333331 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 167.7083333333333 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 177.08333333333326 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 177.08333333333326 52
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 177.08333333333326 55
Completed Iteration #1
Best Reward: 8.333333333333336
Completed Iteration #2
Best Reward: 8.333333333333336
Completed Iteration #3
Best Reward: 8.333333333333336
Completed Iteration #4
Best Reward: 8.333333333333336
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 63.54166666666665 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 68.74999999999999 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 68.74999999999999 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 94.79166666666663 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 106.24999999999997 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 110.41666666666663 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 110.41666666666663 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 112.49999999999997 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 174.99999999999994 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 184.37499999999991 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 184.37499999999991 53
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 184.37499999999991 56
Completed Iteration #5
Best Reward: 8.333333333333336
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8c88> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8518> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f438> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4470> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649400> 18.75 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 113.54166666666663 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 117.70833333333329 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 117.70833333333329 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 119.79166666666663 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 182.2916666666666 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 191.66666666666657 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 191.66666666666657 54
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 191.66666666666657 57
Completed Iteration #6
Best Reward: 8.333333333333336
Completed Iteration #7
Best Reward: 8.333333333333336
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdbe0> 21.875 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa90> 29.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f588> 29.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 102.08333333333329 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 120.83333333333329 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 124.99999999999994 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 124.99999999999994 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 127.08333333333329 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 189.58333333333326 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 198.95833333333323 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 198.95833333333323 55
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 198.95833333333323 58
Completed Iteration #8
Best Reward: 8.333333333333336
Completed Iteration #9
Best Reward: 8.333333333333336
Completed Iteration #10
Best Reward: 8.333333333333336
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 72.91666666666666 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 106.24999999999996 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 124.99999999999996 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 129.1666666666666 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 129.1666666666666 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 131.24999999999994 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 193.74999999999991 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 203.1249999999999 52
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 203.1249999999999 56
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 203.1249999999999 59
Completed Iteration #11
Best Reward: 8.333333333333336
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe784794278> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 129.16666666666663 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 133.33333333333326 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 133.33333333333326 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 135.4166666666666 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 197.91666666666657 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 207.29166666666654 53
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 207.29166666666654 57
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 207.29166666666654 60
Completed Iteration #12
Best Reward: 8.333333333333336
Completed Iteration #13
Best Reward: 8.333333333333336
coverage_call_count 500
Reward: 8.333333333333336
backprop <src.mcts.MCTS_Node object at 0x7fe7847949b0> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794908> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794278> 12.500000000000002 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 137.49999999999997 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 141.6666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 141.6666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 143.74999999999994 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 206.24999999999991 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 215.6249999999999 54
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 215.6249999999999 58
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 215.6249999999999 61
Completed Iteration #14
Best Reward: 8.333333333333336
Reward: 8.333333333333336
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db320> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731898> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847949b0> 16.66666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794908> 16.66666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794278> 20.833333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 145.83333333333331 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 149.99999999999994 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 149.99999999999994 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 152.0833333333333 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 214.58333333333326 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 223.95833333333323 55
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 223.95833333333323 59
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 223.95833333333323 62
Completed Iteration #15
Best Reward: 8.333333333333336
Completed Iteration #16
Best Reward: 8.333333333333336
Completed Iteration #17
Best Reward: 8.333333333333336
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7847e27b8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 149.99999999999997 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 154.1666666666666 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 154.1666666666666 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 156.24999999999994 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 218.74999999999991 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 228.1249999999999 56
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 228.1249999999999 60
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 228.1249999999999 63
Completed Iteration #18
Best Reward: 8.333333333333336
Reward: 11.458333333333336
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661fd0> 11.458333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2a58> 11.458333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c66d8> 18.75 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 74.99999999999999 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 80.20833333333331 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 84.375 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 117.70833333333329 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 161.45833333333331 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 165.62499999999994 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 165.62499999999994 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 167.7083333333333 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 230.20833333333326 52
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 239.58333333333323 57
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 239.58333333333323 61
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 239.58333333333323 64
Completed Iteration #19
Best Reward: 11.458333333333336
Completed Iteration #20
Best Reward: 11.458333333333336
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe78477feb8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 169.7916666666666 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 171.87499999999994 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 234.37499999999991 53
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 243.7499999999999 58
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 243.7499999999999 62
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 243.7499999999999 65
Completed Iteration #21
Best Reward: 11.458333333333336
Completed Iteration #22
Best Reward: 11.458333333333336
Completed Iteration #23
Best Reward: 11.458333333333336
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7847949e8> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794390> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8c88> 14.583333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8518> 14.583333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f438> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4470> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649400> 26.041666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 168.74999999999997 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 172.9166666666666 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 177.08333333333326 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 179.1666666666666 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 241.66666666666657 54
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 251.04166666666654 59
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 251.04166666666654 63
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 251.04166666666654 66
Completed Iteration #24
Best Reward: 11.458333333333336
Reward: 6.25
backprop <src.mcts.MCTS_Node object at 0x7fe784794f98> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 174.99999999999997 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 179.1666666666666 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 183.33333333333326 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 185.4166666666666 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 247.91666666666657 55
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 257.2916666666665 60
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 257.2916666666665 64
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 257.2916666666665 67
Completed Iteration #25
Best Reward: 11.458333333333336
Completed MCTS Level/Depth: #5
root->6->19->0->11->0
Best Reward: 11.458333333333336
Completed Iteration #0
Best Reward: 11.458333333333336
Completed Iteration #1
Best Reward: 11.458333333333336
Completed Iteration #2
Best Reward: 11.458333333333336
Completed Iteration #3
Best Reward: 11.458333333333336
Completed Iteration #4
Best Reward: 11.458333333333336
Completed Iteration #5
Best Reward: 11.458333333333336
Completed Iteration #6
Best Reward: 11.458333333333336
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7847aae48> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8518> 21.874999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f438> 28.124999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4470> 28.124999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649400> 33.33333333333333 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 182.29166666666663 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 186.45833333333326 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 190.62499999999991 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 192.70833333333326 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 255.20833333333323 56
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 264.5833333333332 61
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 264.5833333333332 65
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 264.5833333333332 68
Completed Iteration #7
Best Reward: 11.458333333333336
Completed Iteration #8
Best Reward: 11.458333333333336
Completed Iteration #9
Best Reward: 11.458333333333336
Completed Iteration #10
Best Reward: 11.458333333333336
Reward: 8.333333333333336
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8128> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719278> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db320> 16.66666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731898> 16.66666666666667 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847949b0> 25.000000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7fe784794908> 25.000000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7fe784794278> 29.16666666666667 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 190.62499999999997 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 194.7916666666666 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 198.95833333333326 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 201.0416666666666 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 263.5416666666666 57
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 272.9166666666665 62
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 272.9166666666665 66
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 272.9166666666665 69
Completed Iteration #11
Best Reward: 11.458333333333336
Completed Iteration #12
Best Reward: 11.458333333333336
Completed Iteration #13
Best Reward: 11.458333333333336
Completed Iteration #14
Best Reward: 11.458333333333336
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe784794470> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847940b8> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 14.583333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdbe0> 29.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa90> 36.45833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f588> 36.45833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 124.99999999999994 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 197.91666666666663 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 202.08333333333326 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 206.24999999999991 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 208.33333333333326 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 270.83333333333326 58
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 280.2083333333332 63
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 280.2083333333332 67
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 280.2083333333332 70
Completed Iteration #15
Best Reward: 11.458333333333336
Completed Iteration #16
Best Reward: 11.458333333333336
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe48> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fac8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e27b8> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 202.0833333333333 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 206.24999999999991 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 210.41666666666657 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 212.49999999999991 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 274.99999999999994 59
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 284.3749999999999 64
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 284.3749999999999 68
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 284.3749999999999 71
Completed Iteration #17
Best Reward: 11.458333333333336
Completed Iteration #18
Best Reward: 11.458333333333336
Completed Iteration #19
Best Reward: 11.458333333333336
Reward: 8.333333333333336
backprop <src.mcts.MCTS_Node object at 0x7fe78473a208> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731898> 25.000000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847949b0> 33.33333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7fe784794908> 33.33333333333334 5
backprop <src.mcts.MCTS_Node object at 0x7fe784794278> 37.50000000000001 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 210.41666666666663 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 214.58333333333326 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 218.74999999999991 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 220.83333333333326 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 283.33333333333326 60
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 292.7083333333332 65
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 292.7083333333332 69
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 292.7083333333332 72
Completed Iteration #20
Best Reward: 11.458333333333336
Completed Iteration #21
Best Reward: 11.458333333333336
Completed Iteration #22
Best Reward: 11.458333333333336
Completed Iteration #23
Best Reward: 11.458333333333336
Completed Iteration #24
Best Reward: 11.458333333333336
Completed Iteration #25
Best Reward: 11.458333333333336
Completed MCTS Level/Depth: #6
root->6->19->0->11->0->17
Best Reward: 11.458333333333336
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe78473ae10> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473acc0> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794f98> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 217.7083333333333 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 221.87499999999991 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 226.04166666666657 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 228.12499999999991 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 290.62499999999994 61
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 299.9999999999999 66
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 299.9999999999999 70
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 299.9999999999999 73
Completed Iteration #0
Best Reward: 11.458333333333336
Completed Iteration #1
Best Reward: 11.458333333333336
Completed Iteration #2
Best Reward: 11.458333333333336
Completed Iteration #3
Best Reward: 11.458333333333336
Completed Iteration #4
Best Reward: 11.458333333333336
Reward: 8.333333333333336
backprop <src.mcts.MCTS_Node object at 0x7fe7847549b0> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754a20> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 15.625 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 83.33333333333331 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 88.54166666666666 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 92.70833333333334 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 133.3333333333333 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 226.04166666666663 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 230.20833333333326 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 234.37499999999991 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 236.45833333333326 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 298.95833333333326 62
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 308.3333333333332 67
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 308.3333333333332 71
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 308.3333333333332 74
Completed Iteration #5
Best Reward: 11.458333333333336
Reward: 9.375
backprop <src.mcts.MCTS_Node object at 0x7fe784754f60> 9.375 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719278> 17.708333333333336 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db320> 26.04166666666667 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731898> 34.37500000000001 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847949b0> 42.70833333333334 6
backprop <src.mcts.MCTS_Node object at 0x7fe784794908> 42.70833333333334 6
backprop <src.mcts.MCTS_Node object at 0x7fe784794278> 46.87500000000001 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 235.41666666666663 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 239.58333333333326 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 243.74999999999991 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 245.83333333333326 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 308.33333333333326 63
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 317.7083333333332 68
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 317.7083333333332 72
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 317.7083333333332 75
Completed Iteration #6
Best Reward: 11.458333333333336
Completed Iteration #7
Best Reward: 11.458333333333336
Completed Iteration #8
Best Reward: 11.458333333333336
Reward: 10.416666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719390> 10.416666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847946d8> 10.416666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661fd0> 21.875 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2a58> 21.875 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c66d8> 29.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 93.74999999999997 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 98.95833333333331 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 103.125 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 143.74999999999994 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 245.8333333333333 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 249.99999999999991 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 254.16666666666657 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 256.24999999999994 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 318.74999999999994 64
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 328.1249999999999 69
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 328.1249999999999 73
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 328.1249999999999 76
Completed Iteration #9
Best Reward: 11.458333333333336
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa860> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 249.99999999999994 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 254.16666666666657 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 258.33333333333326 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 260.41666666666663 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 322.91666666666663 65
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 332.2916666666666 70
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 332.2916666666666 74
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 332.2916666666666 77
Completed Iteration #10
Best Reward: 11.458333333333336
Completed Iteration #11
Best Reward: 11.458333333333336
Completed Iteration #12
Best Reward: 11.458333333333336
Completed Iteration #13
Best Reward: 11.458333333333336
Completed Iteration #14
Best Reward: 11.458333333333336
Reward: 9.375
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f940> 9.375 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754198> 9.375 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847949e8> 16.666666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794390> 16.666666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8c88> 23.95833333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8518> 31.249999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f438> 37.49999999999999 6
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4470> 37.49999999999999 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649400> 42.70833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 259.37499999999994 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 263.5416666666666 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 267.70833333333326 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 269.79166666666663 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 332.29166666666663 66
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 341.6666666666666 71
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 341.6666666666666 75
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 341.6666666666666 78
Completed Iteration #15
Best Reward: 11.458333333333336
Completed Iteration #16
Best Reward: 11.458333333333336
Completed Iteration #17
Best Reward: 11.458333333333336
Completed Iteration #18
Best Reward: 11.458333333333336
Completed Iteration #19
Best Reward: 11.458333333333336
Completed Iteration #20
Best Reward: 11.458333333333336
Completed Iteration #21
Best Reward: 11.458333333333336
Completed Iteration #22
Best Reward: 11.458333333333336
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7fe78475c208> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 263.54166666666663 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 267.70833333333326 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 271.87499999999994 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 273.9583333333333 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 336.4583333333333 67
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 345.83333333333326 72
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 345.83333333333326 76
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 345.83333333333326 79
Completed Iteration #23
Best Reward: 11.458333333333336
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc174630> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4470> 44.79166666666666 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649400> 49.99999999999999 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 270.8333333333333 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 274.99999999999994 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 279.16666666666663 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 281.25 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 343.75 68
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 353.12499999999994 73
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 353.12499999999994 77
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 353.12499999999994 80
Completed Iteration #24
Best Reward: 11.458333333333336
Completed Iteration #25
Best Reward: 11.458333333333336
Completed MCTS Level/Depth: #7
root->6->19->0->11->0->17->7
Best Reward: 11.458333333333336
Completed Iteration #0
Best Reward: 11.458333333333336
Completed Iteration #1
Best Reward: 11.458333333333336
Completed Iteration #2
Best Reward: 11.458333333333336
Completed Iteration #3
Best Reward: 11.458333333333336
Completed Iteration #4
Best Reward: 11.458333333333336
Completed Iteration #5
Best Reward: 11.458333333333336
Completed Iteration #6
Best Reward: 11.458333333333336
Completed Iteration #7
Best Reward: 11.458333333333336
Reward: 10.416666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 10.416666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cda0> 10.416666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719390> 20.83333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847946d8> 20.83333333333333 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661fd0> 32.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2a58> 32.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c66d8> 39.58333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 104.16666666666663 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 109.37499999999997 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 113.54166666666666 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 154.1666666666666 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 281.25 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 285.41666666666663 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 289.5833333333333 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 291.6666666666667 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 354.1666666666667 69
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 363.54166666666663 74
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 363.54166666666663 78
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 363.54166666666663 81
Completed Iteration #8
Best Reward: 11.458333333333336
Completed Iteration #9
Best Reward: 11.458333333333336
Completed Iteration #10
Best Reward: 11.458333333333336
Reward: 6.25
backprop <src.mcts.MCTS_Node object at 0x7fe7cb822128> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe819ede5c0> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794470> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847940b8> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdbe0> 35.416666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa90> 42.70833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f588> 42.70833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 160.4166666666666 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 287.5 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 291.66666666666663 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 295.8333333333333 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 297.9166666666667 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 360.4166666666667 70
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 369.79166666666663 75
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 369.79166666666663 79
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 369.79166666666663 82
Completed Iteration #11
Best Reward: 11.458333333333336
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cfd0> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c978> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 11.45833333333333 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 120.83333333333331 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 167.70833333333326 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 294.7916666666667 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 298.9583333333333 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 303.125 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 305.20833333333337 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 367.70833333333337 71
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 377.0833333333333 76
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 377.0833333333333 80
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 377.0833333333333 83
Completed Iteration #12
Best Reward: 11.458333333333336
Completed Iteration #13
Best Reward: 11.458333333333336
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649048> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db550> 49.999999999999986 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f9b0> 56.249999999999986 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 111.45833333333329 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 116.66666666666663 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 128.12499999999997 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 174.99999999999991 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 302.08333333333337 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 306.25 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 310.4166666666667 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 312.50000000000006 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 375.00000000000006 72
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 384.375 77
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 384.375 81
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 384.375 84
Completed Iteration #14
Best Reward: 11.458333333333336
Completed Iteration #15
Best Reward: 11.458333333333336
Completed Iteration #16
Best Reward: 11.458333333333336
Reward: 7.291666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa898> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aacf8> 7.291666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cfd0> 14.583333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c978> 14.583333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 18.749999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 135.41666666666663 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 182.29166666666657 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 309.37500000000006 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 313.5416666666667 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 317.70833333333337 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 319.79166666666674 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 382.29166666666674 73
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 391.6666666666667 78
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 391.6666666666667 82
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 391.6666666666667 85
Completed Iteration #17
Best Reward: 11.458333333333336
Completed Iteration #18
Best Reward: 11.458333333333336
Reward: 6.25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f518> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdbe0> 41.666666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa90> 48.95833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f588> 48.95833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 188.54166666666657 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 315.62500000000006 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 319.7916666666667 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 323.95833333333337 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 326.04166666666674 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 388.54166666666674 74
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 397.9166666666667 79
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 397.9166666666667 83
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 397.9166666666667 86
Completed Iteration #19
Best Reward: 11.458333333333336
Completed Iteration #20
Best Reward: 11.458333333333336
Reward: 8.333333333333336
backprop <src.mcts.MCTS_Node object at 0x7fe7847f80f0> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a1d0> 8.333333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa898> 15.625 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aacf8> 15.625 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cfd0> 22.916666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c978> 22.916666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 27.08333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 143.74999999999997 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 196.87499999999991 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 323.95833333333337 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 328.125 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 332.2916666666667 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 334.37500000000006 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 396.87500000000006 75
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 406.25 80
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 406.25 84
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 406.25 87
Completed Iteration #21
Best Reward: 11.458333333333336
Reward: 6.25
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8198> 6.25 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649048> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db550> 56.249999999999986 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f9b0> 62.499999999999986 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661438> 117.70833333333329 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661160> 122.91666666666663 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 149.99999999999997 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 203.12499999999991 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 330.20833333333337 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 334.375 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 338.5416666666667 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 340.62500000000006 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 403.12500000000006 76
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 412.5 81
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 412.5 85
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 412.5 88
Completed Iteration #22
Best Reward: 11.458333333333336
Completed Iteration #23
Best Reward: 11.458333333333336
Reward: 11.458333333333336
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd390> 11.458333333333336 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a1d0> 19.79166666666667 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa898> 27.083333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847aacf8> 27.083333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cfd0> 34.375 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c978> 34.375 5
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 38.541666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 161.45833333333331 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc88> 214.58333333333326 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa20> 341.6666666666667 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 345.8333333333333 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649908> 350.0 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 352.08333333333337 52
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbb70> 414.58333333333337 77
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d780> 423.9583333333333 82
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cb70> 423.9583333333333 86
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be10> 423.9583333333333 89
Completed Iteration #24
Best Reward: 11.458333333333336
Completed Iteration #25
Best Reward: 11.458333333333336
Completed MCTS Level/Depth: #8
root->6->19->0->11->0->17->7->29
Best Reward: 11.458333333333336
iteration: 6
found coverage increase 11.458333333333336
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6617b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e26a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6617b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6617b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc161e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ecbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f05f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847944e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b710> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7318d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7318d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7318d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6febe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7318d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7318d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e26a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6febe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748cf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 2.0833333333333286 11
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 2.0833333333333286 12
Completed Iteration #11
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 2.0833333333333286 13
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abd30> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 4.166666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 4.166666666666657 14
Completed Iteration #13
Best Reward: 2.0833333333333286
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab8d0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 5.2083333333333215 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 5.2083333333333215 15
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 6.249999999999993 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 9.374999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 9.374999999999986 16
Completed Iteration #17
Best Reward: 4.166666666666664
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794e48> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7942b0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abd30> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 11.458333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 11.458333333333314 17
Completed Iteration #18
Best Reward: 4.166666666666664
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794828> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7942b0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abd30> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 13.541666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 13.541666666666643 18
Completed Iteration #19
Best Reward: 4.166666666666664
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794630> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794fd0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794e48> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7942b0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abd30> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 15.624999999999972 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 15.624999999999972 19
Completed Iteration #20
Best Reward: 4.166666666666664
Completed Iteration #21
Best Reward: 4.166666666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 15.624999999999972 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 15.624999999999972 20
Completed Iteration #22
Best Reward: 4.166666666666664
Completed Iteration #23
Best Reward: 4.166666666666664
Completed Iteration #24
Best Reward: 4.166666666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7318d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 15.624999999999972 21
Completed Iteration #25
Best Reward: 4.166666666666664
Completed MCTS Level/Depth: #0
root
Best Reward: 4.166666666666664
Completed Iteration #0
Best Reward: 4.166666666666664
Completed Iteration #1
Best Reward: 4.166666666666664
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7978> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a9e8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab8d0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 16.666666666666636 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 16.666666666666636 22
Completed Iteration #2
Best Reward: 4.166666666666664
Completed Iteration #3
Best Reward: 4.166666666666664
Completed Iteration #4
Best Reward: 4.166666666666664
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d74e0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 17.7083333333333 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 17.7083333333333 23
Completed Iteration #5
Best Reward: 4.166666666666664
Completed Iteration #6
Best Reward: 4.166666666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d74e0> 1.0416666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 17.7083333333333 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 17.7083333333333 24
Completed Iteration #7
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 10.416666666666657 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 21.874999999999964 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 21.874999999999964 25
Completed Iteration #8
Best Reward: 4.166666666666664
Completed Iteration #9
Best Reward: 4.166666666666664
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab2b0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7aba58> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab8d0> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 22.91666666666663 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 22.91666666666663 26
Completed Iteration #10
Best Reward: 4.166666666666664
Completed Iteration #11
Best Reward: 4.166666666666664
Completed Iteration #12
Best Reward: 4.166666666666664
Completed Iteration #13
Best Reward: 4.166666666666664
Completed Iteration #14
Best Reward: 4.166666666666664
Completed Iteration #15
Best Reward: 4.166666666666664
Completed Iteration #16
Best Reward: 4.166666666666664
Completed Iteration #17
Best Reward: 4.166666666666664
Completed Iteration #18
Best Reward: 4.166666666666664
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c88> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7710> 1.0416666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d74e0> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 23.958333333333293 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 23.958333333333293 27
Completed Iteration #19
Best Reward: 4.166666666666664
Completed Iteration #20
Best Reward: 4.166666666666664
Completed Iteration #21
Best Reward: 4.166666666666664
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d71d0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794fd0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794e48> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7942b0> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abd30> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 26.04166666666662 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 26.04166666666662 28
Completed Iteration #22
Best Reward: 4.166666666666664
Completed Iteration #23
Best Reward: 4.166666666666664
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b518> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 9.374999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 11.458333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 27.083333333333286 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 27.083333333333286 29
Completed Iteration #24
Best Reward: 4.166666666666664
Completed Iteration #25
Best Reward: 4.166666666666664
Completed MCTS Level/Depth: #1
root->8
Best Reward: 4.166666666666664
Completed Iteration #0
Best Reward: 4.166666666666664
Completed Iteration #1
Best Reward: 4.166666666666664
Completed Iteration #2
Best Reward: 4.166666666666664
Completed Iteration #3
Best Reward: 4.166666666666664
Completed Iteration #4
Best Reward: 4.166666666666664
Completed Iteration #5
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f160> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 13.541666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 15.624999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 31.24999999999995 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 31.24999999999995 30
Completed Iteration #6
Best Reward: 4.166666666666664
Completed Iteration #7
Best Reward: 4.166666666666664
Completed Iteration #8
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef898> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef860> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f160> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 17.70833333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 19.79166666666665 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 35.416666666666615 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 35.416666666666615 31
Completed Iteration #9
Best Reward: 4.166666666666664
Completed Iteration #10
Best Reward: 4.166666666666664
Completed Iteration #11
Best Reward: 4.166666666666664
Completed Iteration #12
Best Reward: 4.166666666666664
Completed Iteration #13
Best Reward: 4.166666666666664
Completed Iteration #14
Best Reward: 4.166666666666664
Completed Iteration #15
Best Reward: 4.166666666666664
Completed Iteration #16
Best Reward: 4.166666666666664
Completed Iteration #17
Best Reward: 4.166666666666664
Completed Iteration #18
Best Reward: 4.166666666666664
Completed Iteration #19
Best Reward: 4.166666666666664
Completed Iteration #20
Best Reward: 4.166666666666664
Completed Iteration #21
Best Reward: 4.166666666666664
Completed Iteration #22
Best Reward: 4.166666666666664
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0569e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 19.79166666666665 7
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 21.87499999999998 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 37.49999999999994 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 37.49999999999994 32
Completed Iteration #23
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056160> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 23.958333333333314 8
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 26.041666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 41.66666666666661 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 41.66666666666661 33
Completed Iteration #24
Best Reward: 4.166666666666664
Completed Iteration #25
Best Reward: 4.166666666666664
Completed MCTS Level/Depth: #2
root->8->6
Best Reward: 4.166666666666664
Completed Iteration #0
Best Reward: 4.166666666666664
Completed Iteration #1
Best Reward: 4.166666666666664
Completed Iteration #2
Best Reward: 4.166666666666664
Completed Iteration #3
Best Reward: 4.166666666666664
Completed Iteration #4
Best Reward: 4.166666666666664
Completed Iteration #5
Best Reward: 4.166666666666664
Completed Iteration #6
Best Reward: 4.166666666666664
Completed Iteration #7
Best Reward: 4.166666666666664
Completed Iteration #8
Best Reward: 4.166666666666664
Completed Iteration #9
Best Reward: 4.166666666666664
Completed Iteration #10
Best Reward: 4.166666666666664
Completed Iteration #11
Best Reward: 4.166666666666664
Completed Iteration #12
Best Reward: 4.166666666666664
Completed Iteration #13
Best Reward: 4.166666666666664
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c898> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e6a0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0569e8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 26.041666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 28.12499999999997 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 43.749999999999936 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 43.749999999999936 34
Completed Iteration #14
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a7f0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef860> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f160> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 24.999999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 30.208333333333307 10
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 32.291666666666636 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 47.9166666666666 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 47.9166666666666 35
Completed Iteration #15
Best Reward: 4.166666666666664
Completed Iteration #16
Best Reward: 4.166666666666664
Completed Iteration #17
Best Reward: 4.166666666666664
Completed Iteration #18
Best Reward: 4.166666666666664
Completed Iteration #19
Best Reward: 4.166666666666664
Completed Iteration #20
Best Reward: 4.166666666666664
Completed Iteration #21
Best Reward: 4.166666666666664
Completed Iteration #22
Best Reward: 4.166666666666664
Completed Iteration #23
Best Reward: 4.166666666666664
Completed Iteration #24
Best Reward: 4.166666666666664
Completed Iteration #25
Best Reward: 4.166666666666664
Completed MCTS Level/Depth: #3
root->8->6->0
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0474e0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef860> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f160> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 24.999999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 24.999999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 29.16666666666665 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 34.37499999999997 11
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 36.4583333333333 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 52.083333333333265 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 52.083333333333265 36
Completed Iteration #0
Best Reward: 4.166666666666664
coverage_call_count 900
Completed Iteration #1
Best Reward: 4.166666666666664
Completed Iteration #2
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056748> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ecc0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056160> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 24.999999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 29.16666666666665 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 29.16666666666665 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 33.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 38.541666666666636 12
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 40.624999999999964 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 56.24999999999993 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 56.24999999999993 37
Completed Iteration #3
Best Reward: 4.166666666666664
Completed Iteration #4
Best Reward: 4.166666666666664
Completed Iteration #5
Best Reward: 4.166666666666664
Completed Iteration #6
Best Reward: 4.166666666666664
Completed Iteration #7
Best Reward: 4.166666666666664
Completed Iteration #8
Best Reward: 4.166666666666664
Completed Iteration #9
Best Reward: 4.166666666666664
Completed Iteration #10
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030ef0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030b70> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a7f0> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef860> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f160> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 29.16666666666665 8
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 33.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 33.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 37.49999999999998 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 42.7083333333333 13
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 44.79166666666663 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 60.41666666666659 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 60.41666666666659 38
Completed Iteration #11
Best Reward: 4.166666666666664
Completed Iteration #12
Best Reward: 4.166666666666664
Completed Iteration #13
Best Reward: 4.166666666666664
Completed Iteration #14
Best Reward: 4.166666666666664
Completed Iteration #15
Best Reward: 4.166666666666664
Completed Iteration #16
Best Reward: 4.166666666666664
Completed Iteration #17
Best Reward: 4.166666666666664
Completed Iteration #18
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028dd8> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef860> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f160> 24.999999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 33.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 37.49999999999998 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 37.49999999999998 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 41.66666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 46.874999999999964 14
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 48.95833333333329 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 64.58333333333326 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 64.58333333333326 39
Completed Iteration #19
Best Reward: 4.166666666666664
Completed Iteration #20
Best Reward: 4.166666666666664
Completed Iteration #21
Best Reward: 4.166666666666664
Completed Iteration #22
Best Reward: 4.166666666666664
Completed Iteration #23
Best Reward: 4.166666666666664
Completed Iteration #24
Best Reward: 4.166666666666664
Completed Iteration #25
Best Reward: 4.166666666666664
Completed MCTS Level/Depth: #4
root->8->6->0->8
Best Reward: 4.166666666666664
Completed Iteration #0
Best Reward: 4.166666666666664
Completed Iteration #1
Best Reward: 4.166666666666664
Completed Iteration #2
Best Reward: 4.166666666666664
Completed Iteration #3
Best Reward: 4.166666666666664
Completed Iteration #4
Best Reward: 4.166666666666664
Completed Iteration #5
Best Reward: 4.166666666666664
Completed Iteration #6
Best Reward: 4.166666666666664
Completed Iteration #7
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d240> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d828> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056748> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ecc0> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056160> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 37.49999999999998 10
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 41.66666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 41.66666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 45.83333333333331 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 51.04166666666663 15
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 53.12499999999996 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 68.74999999999991 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 68.74999999999991 40
Completed Iteration #8
Best Reward: 4.166666666666664
Completed Iteration #9
Best Reward: 4.166666666666664
Completed Iteration #10
Best Reward: 4.166666666666664
Completed Iteration #11
Best Reward: 4.166666666666664
Completed Iteration #12
Best Reward: 4.166666666666664
Completed Iteration #13
Best Reward: 4.166666666666664
Completed Iteration #14
Best Reward: 4.166666666666664
Completed Iteration #15
Best Reward: 4.166666666666664
Completed Iteration #16
Best Reward: 4.166666666666664
Completed Iteration #17
Best Reward: 4.166666666666664
Completed Iteration #18
Best Reward: 4.166666666666664
Completed Iteration #19
Best Reward: 4.166666666666664
Completed Iteration #20
Best Reward: 4.166666666666664
Completed Iteration #21
Best Reward: 4.166666666666664
Completed Iteration #22
Best Reward: 4.166666666666664
Completed Iteration #23
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0305f8> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030be0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d240> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d828> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056748> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ecc0> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056160> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 41.66666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 45.83333333333331 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 45.83333333333331 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 49.99999999999997 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 55.20833333333329 16
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 57.29166666666662 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 72.91666666666657 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 72.91666666666657 41
Completed Iteration #24
Best Reward: 4.166666666666664
Completed Iteration #25
Best Reward: 4.166666666666664
Completed MCTS Level/Depth: #5
root->8->6->0->8->3
Best Reward: 4.166666666666664
Completed Iteration #0
Best Reward: 4.166666666666664
Completed Iteration #1
Best Reward: 4.166666666666664
Completed Iteration #2
Best Reward: 4.166666666666664
Completed Iteration #3
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047cc0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 45.83333333333331 12
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 49.99999999999997 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 49.99999999999997 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 54.166666666666636 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 59.37499999999996 17
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 61.458333333333286 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 77.08333333333323 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 77.08333333333323 42
Completed Iteration #4
Best Reward: 4.166666666666664
Completed Iteration #5
Best Reward: 4.166666666666664
Completed Iteration #6
Best Reward: 4.166666666666664
Completed Iteration #7
Best Reward: 4.166666666666664
Completed Iteration #8
Best Reward: 4.166666666666664
Completed Iteration #9
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d320> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 49.99999999999997 13
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 54.166666666666636 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 54.166666666666636 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 58.3333333333333 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 63.54166666666662 18
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 65.62499999999994 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 81.24999999999989 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 81.24999999999989 43
Completed Iteration #10
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe78475c080> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e940> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0305f8> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030be0> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d240> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d828> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056748> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ecc0> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056160> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 54.166666666666636 14
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 58.3333333333333 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 58.3333333333333 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 62.499999999999964 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 67.70833333333329 19
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 69.7916666666666 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 85.41666666666654 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 85.41666666666654 44
Completed Iteration #11
Best Reward: 4.166666666666664
Completed Iteration #12
Best Reward: 4.166666666666664
Completed Iteration #13
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe78475cc88> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475ccf8> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047cc0> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 58.3333333333333 15
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 62.499999999999964 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 62.499999999999964 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 66.66666666666663 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 71.87499999999994 20
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 73.95833333333326 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 89.5833333333332 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 89.5833333333332 45
Completed Iteration #14
Best Reward: 4.166666666666664
Completed Iteration #15
Best Reward: 4.166666666666664
Completed Iteration #16
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe77df835c0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83630> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d320> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 62.499999999999964 16
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 66.66666666666663 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 66.66666666666663 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 70.83333333333329 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 76.0416666666666 21
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 78.12499999999991 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 93.74999999999986 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 93.74999999999986 46
Completed Iteration #17
Best Reward: 4.166666666666664
Completed Iteration #18
Best Reward: 4.166666666666664
Completed Iteration #19
Best Reward: 4.166666666666664
Completed Iteration #20
Best Reward: 4.166666666666664
Completed Iteration #21
Best Reward: 4.166666666666664
Completed Iteration #22
Best Reward: 4.166666666666664
Completed Iteration #23
Best Reward: 4.166666666666664
Completed Iteration #24
Best Reward: 4.166666666666664
Completed Iteration #25
Best Reward: 4.166666666666664
Completed MCTS Level/Depth: #6
root->8->6->0->8->3->26
Best Reward: 4.166666666666664
Completed Iteration #0
Best Reward: 4.166666666666664
Completed Iteration #1
Best Reward: 4.166666666666664
Completed Iteration #2
Best Reward: 4.166666666666664
Completed Iteration #3
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06dda0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d828> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056748> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ecc0> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056160> 24.999999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 66.66666666666663 17
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 70.83333333333329 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 70.83333333333329 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 74.99999999999994 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 80.20833333333326 22
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 82.29166666666657 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 97.91666666666652 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 97.91666666666652 47
Completed Iteration #4
Best Reward: 4.166666666666664
Completed Iteration #5
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe78475cf28> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 70.83333333333329 18
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 74.99999999999994 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 74.99999999999994 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 79.1666666666666 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 84.37499999999991 23
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 86.45833333333323 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 102.08333333333317 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 102.08333333333317 48
Completed Iteration #6
Best Reward: 4.166666666666664
Completed Iteration #7
Best Reward: 4.166666666666664
Completed Iteration #8
Best Reward: 4.166666666666664
Completed Iteration #9
Best Reward: 4.166666666666664
Completed Iteration #10
Best Reward: 4.166666666666664
Completed Iteration #11
Best Reward: 4.166666666666664
Completed Iteration #12
Best Reward: 4.166666666666664
Completed Iteration #13
Best Reward: 4.166666666666664
Completed Iteration #14
Best Reward: 4.166666666666664
Completed Iteration #15
Best Reward: 4.166666666666664
Completed Iteration #16
Best Reward: 4.166666666666664
Completed Iteration #17
Best Reward: 4.166666666666664
Completed Iteration #18
Best Reward: 4.166666666666664
Completed Iteration #19
Best Reward: 4.166666666666664
Completed Iteration #20
Best Reward: 4.166666666666664
Completed Iteration #21
Best Reward: 4.166666666666664
Completed Iteration #22
Best Reward: 4.166666666666664
Completed Iteration #23
Best Reward: 4.166666666666664
Completed Iteration #24
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe77df9ee80> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae2e8> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475cf28> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 74.99999999999994 19
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 79.1666666666666 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 79.1666666666666 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 83.33333333333326 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 88.54166666666657 24
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 90.62499999999989 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 106.24999999999983 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 106.24999999999983 49
Completed Iteration #25
Best Reward: 4.166666666666664
Completed MCTS Level/Depth: #7
root->8->6->0->8->3->26->0
Best Reward: 4.166666666666664
Completed Iteration #0
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae5f8> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d828> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056748> 24.999999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ecc0> 24.999999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056160> 29.16666666666665 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 79.1666666666666 20
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 83.33333333333326 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 83.33333333333326 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 87.49999999999991 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 92.70833333333323 25
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 94.79166666666654 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 110.41666666666649 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 110.41666666666649 50
Completed Iteration #1
Best Reward: 4.166666666666664
Completed Iteration #2
Best Reward: 4.166666666666664
Completed Iteration #3
Best Reward: 4.166666666666664
Completed Iteration #4
Best Reward: 4.166666666666664
coverage_call_count 1000
Completed Iteration #5
Best Reward: 4.166666666666664
Completed Iteration #6
Best Reward: 4.166666666666664
Completed Iteration #7
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaed30> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb96a0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c080> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e940> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0305f8> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030be0> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d240> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d828> 24.999999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056748> 29.16666666666665 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ecc0> 29.16666666666665 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056160> 33.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 83.33333333333326 21
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 87.49999999999991 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 87.49999999999991 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 91.66666666666657 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 96.87499999999989 26
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 98.9583333333332 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 114.58333333333314 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 114.58333333333314 51
Completed Iteration #8
Best Reward: 4.166666666666664
Completed Iteration #9
Best Reward: 4.166666666666664
Completed Iteration #10
Best Reward: 4.166666666666664
Completed Iteration #11
Best Reward: 4.166666666666664
Completed Iteration #12
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe77df44048> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d828> 29.16666666666665 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056748> 33.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ecc0> 33.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056160> 37.49999999999998 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 87.49999999999991 22
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 91.66666666666657 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 91.66666666666657 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 95.83333333333323 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 101.04166666666654 27
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 103.12499999999986 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 118.7499999999998 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 118.7499999999998 52
Completed Iteration #13
Best Reward: 4.166666666666664
Completed Iteration #14
Best Reward: 4.166666666666664
Completed Iteration #15
Best Reward: 4.166666666666664
Completed Iteration #16
Best Reward: 4.166666666666664
Completed Iteration #17
Best Reward: 4.166666666666664
Completed Iteration #18
Best Reward: 4.166666666666664
Completed Iteration #19
Best Reward: 4.166666666666664
Completed Iteration #20
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e9b0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e940> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0305f8> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030be0> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d240> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d828> 33.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056748> 37.49999999999998 10
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ecc0> 37.49999999999998 10
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056160> 41.66666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 91.66666666666657 23
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 95.83333333333323 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 95.83333333333323 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 99.99999999999989 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 105.2083333333332 28
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 107.29166666666652 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 122.91666666666646 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 122.91666666666646 53
Completed Iteration #21
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaecc0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ecc0> 41.66666666666664 11
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056160> 45.83333333333331 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 95.83333333333323 24
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8160> 99.99999999999989 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d438> 99.99999999999989 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 104.16666666666654 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab588> 109.37499999999986 29
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa2b0> 111.45833333333317 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe048> 127.08333333333312 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dd68> 127.08333333333312 54
Completed Iteration #22
Best Reward: 4.166666666666664
Completed Iteration #23
Best Reward: 4.166666666666664
Completed Iteration #24
Best Reward: 4.166666666666664
Completed Iteration #25
Best Reward: 4.166666666666664
Completed MCTS Level/Depth: #8
root->8->6->0->8->3->26->0->1
Best Reward: 4.166666666666664
iteration: 15
found coverage increase 4.166666666666664
Current Total Coverage 25.0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df447b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc174668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 25.0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaeb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaeb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaeb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae550> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 25.0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df097b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df097b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 25.0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c080> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 25.0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded75f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8780> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 25.0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df090b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1af28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c5c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 25.0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 1.0416666666666679 8
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 1.0416666666666679 9
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77de902e8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 2.0833333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 2.0833333333333357 10
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 2.0833333333333357 11
Completed Iteration #15
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77de909b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 3.1250000000000036 6
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 3.1250000000000036 12
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77df1ac50> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 4.166666666666671 7
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 4.166666666666671 13
Completed Iteration #19
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 4.166666666666671 14
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c518> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c588> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de909b0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 5.208333333333339 8
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 5.208333333333339 15
Completed Iteration #22
Best Reward: 1.0416666666666679
coverage_call_count 1200
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c978> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 6.250000000000007 9
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 6.250000000000007 16
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 7.291666666666675 10
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 7.291666666666675 17
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77dea49e8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 8.333333333333343 11
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 8.333333333333343 18
Completed Iteration #5
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4cc0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 9.37500000000001 12
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 9.37500000000001 19
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4fd0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 10.416666666666679 13
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 10.416666666666679 20
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1550> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb15c0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea49e8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 11.458333333333346 14
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 11.458333333333346 21
Completed Iteration #12
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77deb19e8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1898> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1550> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77deb15c0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea49e8> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 12.500000000000014 15
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 12.500000000000014 22
Completed Iteration #13
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c518> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c588> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de909b0> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 12.500000000000014 16
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 12.500000000000014 23
Completed Iteration #14
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e470> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09908> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4fd0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 13.541666666666682 17
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 13.541666666666682 24
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb38> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 14.58333333333335 18
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 14.58333333333335 25
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77dea45c0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4ba8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb38> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 15.625000000000018 19
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 15.625000000000018 26
Completed Iteration #23
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 16.666666666666686 20
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 16.666666666666686 27
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #1
root->2
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 17.708333333333353 21
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 17.708333333333353 28
Completed Iteration #0
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77df83f60> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90978> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 18.75000000000002 22
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 18.75000000000002 29
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e3c8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae4a8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c978> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 19.79166666666669 23
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 19.79166666666669 30
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77df44b70> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09d30> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83f60> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90978> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 20.833333333333357 24
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 20.833333333333357 31
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Completed Iteration #10
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1a58> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae4a8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c978> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 21.875000000000025 25
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 21.875000000000025 32
Completed Iteration #11
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77de52080> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 10.416666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 22.916666666666693 26
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 22.916666666666693 33
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77de52630> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 8.333333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 11.458333333333346 12
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 23.95833333333336 27
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 23.95833333333336 34
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e10> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09d30> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df83f60> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90978> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 12.500000000000014 13
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 25.00000000000003 28
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 25.00000000000003 35
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77de59470> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 13.541666666666682 14
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 26.041666666666696 29
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 26.041666666666696 36
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #2
root->2->6
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8f98> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 11.458333333333343 11
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 15.625000000000014 15
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 28.12500000000003 30
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 28.12500000000003 37
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77de527b8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 4.166666666666668 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 5.208333333333336 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 12.50000000000001 12
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 16.666666666666682 16
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 29.166666666666696 31
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 29.166666666666696 38
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #3
root->2->6->0
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ef0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 5.208333333333336 5
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 6.2500000000000036 6
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 13.541666666666679 13
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 17.70833333333335 17
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 30.208333333333364 32
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 30.208333333333364 39
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe77de90438> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 6.2500000000000036 6
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 7.291666666666671 7
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 14.583333333333346 14
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 18.750000000000018 18
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 31.250000000000032 33
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 31.250000000000032 40
Completed Iteration #5
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe734009630> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 7.291666666666671 7
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 8.33333333333334 8
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 15.625000000000014 15
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 19.791666666666686 19
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 32.2916666666667 34
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 32.2916666666667 41
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe734009eb8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 8.33333333333334 8
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 9.375000000000007 9
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 16.666666666666682 16
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 20.833333333333353 20
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 33.33333333333337 35
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 33.33333333333337 42
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 9.375000000000007 9
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 10.416666666666675 10
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 17.70833333333335 17
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 21.87500000000002 21
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 34.37500000000004 36
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 34.37500000000004 43
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe73401b198> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010e80> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ef0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 10.416666666666675 10
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 11.458333333333343 11
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 18.750000000000018 18
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 22.91666666666669 22
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 35.416666666666714 37
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 35.416666666666714 44
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
coverage_call_count 1300
Completed Iteration #21
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe73401b7f0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 11.458333333333343 11
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 12.50000000000001 12
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 19.791666666666686 19
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 23.958333333333357 23
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 36.458333333333385 38
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 36.458333333333385 45
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #4
root->2->6->0->5
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe734009f98> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010e80> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ef0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 12.50000000000001 12
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 13.541666666666679 13
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 20.833333333333353 20
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 25.000000000000025 24
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 37.50000000000006 39
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 37.50000000000006 46
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4080> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401bdd8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009630> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 13.541666666666679 13
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 14.583333333333346 14
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 21.87500000000002 21
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 26.041666666666693 25
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 38.54166666666673 40
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 38.54166666666673 47
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe73401b898> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009390> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8f98> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 6.25 5
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 15.62500000000001 14
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 16.66666666666668 15
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 23.958333333333353 22
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 28.125000000000025 26
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 40.62500000000006 41
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 40.62500000000006 48
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #5
root->2->6->0->5->0
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cf8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 7.291666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 8.333333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 17.708333333333343 15
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 18.75000000000001 16
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 26.041666666666686 23
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 30.208333333333357 27
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 42.708333333333385 42
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 42.708333333333385 49
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce9b0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cee10> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cf8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 9.374999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 10.416666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 19.791666666666675 16
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 20.833333333333343 17
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 28.125000000000018 24
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 32.291666666666686 28
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 44.791666666666714 43
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 44.791666666666714 50
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #6
root->2->6->0->5->0->4
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5f98> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009240> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de527b8> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 11.458333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 12.499999999999996 8
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 21.875000000000007 17
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 22.916666666666675 18
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 30.20833333333335 25
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 34.375000000000014 29
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 46.87500000000004 44
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 46.87500000000004 51
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a2e8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 13.54166666666666 8
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 14.583333333333329 9
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 23.95833333333334 18
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 25.000000000000007 19
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 32.291666666666686 26
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 36.45833333333334 30
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 48.95833333333337 45
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 48.95833333333337 52
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe73401bd68> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401bcc0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5f98> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe734009240> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de527b8> 5.208333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 15.624999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 16.66666666666666 10
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 26.04166666666667 19
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 27.08333333333334 20
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 34.375000000000014 27
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 38.54166666666667 31
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 51.0416666666667 46
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 51.0416666666667 53
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5e10> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cee10> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cf8> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 17.708333333333325 10
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 18.749999999999993 11
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 28.125000000000004 20
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 29.16666666666667 21
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 36.45833333333334 28
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 40.625 32
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 53.12500000000003 47
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 53.12500000000003 54
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dde48> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddef0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a2e8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 19.791666666666657 11
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 20.833333333333325 12
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 30.208333333333336 21
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 31.250000000000004 22
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 38.54166666666667 29
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 42.70833333333333 33
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 55.20833333333336 48
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 55.20833333333336 55
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #7
root->2->6->0->5->0->4->2
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7908> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cee10> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cf8> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 21.87499999999999 12
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 22.916666666666657 13
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 32.29166666666667 22
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 33.333333333333336 23
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 40.625 30
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 44.79166666666666 34
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 57.291666666666686 49
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 57.291666666666686 56
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fa90> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cee10> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cf8> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 23.95833333333332 13
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 24.99999999999999 14
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 34.375 23
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 35.41666666666667 24
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 42.70833333333333 31
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 46.874999999999986 35
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 59.375000000000014 50
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 59.375000000000014 57
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d79bc18> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cee10> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cf8> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a20> 26.041666666666654 14
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4198> 27.08333333333332 15
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 36.45833333333333 24
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4710> 37.5 25
backprop <src.mcts.MCTS_Node object at 0x7fe77de90358> 44.79166666666666 32
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 48.958333333333314 36
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 61.45833333333334 51
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 61.45833333333334 58
Completed Iteration #18
Best Reward: 2.083333333333332
coverage_call_count 1400
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #8
root->2->6->0->5->0->4->2->1
Best Reward: 2.083333333333332
iteration: 22
found coverage increase 2.083333333333332
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e70b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b208> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77f0> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 2.0833333333333357 16
Completed Iteration #18
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 2.0833333333333357 17
Completed Iteration #19
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e70b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 2.0833333333333357 18
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #0
root
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77f0> 2.0833333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 2.0833333333333357 19
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77f0> 2.0833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 2.0833333333333357 20
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77f0> 2.0833333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 2.0833333333333357 21
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77f0> 2.0833333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 2.0833333333333357 22
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77f0> 2.0833333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 2.0833333333333357 23
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #1
root->7
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #2
root->7->26
Best Reward: 2.0833333333333357
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 2.0833333333333357
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7111d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d9b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7200b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7372e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720b70> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d737748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7579b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7579b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d74da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9da0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 1600
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6852e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6852e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ceda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340091d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340105f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734010ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340105c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340095f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340105c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d57f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44e0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340090f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340094e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340104e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d59e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340104a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340099b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340099b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340104a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d685828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340099b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340104a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ceda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d694320> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de736d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de73860> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df095c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73630> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de596d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de907f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1acc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 2
Completed Iteration #2
Best Reward: 0
coverage_call_count 1900
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8438> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90668> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de596d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de596d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de596d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 2000
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded76a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c908> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df832e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ce80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 21
Completed Iteration #23
Best Reward: 0
coverage_call_count 2100
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df9efd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df839e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0309b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0309b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b00> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 14
Completed Iteration #20
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cecc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ecbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7942b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7942b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7942b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb8cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7942b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 2300
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abe10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7697b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7190b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7190b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7190b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7198d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847545f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc70b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847540b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340096d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340096d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df83dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340096d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb8224a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb8224a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb822160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f86a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb8224a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f86a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78477fb00> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe819ede588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6611d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb822470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7314e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb822240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f89b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f89b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f89b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 1.0416666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 1.0416666666666643 22
Completed Iteration #24
Best Reward: 1.0416666666666643
Completed Iteration #25
Best Reward: 1.0416666666666643
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666643
Completed Iteration #0
Best Reward: 1.0416666666666643
Completed Iteration #1
Best Reward: 1.0416666666666643
Completed Iteration #2
Best Reward: 1.0416666666666643
Completed Iteration #3
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 1.0416666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 1.0416666666666643 23
Completed Iteration #4
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 1.0416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 1.0416666666666643 24
Completed Iteration #5
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 1.0416666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 1.0416666666666643 25
Completed Iteration #6
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 1.0416666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 1.0416666666666643 26
Completed Iteration #7
Best Reward: 1.0416666666666643
Completed Iteration #8
Best Reward: 1.0416666666666643
Completed Iteration #9
Best Reward: 1.0416666666666643
Completed Iteration #10
Best Reward: 1.0416666666666643
Completed Iteration #11
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 1.0416666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 1.0416666666666643 27
Completed Iteration #12
Best Reward: 1.0416666666666643
Completed Iteration #13
Best Reward: 1.0416666666666643
Completed Iteration #14
Best Reward: 1.0416666666666643
Completed Iteration #15
Best Reward: 1.0416666666666643
Completed Iteration #16
Best Reward: 1.0416666666666643
Completed Iteration #17
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 1.0416666666666643 10
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 1.0416666666666643 28
Completed Iteration #18
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 1.0416666666666643 11
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 1.0416666666666643 29
Completed Iteration #19
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 1.0416666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 1.0416666666666643 30
Completed Iteration #20
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 1.0416666666666643 13
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 1.0416666666666643 31
Completed Iteration #21
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 1.0416666666666643 14
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 1.0416666666666643 32
Completed Iteration #22
Best Reward: 1.0416666666666643
Completed Iteration #23
Best Reward: 1.0416666666666643
Completed Iteration #24
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5ba8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 2.0833333333333286 15
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 2.0833333333333286 33
Completed Iteration #25
Best Reward: 1.0416666666666643
Completed MCTS Level/Depth: #1
root->6
Best Reward: 1.0416666666666643
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 4.166666666666661 16
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 4.166666666666661 34
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe78477f390> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a668> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 4.166666666666661 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 5.208333333333325 17
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 5.208333333333325 35
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 4.166666666666661 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 5.208333333333325 18
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 5.208333333333325 36
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4cc0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c64a8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f390> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe78473a668> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 5.208333333333325 6
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 6.249999999999989 19
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 6.249999999999989 37
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #2
root->6->7
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4908> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 7.291666666666657 7
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 8.333333333333321 20
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 8.333333333333321 38
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae0f0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 5.208333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 8.333333333333321 8
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 9.374999999999986 21
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 9.374999999999986 39
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fa90> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 7.291666666666661 6
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 10.416666666666654 9
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 11.458333333333318 22
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 11.458333333333318 40
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 7.291666666666661 7
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 10.416666666666654 10
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 11.458333333333318 23
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 11.458333333333318 41
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db470> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 8.333333333333325 8
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 11.458333333333318 11
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 12.499999999999982 24
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 12.499999999999982 42
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748dd8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 10.416666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 13.54166666666665 12
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 14.583333333333314 25
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 14.583333333333314 43
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #3
root->6->7->0
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 12.49999999999999 10
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 15.624999999999982 13
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 16.666666666666647 26
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 16.666666666666647 44
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
coverage_call_count 2600
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f828> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 14.583333333333321 11
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 17.708333333333314 14
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 18.74999999999998 27
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 18.74999999999998 45
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db828> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 14.583333333333325 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 16.666666666666654 12
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 19.791666666666647 15
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 20.83333333333331 28
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 20.83333333333331 46
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #4
root->6->7->0->8
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 14.583333333333325 8
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 16.666666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 18.749999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 21.87499999999998 16
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 22.916666666666643 29
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 22.916666666666643 47
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bbe0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 16.666666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 18.74999999999999 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 20.833333333333318 14
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 23.95833333333331 17
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 24.999999999999975 30
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 24.999999999999975 48
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #5
root->6->7->0->8->6
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee1d0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee9b0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 18.74999999999999 10
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 20.83333333333332 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 22.91666666666665 15
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 26.041666666666643 18
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 27.083333333333307 31
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 27.083333333333307 49
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dcf8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee9b0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 20.83333333333332 11
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 22.916666666666654 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 24.999999999999982 16
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 28.124999999999975 19
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 29.16666666666664 32
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 29.16666666666664 50
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748208> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d96d8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee1d0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee9b0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 22.916666666666654 12
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 24.999999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 27.083333333333314 17
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 30.208333333333307 20
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 31.24999999999997 33
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 31.24999999999997 51
Completed Iteration #19
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee9b0> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 24.999999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 27.083333333333318 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 29.166666666666647 18
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 32.29166666666664 21
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 33.3333333333333 34
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 33.3333333333333 52
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bc18> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 14.583333333333325 8
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 27.083333333333318 14
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 29.16666666666665 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 31.24999999999998 19
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 34.37499999999997 22
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 35.41666666666663 35
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 35.41666666666663 53
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #6
root->6->7->0->8->6->27
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028da0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d96d8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee1d0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee9b0> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 14.583333333333325 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 16.666666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 29.16666666666665 15
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 31.249999999999982 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 33.333333333333314 20
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 36.4583333333333 23
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 37.49999999999996 36
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 37.49999999999996 54
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0978> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 16.666666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 18.74999999999999 10
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 31.249999999999982 16
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 33.333333333333314 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 35.41666666666664 21
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 38.54166666666663 24
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 39.583333333333286 37
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 39.583333333333286 55
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d74de80> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d128> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0978> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 18.74999999999999 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 20.83333333333332 11
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 33.333333333333314 17
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 35.41666666666664 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 37.49999999999997 22
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 40.62499999999996 25
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 41.666666666666615 38
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 41.666666666666615 56
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #7
root->6->7->0->8->6->27->6
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a7b8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d96d8> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee1d0> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee9b0> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 14.583333333333325 8
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 20.83333333333332 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 22.916666666666654 12
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 35.41666666666664 18
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 37.49999999999997 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 39.5833333333333 23
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 42.708333333333286 26
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 43.74999999999994 39
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 43.74999999999994 57
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748908> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d96d8> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee1d0> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee9b0> 14.583333333333325 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 16.666666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 22.916666666666654 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 24.999999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 37.49999999999997 19
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 39.5833333333333 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 41.66666666666663 24
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 44.791666666666615 27
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 45.83333333333327 40
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 45.83333333333327 58
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
coverage_call_count 2700
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c7f0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d358> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dcf8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee9b0> 16.666666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 18.74999999999999 10
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 24.999999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 27.083333333333318 14
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 39.5833333333333 20
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 41.66666666666663 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 43.74999999999996 25
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 46.87499999999994 28
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 47.9166666666666 41
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 47.9166666666666 59
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a390> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee9b0> 18.74999999999999 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 20.83333333333332 11
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 27.083333333333318 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 29.16666666666665 15
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 41.66666666666663 21
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 43.74999999999996 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 45.833333333333286 26
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 48.95833333333327 29
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 49.99999999999993 42
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 49.99999999999993 60
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b208> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79be10> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c7f0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d358> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dcf8> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee9b0> 20.83333333333332 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 22.916666666666654 12
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 29.16666666666665 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 31.249999999999982 16
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 43.74999999999996 22
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 45.833333333333286 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 47.916666666666615 27
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 51.0416666666666 30
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 52.08333333333326 43
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 52.08333333333326 61
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7fe72d737160> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a588> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a7b8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d96d8> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee1d0> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee9b0> 22.916666666666654 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c128> 24.999999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d438> 31.249999999999982 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 33.333333333333314 17
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdd30> 45.833333333333286 23
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 47.916666666666615 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 49.99999999999994 28
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 53.12499999999993 31
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 54.166666666666586 44
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8fd0> 54.166666666666586 62
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #8
root->6->7->0->8->6->27->6->4
Best Reward: 2.083333333333332
iteration: 63
found coverage increase 2.083333333333332
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf60> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 2.0833333333333286 7
Completed Iteration #6
Best Reward: 2.0833333333333286
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d7577f0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf60> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 3.125 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 3.125 8
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 3.125 9
Completed Iteration #9
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 3.125 10
Completed Iteration #10
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 3.125 11
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe78473a5c0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf60> 4.166666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 4.166666666666671 12
Completed Iteration #13
Best Reward: 2.0833333333333286
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d7373c8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 5.208333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 5.208333333333343 13
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 6.250000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 6.250000000000014 14
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d79bdd8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79be80> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7373c8> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 8.333333333333343 8
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 8.333333333333343 15
Completed Iteration #17
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d79bda0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 10.416666666666671 9
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 10.416666666666671 16
Completed Iteration #18
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d737828> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 5.208333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 12.5 10
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 12.5 17
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0e10> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 4.166666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf60> 6.25 5
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 14.583333333333329 11
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 14.583333333333329 18
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f320> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f438> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7577f0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 5.208333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf60> 7.291666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 15.625 12
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 15.625 19
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 17.70833333333333 13
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 17.70833333333333 20
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #0
root
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7be0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 18.75 14
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 18.75 21
Completed Iteration #3
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 9.374999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 20.83333333333333 15
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 20.83333333333333 22
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7b00> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7c88> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7373c8> 4.166666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 21.875 16
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 21.875 23
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f198> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 23.95833333333333 17
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 23.95833333333333 24
Completed Iteration #8
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c3c8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf60> 9.375 7
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 26.041666666666657 18
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 26.041666666666657 25
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6615f8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 28.124999999999986 19
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 28.124999999999986 26
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf60> 9.375 8
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 28.124999999999986 20
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 28.124999999999986 27
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f400> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fef0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7be0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 30.208333333333314 21
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 30.208333333333314 28
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cf8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711cc0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79bdd8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d79be80> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7373c8> 6.25 5
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 32.29166666666664 22
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 32.29166666666664 29
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fc50> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fcc0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c3c8> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf60> 10.416666666666671 9
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 33.333333333333314 23
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 33.333333333333314 30
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 33.333333333333314 24
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 33.333333333333314 31
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #1
root->0
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d79be10> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 11.458333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 35.41666666666664 25
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 35.41666666666664 32
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #2
root->0->7
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
coverage_call_count 2800
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c0f0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 13.541666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 37.49999999999997 26
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 37.49999999999997 33
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d74df60> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d860> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737828> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 14.5833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 15.624999999999972 9
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 39.5833333333333 27
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 39.5833333333333 34
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0289e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028cc0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79bda0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 16.66666666666663 9
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 17.7083333333333 10
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 41.66666666666663 28
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 41.66666666666663 35
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7e80> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 18.749999999999957 10
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 19.79166666666663 11
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 43.74999999999996 29
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 43.74999999999996 36
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d737e80> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79be10> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 20.833333333333286 11
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 21.874999999999957 12
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 45.833333333333286 30
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 45.833333333333286 37
Completed Iteration #23
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fe10> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 22.916666666666615 12
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 23.958333333333286 13
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 47.916666666666615 31
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 47.916666666666615 38
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #3
root->0->7->8
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d7f0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fda0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 24.999999999999943 13
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 26.041666666666615 14
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 49.99999999999994 32
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 49.99999999999994 39
Completed Iteration #10
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748e80> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 27.08333333333327 14
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 28.124999999999943 15
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 52.08333333333327 33
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 52.08333333333327 40
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649ba8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 29.1666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 30.20833333333327 16
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 54.1666666666666 34
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 54.1666666666666 41
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #4
root->0->7->8->9
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b9b0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 14.5833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 31.24999999999993 16
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 32.2916666666666 17
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 56.24999999999993 35
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 56.24999999999993 42
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0280f0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d828> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748e80> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 14.5833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 16.66666666666663 9
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 33.33333333333326 17
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 34.37499999999993 18
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 58.33333333333326 36
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 58.33333333333326 43
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae080> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c588> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0280f0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d828> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748e80> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 16.66666666666663 9
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 18.749999999999957 10
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 35.416666666666586 18
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 36.45833333333326 19
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 60.416666666666586 37
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 60.416666666666586 44
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe72d711ac8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720668> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 18.749999999999957 10
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 20.833333333333286 11
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 37.499999999999915 19
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 38.541666666666586 20
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 62.499999999999915 38
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 62.499999999999915 45
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae9e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 20.833333333333286 11
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 22.916666666666615 12
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 39.58333333333324 20
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 40.624999999999915 21
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 64.58333333333324 39
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 64.58333333333324 46
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b1d0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69ba58> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649ba8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 22.916666666666615 12
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 24.999999999999943 13
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 41.66666666666657 21
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 42.70833333333324 22
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 66.66666666666657 40
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 66.66666666666657 47
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #5
root->0->7->8->9->8
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0668> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475ccc0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711ac8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720668> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 24.999999999999943 13
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 27.08333333333327 14
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 43.7499999999999 22
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 44.79166666666657 23
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 68.7499999999999 41
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 68.7499999999999 48
Completed Iteration #3
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028978> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649eb8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0668> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe78475ccc0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d711ac8> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d720668> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 27.08333333333327 14
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 29.1666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 45.83333333333323 23
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 46.8749999999999 24
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 70.83333333333323 42
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 70.83333333333323 49
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720668> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 29.1666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 31.24999999999993 16
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 47.91666666666656 24
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 48.95833333333323 25
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 72.91666666666656 43
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 72.91666666666656 50
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db0f0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f710> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028978> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649eb8> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0668> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe78475ccc0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d711ac8> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d720668> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 14.5833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 31.24999999999993 16
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 33.33333333333326 17
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 49.999999999999886 25
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 51.04166666666656 26
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 74.99999999999989 44
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 74.99999999999989 51
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6860> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aef98> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d7f0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fda0> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 16.66666666666663 9
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 33.33333333333326 17
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 35.416666666666586 18
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 52.083333333333215 26
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 53.124999999999886 27
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 77.08333333333321 45
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 77.08333333333321 52
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07db70> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f9e8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6860> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aef98> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d7f0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fda0> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 18.749999999999957 10
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 35.416666666666586 18
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 37.499999999999915 19
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 54.16666666666654 27
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 55.208333333333215 28
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 79.16666666666654 46
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 79.16666666666654 53
Completed Iteration #20
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bc18> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fda0> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 20.833333333333286 11
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 37.499999999999915 19
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 39.58333333333324 20
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 56.24999999999987 28
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 57.29166666666654 29
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 81.24999999999987 47
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 81.24999999999987 54
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #6
root->0->7->8->9->8->6
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Completed Iteration #1
Best Reward: 2.0833333333333286
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db320> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475ccc0> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d711ac8> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d720668> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 22.916666666666615 12
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 39.58333333333324 20
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 41.66666666666657 21
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 58.3333333333332 29
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 59.37499999999987 30
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 83.3333333333332 48
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 83.3333333333332 55
Completed Iteration #5
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6c88> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720668> 14.5833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 24.999999999999943 13
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 41.66666666666657 21
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 43.7499999999999 22
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 60.41666666666653 30
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 61.4583333333332 31
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 85.41666666666653 49
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 85.41666666666653 56
Completed Iteration #6
Best Reward: 2.0833333333333286
coverage_call_count 2900
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4828> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475ccf8> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720668> 16.66666666666663 9
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 27.08333333333327 14
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 43.7499999999999 22
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 45.83333333333323 23
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 62.49999999999986 31
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 63.54166666666653 32
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 87.49999999999986 50
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 87.49999999999986 57
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8c18> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f710> 4.166666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028978> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649eb8> 6.249999999999986 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0668> 8.333333333333314 5
backprop <src.mcts.MCTS_Node object at 0x7fe78475ccc0> 10.416666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d711ac8> 12.499999999999972 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d720668> 18.749999999999957 10
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 29.1666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 45.83333333333323 23
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 47.91666666666656 24
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 64.58333333333319 32
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 65.62499999999986 33
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 89.58333333333319 51
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 89.58333333333319 58
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #7
root->0->7->8->9->8->6->8
Best Reward: 2.0833333333333286
Completed Iteration #0
Best Reward: 2.0833333333333286
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd438> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a3c8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db0f0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f710> 5.208333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028978> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649eb8> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0668> 9.374999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7fe78475ccc0> 11.458333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d711ac8> 13.541666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7fe72d720668> 19.79166666666663 11
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 30.20833333333327 16
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 46.8749999999999 24
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 48.95833333333323 25
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 65.62499999999986 33
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 66.66666666666653 34
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 90.62499999999986 52
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 90.62499999999986 59
Completed Iteration #1
Best Reward: 2.0833333333333286
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aef60> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a3c8> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db0f0> 5.208333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f710> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028978> 9.374999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649eb8> 9.374999999999986 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0668> 11.458333333333314 7
backprop <src.mcts.MCTS_Node object at 0x7fe78475ccc0> 13.541666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7fe72d711ac8> 15.624999999999972 9
backprop <src.mcts.MCTS_Node object at 0x7fe72d720668> 21.874999999999957 12
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e78d0> 32.2916666666666 17
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7208> 48.95833333333323 25
backprop <src.mcts.MCTS_Node object at 0x7fe72d711eb8> 51.04166666666656 26
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 67.70833333333319 34
backprop <src.mcts.MCTS_Node object at 0x7fe72d7376a0> 68.74999999999986 35
backprop <src.mcts.MCTS_Node object at 0x7fe784794438> 92.70833333333319 53
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a20> 92.70833333333319 60
Completed Iteration #2
Best Reward: 2.0833333333333286
Completed Iteration #3
Best Reward: 2.0833333333333286
Completed Iteration #4
Best Reward: 2.0833333333333286
Completed Iteration #5
Best Reward: 2.0833333333333286
Completed Iteration #6
Best Reward: 2.0833333333333286
Completed Iteration #7
Best Reward: 2.0833333333333286
Completed Iteration #8
Best Reward: 2.0833333333333286
Completed Iteration #9
Best Reward: 2.0833333333333286
Completed Iteration #10
Best Reward: 2.0833333333333286
Completed Iteration #11
Best Reward: 2.0833333333333286
Completed Iteration #12
Best Reward: 2.0833333333333286
Completed Iteration #13
Best Reward: 2.0833333333333286
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Completed Iteration #18
Best Reward: 2.0833333333333286
Completed Iteration #19
Best Reward: 2.0833333333333286
Completed Iteration #20
Best Reward: 2.0833333333333286
Completed Iteration #21
Best Reward: 2.0833333333333286
Completed Iteration #22
Best Reward: 2.0833333333333286
Completed Iteration #23
Best Reward: 2.0833333333333286
Completed Iteration #24
Best Reward: 2.0833333333333286
Completed Iteration #25
Best Reward: 2.0833333333333286
Completed MCTS Level/Depth: #8
root->0->7->8->9->8->6->8->0
Best Reward: 2.0833333333333286
iteration: 64
found coverage increase 2.0833333333333286
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7946a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7946a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e22b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847546d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847945c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847945c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb947278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ecbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7693c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce10> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847940b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847940b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d74a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe784754e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10c710> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3100
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e20f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feb00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847949b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06de80> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ab38> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d75c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d9e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df448d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe819ede588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df448d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df448d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df448d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d71d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de522e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de522e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de737f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c8d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de528d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2898> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847547f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c45c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c45c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847547f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c45c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7340102b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de908d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de524e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de908d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 16
Completed Iteration #17
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7693c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de591d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d694160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6943c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6947b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6948d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6948d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6858d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 33.33333333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7003170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7003175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 3600
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7003170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c40b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 33.33333333333333
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700322710> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 1.0416666666666714 2
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 1.0416666666666714 3
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700322f28> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322be0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322710> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 2.083333333333343 4
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700330080> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 3.125000000000014 5
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322710> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 3.125000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 3.125000000000014 6
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700330668> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322be0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700322710> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 4.166666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 4.166666666666686 7
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 4.166666666666686 8
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330668> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe700322be0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe700322710> 3.125000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 4.166666666666686 8
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 4.166666666666686 9
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 5.208333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 5.208333333333357 10
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700317ac8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 6.250000000000028 10
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 6.250000000000028 11
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7003300f0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 7.2916666666667 11
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 7.2916666666667 12
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700330550> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330588> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003300f0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 8.333333333333371 12
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 8.333333333333371 13
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700330b38> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322be0> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe700322710> 4.166666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 9.375000000000043 13
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 9.375000000000043 14
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700330e80> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 10.416666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 10.416666666666714 15
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe70033f208> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f048> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330b38> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700322be0> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7fe700322710> 5.208333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 11.458333333333385 15
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 11.458333333333385 16
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe70033f6a0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003306a0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 12.500000000000057 16
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 12.500000000000057 17
Completed Iteration #21
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe70033f9b0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f860> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330080> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 13.541666666666728 17
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 13.541666666666728 18
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe70033fef0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff60> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322f28> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700322be0> 5.208333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7fe700322710> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 14.5833333333334 18
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 14.5833333333334 19
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7003304a8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f860> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700330080> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 15.625000000000071 19
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 15.625000000000071 20
Completed Iteration #1
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe70033f5c0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f860> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe700330080> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 16.666666666666742 20
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 16.666666666666742 21
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330550> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe700330588> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe7003300f0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 16.666666666666742 21
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 16.666666666666742 22
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700317dd8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003179b0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fef0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff60> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700322f28> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe700322be0> 6.250000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7fe700322710> 7.2916666666667 10
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 17.708333333333414 22
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 17.708333333333414 23
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f860> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe700330080> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 17.708333333333414 23
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 17.708333333333414 24
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700330d68> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003305c0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330e80> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 18.750000000000085 24
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 18.750000000000085 25
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe70033f2e8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003306a0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 19.791666666666757 25
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 19.791666666666757 26
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330550> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7fe700330588> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7fe7003300f0> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 19.791666666666757 26
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 19.791666666666757 27
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700317320> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df096a0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003300f0> 3.125000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 20.833333333333428 27
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 20.833333333333428 28
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700317fd0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003178d0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330e80> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 21.8750000000001 28
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 21.8750000000001 29
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7003225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317ac8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 21.8750000000001 29
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 21.8750000000001 30
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f860> 3.125000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7fe700330080> 4.166666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 21.8750000000001 30
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 21.8750000000001 31
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 21.8750000000001 31
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 21.8750000000001 32
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 21.8750000000001 32
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 21.8750000000001 33
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 21.8750000000001 33
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 21.8750000000001 34
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe77df83940> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee908> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f5c0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033f860> 4.166666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7fe700330080> 5.208333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 22.91666666666677 34
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 22.91666666666677 35
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #1
root->0
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003306a0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 22.91666666666677 35
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 22.91666666666677 36
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d694940> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003306a0> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 23.958333333333442 36
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 23.958333333333442 37
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 4.166666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 23.958333333333442 37
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 23.958333333333442 38
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7198> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003306a0> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 5.208333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 25.000000000000114 38
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 25.000000000000114 39
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002e77b8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f940> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 26.041666666666785 39
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 26.041666666666785 40
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700322f60> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f940> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 7.2916666666667 10
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 27.083333333333456 40
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 27.083333333333456 41
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 2.083333333333343
backprop <src.mcts.MCTS_Node object at 0x7fe78473ac18> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 9.375000000000043 11
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 29.1666666666668 41
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 29.1666666666668 42
Completed Iteration #18
Best Reward: 2.083333333333343
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700330898> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef7f0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e77b8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033f940> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 10.416666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 30.20833333333347 42
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 30.20833333333347 43
Completed Iteration #19
Best Reward: 2.083333333333343
Completed Iteration #20
Best Reward: 2.083333333333343
Completed Iteration #21
Best Reward: 2.083333333333343
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe77de59208> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8b38> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 11.458333333333385 13
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 31.250000000000142 43
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 31.250000000000142 44
Completed Iteration #22
Best Reward: 2.083333333333343
Completed Iteration #23
Best Reward: 2.083333333333343
Completed Iteration #24
Best Reward: 2.083333333333343
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5630> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 3.125000000000014 3
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 12.500000000000057 14
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 32.29166666666681 44
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 32.29166666666681 45
Completed Iteration #25
Best Reward: 2.083333333333343
Completed MCTS Level/Depth: #2
root->0->2
Best Reward: 2.083333333333343
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002c88d0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8780> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5630> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 4.166666666666686 4
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 13.541666666666728 15
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 33.333333333333485 45
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 33.333333333333485 46
Completed Iteration #0
Best Reward: 2.083333333333343
Reward: 2.083333333333343
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 6.250000000000028 5
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 15.625000000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 35.41666666666683 46
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 35.41666666666683 47
Completed Iteration #1
Best Reward: 2.083333333333343
Completed Iteration #2
Best Reward: 2.083333333333343
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002e78d0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 3.125000000000014 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 7.2916666666667 6
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 16.666666666666742 17
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 36.4583333333335 47
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 36.4583333333335 48
Completed Iteration #3
Best Reward: 2.083333333333343
Completed Iteration #4
Best Reward: 2.083333333333343
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa0f0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 8.333333333333371 7
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 17.708333333333414 18
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 37.50000000000017 48
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 37.50000000000017 49
Completed Iteration #5
Best Reward: 2.083333333333343
Completed Iteration #6
Best Reward: 2.083333333333343
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700317978> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7e10> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e78d0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 4.166666666666686 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 9.375000000000043 8
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 18.750000000000085 19
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 38.54166666666684 49
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 38.54166666666684 50
Completed Iteration #7
Best Reward: 2.083333333333343
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa780> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa5c0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e78d0> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 5.208333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 10.416666666666714 9
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 19.791666666666757 20
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 39.58333333333351 50
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 39.58333333333351 51
Completed Iteration #8
Best Reward: 2.083333333333343
Completed Iteration #9
Best Reward: 2.083333333333343
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002fada0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fae10> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473ac18> 3.125000000000014 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 11.458333333333385 10
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 20.833333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 40.625000000000185 51
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 40.625000000000185 52
Completed Iteration #10
Best Reward: 2.083333333333343
coverage_call_count 3700
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700282320> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282128> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5630> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 12.500000000000057 11
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 21.8750000000001 22
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 41.666666666666856 52
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 41.666666666666856 53
Completed Iteration #11
Best Reward: 2.083333333333343
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047940> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322828> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473ac18> 4.166666666666686 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 13.541666666666728 12
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 22.91666666666677 23
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 42.70833333333353 53
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 42.70833333333353 54
Completed Iteration #12
Best Reward: 2.083333333333343
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 6.250000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 8.333333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 16.66666666666673 13
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 26.04166666666677 24
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 45.83333333333353 54
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 45.83333333333353 55
Completed Iteration #13
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 17.7083333333334 14
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 27.083333333333442 25
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 46.8750000000002 55
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 46.8750000000002 56
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7b70> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7c88> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 18.75000000000007 15
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 28.125000000000114 26
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 47.91666666666687 56
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 47.91666666666687 57
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473ac18> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 18.75000000000007 16
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 28.125000000000114 27
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 47.91666666666687 57
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 47.91666666666687 58
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa4a8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 19.791666666666742 17
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 29.166666666666785 28
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 48.95833333333354 58
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 48.95833333333354 59
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #3
root->0->2->6
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Reward: 2.083333333333343
backprop <src.mcts.MCTS_Node object at 0x7fe700282358> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 8.333333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 10.4166666666667 7
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 21.875000000000085 18
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 31.250000000000128 29
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 51.041666666666885 59
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 51.041666666666885 60
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 10.4166666666667 8
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 21.875000000000085 19
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 31.250000000000128 30
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 51.041666666666885 60
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 51.041666666666885 61
Completed Iteration #7
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1240> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282630> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282358> 3.125000000000014 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 9.375000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 11.458333333333371 9
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 22.916666666666757 20
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 32.2916666666668 31
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 52.083333333333556 61
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 52.083333333333556 62
Completed Iteration #8
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1668> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1518> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 12.500000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 14.583333333333371 10
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 26.041666666666757 21
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 35.4166666666668 32
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 55.208333333333556 62
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 55.208333333333556 63
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad160> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1fd0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1668> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1518> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 7.291666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 13.5416666666667 9
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 15.625000000000043 11
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 27.083333333333428 22
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 36.45833333333347 33
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 56.25000000000023 63
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 56.25000000000023 64
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282358> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 13.5416666666667 10
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 15.625000000000043 12
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 27.083333333333428 23
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 36.45833333333347 34
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 56.25000000000023 64
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 56.25000000000023 65
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d56a0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad160> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1fd0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1668> 5.208333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1518> 5.208333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 14.583333333333371 11
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 16.666666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 28.1250000000001 24
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 37.50000000000014 35
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 57.2916666666669 65
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 57.2916666666669 66
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d56a0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad160> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1fd0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1668> 5.208333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1518> 5.208333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 8.333333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 14.583333333333371 12
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 16.666666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 28.1250000000001 25
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 37.50000000000014 36
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 57.2916666666669 66
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 57.2916666666669 67
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 16.666666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 28.1250000000001 26
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 37.50000000000014 37
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 57.2916666666669 67
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 57.2916666666669 68
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #4
root->0->2->6->18
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002a18d0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1fd0> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1668> 6.250000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1518> 6.250000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 9.375000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 15.625000000000043 13
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 17.708333333333385 16
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 29.16666666666677 27
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 38.54166666666681 38
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 58.33333333333357 68
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 58.33333333333357 69
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Reward: 2.083333333333343
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad400> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad630> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d56a0> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad160> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1fd0> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1668> 8.333333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1518> 8.333333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 11.458333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 17.708333333333385 14
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 19.79166666666673 17
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 31.250000000000114 28
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 40.625000000000156 39
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 60.41666666666691 69
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 60.41666666666691 70
Completed Iteration #9
Best Reward: 3.125
Completed Iteration #10
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe700282f98> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1518> 11.458333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 14.583333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 20.833333333333385 15
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 22.91666666666673 18
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 34.375000000000114 29
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 43.750000000000156 40
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 63.54166666666691 70
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 63.54166666666691 71
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700241668> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1518> 12.500000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 15.625000000000028 10
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 21.875000000000057 16
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 23.9583333333334 19
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 35.416666666666785 30
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 44.79166666666683 41
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 64.58333333333358 71
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 64.58333333333358 72
Completed Iteration #15
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700241a58> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241898> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa780> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa5c0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e78d0> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 22.91666666666673 17
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 25.00000000000007 20
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 36.45833333333346 31
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 45.8333333333335 42
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 65.62500000000026 72
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 65.62500000000026 73
Completed Iteration #16
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe70033f5f8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa90> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317978> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7e10> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e78d0> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 23.9583333333334 18
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 26.041666666666742 21
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 37.50000000000013 32
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 46.87500000000017 43
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 66.66666666666693 73
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 66.66666666666693 74
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 15.625000000000028 11
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 23.9583333333334 19
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 26.041666666666742 22
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 37.50000000000013 33
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 46.87500000000017 44
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 66.66666666666693 74
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 66.66666666666693 75
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 27.0833333333334 20
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 29.166666666666742 23
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 40.62500000000013 34
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 50.00000000000017 45
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 69.79166666666693 75
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 69.79166666666693 76
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #5
root->0->2->6->18->3
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Reward: 2.083333333333343
backprop <src.mcts.MCTS_Node object at 0x7fe7002544a8> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254518> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 5.208333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 29.166666666666742 21
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 31.250000000000085 24
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 42.70833333333347 35
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 52.08333333333351 46
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 71.87500000000027 76
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 71.87500000000027 77
Completed Iteration #8
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad588> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 8.333333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 32.29166666666674 22
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 34.375000000000085 25
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 45.83333333333347 36
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 55.20833333333351 47
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 75.00000000000027 77
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 75.00000000000027 78
Completed Iteration #9
Best Reward: 3.125
Reward: 2.083333333333343
backprop <src.mcts.MCTS_Node object at 0x7fe7002549b0> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 5.208333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 10.416666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 34.375000000000085 23
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 36.45833333333343 26
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 47.91666666666681 37
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 57.291666666666856 48
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 77.08333333333361 78
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 77.08333333333361 79
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Completed Iteration #18
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7002626a0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 8.333333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 13.541666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 37.500000000000085 24
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 39.58333333333343 27
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 51.04166666666681 38
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 60.416666666666856 49
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 80.20833333333361 79
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 80.20833333333361 80
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Reward: 2.083333333333343
backprop <src.mcts.MCTS_Node object at 0x7fe700262f28> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262e80> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002549b0> 4.166666666666686 3
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 10.416666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 15.625000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 39.58333333333343 25
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 41.66666666666677 28
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 53.125000000000156 39
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 62.5000000000002 50
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 82.29166666666696 80
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 82.29166666666696 81
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #6
root->0->2->6->18->3->4
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700270f28> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e400> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262f28> 3.125000000000014 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262e80> 3.125000000000014 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002549b0> 5.208333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 11.458333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 16.6666666666667 8
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 40.6250000000001 26
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 42.70833333333344 29
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 54.16666666666683 40
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 63.54166666666687 51
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 83.33333333333363 81
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 83.33333333333363 82
Completed Iteration #8
Best Reward: 3.125
coverage_call_count 3800
Completed Iteration #9
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad828> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1898> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002626a0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 12.500000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 17.70833333333337 9
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 41.66666666666677 27
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 43.750000000000114 30
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 55.2083333333335 41
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 64.58333333333354 52
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 84.3750000000003 82
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 84.3750000000003 83
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700241e10> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e400> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262f28> 4.166666666666686 4
backprop <src.mcts.MCTS_Node object at 0x7fe700262e80> 4.166666666666686 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002549b0> 6.250000000000028 5
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 13.5416666666667 8
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 18.750000000000043 10
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 42.70833333333344 28
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 44.791666666666785 31
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 56.25000000000017 42
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 65.62500000000021 53
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 85.41666666666697 83
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 85.41666666666697 84
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7002709b0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1898> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002626a0> 7.291666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 16.6666666666667 9
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 21.875000000000043 11
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 45.83333333333344 29
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 47.916666666666785 32
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 59.37500000000017 43
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 68.75000000000021 54
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 88.54166666666697 84
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 88.54166666666697 85
Completed Iteration #18
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270f28> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe70027e400> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe700262f28> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe700262e80> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002549b0> 6.250000000000028 6
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 16.6666666666667 10
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 21.875000000000043 12
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 45.83333333333344 30
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 47.916666666666785 33
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 59.37500000000017 44
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 68.75000000000021 55
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 88.54166666666697 85
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 88.54166666666697 86
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Reward: 2.083333333333343
backprop <src.mcts.MCTS_Node object at 0x7fe70027ebe0> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027ec50> 2.083333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262f28> 6.250000000000028 6
backprop <src.mcts.MCTS_Node object at 0x7fe700262e80> 6.250000000000028 6
backprop <src.mcts.MCTS_Node object at 0x7fe7002549b0> 8.333333333333371 7
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 18.750000000000043 11
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 23.958333333333385 13
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 47.916666666666785 31
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 50.00000000000013 34
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 61.45833333333351 45
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 70.83333333333356 56
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 90.62500000000031 86
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 90.62500000000031 87
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #7
root->0->2->6->18->3->4->2
Best Reward: 3.125
Completed Iteration #0
Best Reward: 3.125
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad828> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1898> 4.166666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002626a0> 7.291666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 18.750000000000043 12
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 23.958333333333385 14
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 47.916666666666785 32
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 50.00000000000013 35
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 61.45833333333351 46
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 70.83333333333356 57
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 90.62500000000031 87
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 90.62500000000031 88
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700221d68> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1898> 5.208333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002626a0> 8.333333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 19.791666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 25.000000000000057 15
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 48.95833333333346 33
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 51.0416666666668 36
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 62.500000000000185 47
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 71.87500000000023 58
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 91.66666666666698 88
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 91.66666666666698 89
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7002add68> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254668> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002709b0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1898> 8.333333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7fe7002626a0> 11.458333333333343 7
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 22.916666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 28.125000000000057 16
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 52.08333333333346 34
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 54.1666666666668 37
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 65.62500000000018 48
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 75.00000000000023 59
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 94.79166666666698 89
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 94.79166666666698 90
Completed Iteration #10
Best Reward: 3.125
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Completed Iteration #14
Best Reward: 3.125
Completed Iteration #15
Best Reward: 3.125
Completed Iteration #16
Best Reward: 3.125
Completed Iteration #17
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8f28> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1898> 11.458333333333343 7
backprop <src.mcts.MCTS_Node object at 0x7fe7002626a0> 14.583333333333343 8
backprop <src.mcts.MCTS_Node object at 0x7fe700241c18> 26.041666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 31.250000000000057 17
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7a20> 55.20833333333346 35
backprop <src.mcts.MCTS_Node object at 0x7fe7002e74a8> 57.2916666666668 38
backprop <src.mcts.MCTS_Node object at 0x7fe70033f588> 68.75000000000018 49
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 78.12500000000023 60
backprop <src.mcts.MCTS_Node object at 0x7fe7003221d0> 97.91666666666698 90
backprop <src.mcts.MCTS_Node object at 0x7fe700322278> 97.91666666666698 91
Completed Iteration #18
Best Reward: 3.125
Completed Iteration #19
Best Reward: 3.125
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Completed Iteration #22
Best Reward: 3.125
Completed Iteration #23
Best Reward: 3.125
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #8
root->0->2->6->18->3->4->2->3
Best Reward: 3.125
iteration: 91
found coverage increase 3.125
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002216d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001cac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001cae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3780> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002216d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700221e10> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700270710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001cab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001cab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002adda0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001884e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001887b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700188358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002211d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001f38d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001981d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002547b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001981d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001885f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700270588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001982b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700270208> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001542e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3e10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002542e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001629b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001628d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001628d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001542e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001982b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f31d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010eef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3cc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ac88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 4100
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ac88> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ac88> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000cac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ac88> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000cac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013ac88> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000cac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70013ac88> 0.0 7
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000cafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ac88> 0.0 8
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013ac88> 0.0 9
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013ac88> 0.0 10
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ac88> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ac88> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013ac88> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2be0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000cac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000caba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700282cc0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df441d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df447b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df447b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7080> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000cafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002549b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7003179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fada0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a17f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7003304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7003305c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003229b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fb38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700317eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700317eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000cada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000cada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700317860> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003179b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003179b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6854a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7340104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7003302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003302e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700330978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003229e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003229e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 4500
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cf28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df090f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0479e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 4600
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df836d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0476d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7efef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df09748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb822748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb822128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b55f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa0f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e25c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdac8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01efd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7202b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc1542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847f84e0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7205c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc1542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 4800
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784794828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d711748> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6fe320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6feac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe1d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdb38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de730b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d94a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 10
Completed Iteration #8
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d94a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d94a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d94a8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d74df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9438> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d757ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc01e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0284a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0284a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 3
Completed Iteration #4
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7575f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d757f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7576d8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475cb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475cb38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7375f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75fcf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac748f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7484e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc056470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7484e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6499b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6499b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6499b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7488d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d720898> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe70016f278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002415c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70027e160> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 5200
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002212b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700241208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016feb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78475ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aefd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aefd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7001d75c0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700270ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700270c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002707f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad3c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700270978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700270630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700270908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001987f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700270390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700270fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001980b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002707f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002adc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002adef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001885c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac769438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002707f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc047b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7485c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002add30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001caf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001caf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001caf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70016fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c37b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c37b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3320> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700270438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001caf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002622e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002622e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700270940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001cab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 19
Completed Iteration #19
Best Reward: 0
coverage_call_count 5400
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f35c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002add30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700188780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001623c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700221a20> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 36.45833333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facae6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f160> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001cac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001f35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027ea90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facaea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facaecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facaee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001cac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facaef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700262828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac637b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac720f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac638d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeb38> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 36.45833333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 1.0416666666666714 7
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 1.0416666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 1.0416666666666714 8
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 2.083333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 2.083333333333343 9
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 2.083333333333343 7
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 2.083333333333343 10
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 2.083333333333343 11
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78475cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 2.083333333333343 12
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 2.083333333333343 13
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 2.083333333333343 14
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facaea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facae6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 2.083333333333343 15
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 2.083333333333343 8
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 2.083333333333343 16
Completed Iteration #18
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3358> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 3.125000000000014 9
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 3.125000000000014 17
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facae6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 3.125000000000014 18
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad400> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63588> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3358> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 4.166666666666686 10
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 4.166666666666686 19
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 4.166666666666686 20
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700188780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 4.166666666666686 11
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 4.166666666666686 21
Completed Iteration #1
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 4.166666666666686 12
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 4.166666666666686 22
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700262c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 4.166666666666686 13
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 4.166666666666686 23
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 5.208333333333357 14
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 5.208333333333357 24
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91550> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad400> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63588> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3358> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 6.250000000000028 15
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 6.250000000000028 25
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f940> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 7.2916666666667 16
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 7.2916666666667 26
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 6.250000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 7.2916666666667 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 7.2916666666667 17
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 7.2916666666667 27
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63588> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3358> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 7.2916666666667 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 7.2916666666667 18
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 7.2916666666667 28
Completed Iteration #10
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f940> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 6.250000000000028 10
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 7.2916666666667 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 7.2916666666667 19
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 7.2916666666667 29
Completed Iteration #11
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700262668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f940> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 6.250000000000028 11
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 7.2916666666667 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 7.2916666666667 20
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 7.2916666666667 30
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 6.250000000000028 12
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 7.2916666666667 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 7.2916666666667 21
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 7.2916666666667 31
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac723c8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac721d0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3358> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 7.2916666666667 13
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 8.333333333333371 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 8.333333333333371 22
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 8.333333333333371 32
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 8.333333333333371 23
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 8.333333333333371 33
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac013c8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 9.375000000000043 24
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 9.375000000000043 34
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac013c8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 9.375000000000043 25
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 9.375000000000043 35
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 9.375000000000043 26
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 9.375000000000043 36
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 8.333333333333371 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 9.375000000000043 27
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 9.375000000000043 37
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 9.375000000000043 28
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 9.375000000000043 38
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #1
root->2
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63588> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3358> 4.166666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 7.2916666666667 14
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 8.333333333333371 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 9.375000000000043 29
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 9.375000000000043 39
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91550> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad400> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63588> 2.083333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3358> 4.166666666666686 8
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 7.2916666666667 15
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 8.333333333333371 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 9.375000000000043 30
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 9.375000000000043 40
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac372e8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 8.333333333333371 16
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 9.375000000000043 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 10.416666666666714 31
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 10.416666666666714 41
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 9.375000000000043 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 10.416666666666714 32
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 10.416666666666714 42
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 9.375000000000043 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 10.416666666666714 33
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 10.416666666666714 43
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 8.333333333333371 17
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 9.375000000000043 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 10.416666666666714 34
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 10.416666666666714 44
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d4a8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d5c0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac372e8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 9.375000000000043 18
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 10.416666666666714 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 11.458333333333385 35
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 11.458333333333385 45
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d940> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2dba8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac723c8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac721d0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3358> 5.208333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 10.416666666666714 19
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 11.458333333333385 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 12.500000000000057 36
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 12.500000000000057 46
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37048> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 11.458333333333385 20
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 12.500000000000057 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 13.541666666666728 37
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 13.541666666666728 47
Completed Iteration #18
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 12.500000000000057 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 13.541666666666728 38
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 13.541666666666728 48
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37ba8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 12.500000000000057 21
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 13.541666666666728 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 14.5833333333334 39
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 14.5833333333334 49
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37ef0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 13.541666666666728 22
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 14.5833333333334 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 15.625000000000071 40
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 15.625000000000071 50
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #2
root->2->19
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d940> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2dba8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac723c8> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac721d0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3358> 5.208333333333357 10
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 13.541666666666728 23
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 14.5833333333334 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 15.625000000000071 41
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 15.625000000000071 51
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f940> 1.0416666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 13.541666666666728 24
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 14.5833333333334 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 15.625000000000071 42
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 15.625000000000071 52
Completed Iteration #10
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3be0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3978> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 14.5833333333334 25
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 15.625000000000071 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 16.666666666666742 43
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 16.666666666666742 53
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d4a8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d5c0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac372e8> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 14.5833333333334 26
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 15.625000000000071 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 16.666666666666742 44
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 16.666666666666742 54
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7cae80> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d35f8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d4a8> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d5c0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac372e8> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 15.625000000000071 27
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 16.666666666666742 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 17.708333333333414 45
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 17.708333333333414 55
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #3
root->2->19->7
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3be0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3978> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 5.208333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 15.625000000000071 28
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 16.666666666666742 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 17.708333333333414 46
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 17.708333333333414 56
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3978> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 5.208333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 15.625000000000071 29
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 16.666666666666742 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 17.708333333333414 47
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 17.708333333333414 57
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac012b0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 16.666666666666742 30
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 17.708333333333414 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 18.750000000000085 48
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 18.750000000000085 58
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9a58> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 7.2916666666667 10
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 17.708333333333414 31
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 18.750000000000085 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 19.791666666666757 49
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 19.791666666666757 59
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3978> 1.0416666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 7.2916666666667 11
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 17.708333333333414 32
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 18.750000000000085 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 19.791666666666757 50
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 19.791666666666757 60
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9a20> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 8.333333333333371 12
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 18.750000000000085 33
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 19.791666666666757 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 20.833333333333428 51
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 20.833333333333428 61
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff978> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff4a8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9a20> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 9.375000000000043 13
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 19.791666666666757 34
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 20.833333333333428 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 21.8750000000001 52
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 21.8750000000001 62
Completed Iteration #18
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3978> 1.0416666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 9.375000000000043 14
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 19.791666666666757 35
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 20.833333333333428 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 21.8750000000001 53
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 21.8750000000001 63
Completed Iteration #19
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6facae048> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f95f8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac012b0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 8.333333333333371 9
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 10.416666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 20.833333333333428 36
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 21.8750000000001 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 22.91666666666677 54
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 22.91666666666677 64
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 10.416666666666714 16
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 20.833333333333428 37
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 21.8750000000001 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 22.91666666666677 55
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 22.91666666666677 65
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #4
root->2->19->7->10
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9ba8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9be0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37048> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 9.375000000000043 10
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 11.458333333333385 17
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 21.8750000000001 38
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 22.91666666666677 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 23.958333333333442 56
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 23.958333333333442 66
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facae048> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f95f8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac012b0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 9.375000000000043 11
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 11.458333333333385 18
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 21.8750000000001 39
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 22.91666666666677 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 23.958333333333442 57
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 23.958333333333442 67
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ffda0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7fff98> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37ef0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 10.416666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 12.500000000000057 19
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 22.91666666666677 40
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 23.958333333333442 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 25.000000000000114 58
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 25.000000000000114 68
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 11.458333333333385 13
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 13.541666666666728 20
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 23.958333333333442 41
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 25.000000000000114 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 26.041666666666785 59
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 26.041666666666785 69
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7906a0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7904e0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9a58> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 12.500000000000057 14
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 14.5833333333334 21
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 25.000000000000114 42
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 26.041666666666785 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 27.083333333333456 60
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 27.083333333333456 70
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790f28> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 13.541666666666728 15
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 15.625000000000071 22
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 26.041666666666785 43
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 27.083333333333456 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 28.125000000000128 61
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 28.125000000000128 71
Completed Iteration #13
Best Reward: 1.0416666666666714
coverage_call_count 5700
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797320> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 14.5833333333334 16
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 16.666666666666742 23
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 27.083333333333456 44
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 28.125000000000128 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 29.1666666666668 62
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 29.1666666666668 72
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797320> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 14.5833333333334 17
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 16.666666666666742 24
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 27.083333333333456 45
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 28.125000000000128 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 29.1666666666668 63
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 29.1666666666668 73
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7906a0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7904e0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9a58> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 14.5833333333334 18
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 16.666666666666742 25
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 27.083333333333456 46
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 28.125000000000128 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 29.1666666666668 64
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 29.1666666666668 74
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797320> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 14.5833333333334 19
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 16.666666666666742 26
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 27.083333333333456 47
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 28.125000000000128 52
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 29.1666666666668 65
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 29.1666666666668 75
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff668> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff3c8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797320> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 15.625000000000071 20
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 17.708333333333414 27
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 28.125000000000128 48
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 29.1666666666668 53
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 30.20833333333347 66
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 30.20833333333347 76
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff978> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff4a8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9a20> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 15.625000000000071 21
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 17.708333333333414 28
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 28.125000000000128 49
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 29.1666666666668 54
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 30.20833333333347 67
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 30.20833333333347 77
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #5
root->2->19->7->10->1
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ffda0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7fff98> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37ef0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 6.250000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 7.2916666666667 9
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 15.625000000000071 22
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 17.708333333333414 29
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 28.125000000000128 50
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 29.1666666666668 55
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 30.20833333333347 68
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 30.20833333333347 78
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9be0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37048> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 7.2916666666667 10
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 15.625000000000071 23
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 17.708333333333414 30
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 28.125000000000128 51
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 29.1666666666668 56
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 30.20833333333347 69
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 30.20833333333347 79
Completed Iteration #1
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797b00> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac726d8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 8.333333333333371 11
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 16.666666666666742 24
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 18.750000000000085 31
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 29.1666666666668 52
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 30.20833333333347 57
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 31.250000000000142 70
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 31.250000000000142 80
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797f98> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797dd8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37048> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 7.2916666666667 10
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 9.375000000000043 12
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 17.708333333333414 25
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 19.791666666666757 32
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 30.20833333333347 53
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 31.250000000000142 58
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 32.29166666666681 71
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 32.29166666666681 81
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac726d8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 9.375000000000043 13
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 17.708333333333414 26
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 19.791666666666757 33
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 30.20833333333347 54
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 31.250000000000142 59
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 32.29166666666681 72
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 32.29166666666681 82
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ffe80> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac726d8> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 10.416666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 18.750000000000085 27
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 20.833333333333428 34
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 31.250000000000142 55
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 32.29166666666681 60
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 33.333333333333485 73
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 33.333333333333485 83
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797710> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9278> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 8.333333333333371 11
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 11.458333333333385 15
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 19.791666666666757 28
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 21.8750000000001 35
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 32.29166666666681 56
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 33.333333333333485 61
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 34.375000000000156 74
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 34.375000000000156 84
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9ba8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9be0> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37048> 3.125000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 8.333333333333371 12
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 11.458333333333385 16
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 19.791666666666757 29
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 21.8750000000001 36
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 32.29166666666681 57
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 33.333333333333485 62
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 34.375000000000156 75
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 34.375000000000156 85
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01c50> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790630> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790f28> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 9.375000000000043 13
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 12.500000000000057 17
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 20.833333333333428 30
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 22.91666666666677 37
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 33.333333333333485 58
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 34.375000000000156 63
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 35.41666666666683 76
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 35.41666666666683 86
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac726d8> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 12.500000000000057 18
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 20.833333333333428 31
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 22.91666666666677 38
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 33.333333333333485 59
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 34.375000000000156 64
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 35.41666666666683 77
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 35.41666666666683 87
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797f98> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797dd8> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37048> 3.125000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 9.375000000000043 14
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 12.500000000000057 19
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 20.833333333333428 32
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 22.91666666666677 39
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 33.333333333333485 60
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 34.375000000000156 65
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 35.41666666666683 78
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 35.41666666666683 88
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #6
root->2->19->7->10->1->17
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746e10> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790630> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790f28> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 10.416666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 13.541666666666728 20
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 21.8750000000001 33
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 23.958333333333442 40
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 34.375000000000156 61
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 35.41666666666683 66
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 36.4583333333335 79
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 36.4583333333335 89
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746390> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afb38> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797710> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9278> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 11.458333333333385 16
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 14.5833333333334 21
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 22.91666666666677 34
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 25.000000000000114 41
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 35.41666666666683 62
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 36.4583333333335 67
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 37.50000000000017 80
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 37.50000000000017 90
Completed Iteration #4
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746e10> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790630> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790f28> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 11.458333333333385 17
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 14.5833333333334 22
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 22.91666666666677 35
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 25.000000000000114 42
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 35.41666666666683 63
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 36.4583333333335 68
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 37.50000000000017 81
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 37.50000000000017 91
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797c88> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 12.500000000000057 18
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 15.625000000000071 23
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 23.958333333333442 36
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 26.041666666666785 43
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 36.4583333333335 64
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 37.50000000000017 69
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 38.54166666666684 82
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 38.54166666666684 92
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7906d8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9278> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 13.541666666666728 19
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 16.666666666666742 24
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 25.000000000000114 37
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 27.083333333333456 44
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 37.50000000000017 65
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 38.54166666666684 70
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 39.58333333333351 83
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 39.58333333333351 93
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797828> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af940> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01c50> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790630> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790f28> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 14.5833333333334 20
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 17.708333333333414 25
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 26.041666666666785 38
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 28.125000000000128 45
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 38.54166666666684 66
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 39.58333333333351 71
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 40.625000000000185 84
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 40.625000000000185 94
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797c88> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 14.5833333333334 21
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 17.708333333333414 26
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 26.041666666666785 39
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 28.125000000000128 46
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 38.54166666666684 67
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 39.58333333333351 72
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 40.625000000000185 85
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 40.625000000000185 95
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9be0> 1.0416666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37048> 3.125000000000014 8
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 14.5833333333334 22
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 17.708333333333414 27
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 26.041666666666785 40
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 28.125000000000128 47
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 38.54166666666684 68
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 39.58333333333351 73
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 40.625000000000185 86
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 40.625000000000185 96
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d278> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 15.625000000000071 23
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 18.750000000000085 28
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 27.083333333333456 41
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 29.1666666666668 48
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 39.58333333333351 69
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 40.625000000000185 74
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 41.666666666666856 87
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 41.666666666666856 97
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752b70> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 16.666666666666742 24
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 19.791666666666757 29
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 28.125000000000128 42
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 30.20833333333347 49
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 40.625000000000185 70
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 41.666666666666856 75
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 42.70833333333353 88
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 42.70833333333353 98
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d278> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 5.208333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 16.666666666666742 25
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 19.791666666666757 30
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 28.125000000000128 43
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 30.20833333333347 50
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 40.625000000000185 71
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 41.666666666666856 76
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 42.70833333333353 89
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 42.70833333333353 99
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #7
root->2->19->7->10->1->17->7
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752ba8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af198> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 6.250000000000028 8
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 17.708333333333414 26
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 20.833333333333428 31
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 29.1666666666668 44
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 31.250000000000142 51
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 41.666666666666856 72
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 42.70833333333353 77
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 43.7500000000002 90
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 43.7500000000002 100
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 17.708333333333414 27
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 20.833333333333428 32
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 29.1666666666668 45
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 31.250000000000142 52
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 41.666666666666856 73
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 42.70833333333353 78
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 43.7500000000002 91
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 43.7500000000002 101
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff6a0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797f28> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7906d8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9278> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 7.2916666666667 10
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 18.750000000000085 28
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 21.8750000000001 33
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 30.20833333333347 46
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 32.29166666666681 53
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 42.70833333333353 74
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 43.7500000000002 79
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 44.79166666666687 92
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 44.79166666666687 102
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9278> 4.166666666666686 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 7.2916666666667 11
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 18.750000000000085 29
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 21.8750000000001 34
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 30.20833333333347 47
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 32.29166666666681 54
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 42.70833333333353 75
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 43.7500000000002 80
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 44.79166666666687 93
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 44.79166666666687 103
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752f28> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746940> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d278> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 8.333333333333371 12
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 19.791666666666757 30
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 22.91666666666677 35
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 31.250000000000142 48
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 33.333333333333485 55
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 43.7500000000002 76
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 44.79166666666687 81
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 45.83333333333354 94
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 45.83333333333354 104
Completed Iteration #11
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76de80> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af198> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 9.375000000000043 13
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 20.833333333333428 31
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 23.958333333333442 36
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 32.29166666666681 49
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 34.375000000000156 56
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 44.79166666666687 77
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 45.83333333333354 82
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 46.87500000000021 95
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 46.87500000000021 105
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9278> 4.166666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 9.375000000000043 14
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 20.833333333333428 32
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 23.958333333333442 37
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 32.29166666666681 50
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 34.375000000000156 57
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 44.79166666666687 78
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 45.83333333333354 83
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 46.87500000000021 96
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 46.87500000000021 106
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ffe48> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797f28> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7906d8> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9278> 5.208333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 10.416666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 21.8750000000001 33
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 25.000000000000114 38
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 33.333333333333485 51
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 35.41666666666683 58
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 45.83333333333354 79
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 46.87500000000021 84
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 47.916666666666885 97
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 47.916666666666885 107
Completed Iteration #20
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 2.083333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 10.416666666666714 16
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 21.8750000000001 34
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 25.000000000000114 39
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 33.333333333333485 52
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 35.41666666666683 59
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 45.83333333333354 80
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 46.87500000000021 85
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 47.916666666666885 98
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 47.916666666666885 108
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76dd30> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d550> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ffe48> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797f28> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7906d8> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9278> 6.250000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7900f0> 11.458333333333385 17
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cc0> 22.91666666666677 35
backprop <src.mcts.MCTS_Node object at 0x7fe700154588> 26.041666666666785 40
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3240> 34.375000000000156 53
backprop <src.mcts.MCTS_Node object at 0x7fe6fac727f0> 36.4583333333335 60
backprop <src.mcts.MCTS_Node object at 0x7fe6fac722e8> 46.87500000000021 81
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72780> 47.916666666666885 86
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 48.958333333333556 99
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01208> 48.958333333333556 109
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #8
root->2->19->7->10->1->17->7->29
Best Reward: 1.0416666666666714
iteration: 159
found coverage increase 1.0416666666666714
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7131d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7210b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7136d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7139e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77fac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d860> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6dabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6dab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc10cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c82e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ab198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe700282a90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 6
Completed Iteration #9
Best Reward: 0
coverage_call_count 5900
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f97b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7cac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7cac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7cab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7904e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700282048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca160> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac018d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac634a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d588> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac726a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac726a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac726a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df1a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac012e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac726a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f37f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af160> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6dae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7d3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6dae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6dae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac68c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700282048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac37630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac01898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000f3630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6dae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 37.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ca278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000f33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facae470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facae9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facaea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaed30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 37.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facaee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa790a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac916a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700162630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7abf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 1.0416666666666714 19
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700154828> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 2.083333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 2.083333333333343 20
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 2.083333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 2.083333333333343 21
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 2.083333333333343 7
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 2.083333333333343 22
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 3.125000000000014 8
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 3.125000000000014 23
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facaeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 3.125000000000014 9
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 3.125000000000014 24
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6facfce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 3.125000000000014 10
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 3.125000000000014 25
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7af2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 3.125000000000014 11
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 3.125000000000014 26
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 3.125000000000014 12
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 3.125000000000014 27
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 3.125000000000014 13
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 3.125000000000014 28
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700154470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 3.125000000000014 14
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 3.125000000000014 29
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #1
root->1
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac91d68> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc240> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154828> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 4.166666666666686 15
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 4.166666666666686 30
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9ef0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 5.208333333333357 16
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 5.208333333333357 31
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc4e0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 6.250000000000028 17
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 6.250000000000028 32
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700154a20> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 7.2916666666667 18
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 7.2916666666667 33
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 8.333333333333371 9
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 8.333333333333371 19
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 8.333333333333371 34
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7001f35c0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700162b38> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 9.375000000000043 10
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 9.375000000000043 20
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 9.375000000000043 35
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #2
root->1->26
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
coverage_call_count 6200
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7ac69b240> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 8.333333333333371 9
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 10.416666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 10.416666666666714 21
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 10.416666666666714 36
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002ad438> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc240> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe700154828> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 9.375000000000043 10
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 11.458333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 11.458333333333385 22
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 11.458333333333385 37
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002adcc0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6facfc240> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe700154828> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 10.416666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 12.500000000000057 13
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 12.500000000000057 23
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 12.500000000000057 38
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c64e0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 11.458333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 13.541666666666728 14
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 13.541666666666728 24
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 13.541666666666728 39
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2dfd0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 12.500000000000057 13
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 14.5833333333334 15
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 14.5833333333334 25
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 14.5833333333334 40
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca710> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 13.541666666666728 14
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 15.625000000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 15.625000000000071 26
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 15.625000000000071 41
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #3
root->1->26->0
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700270fd0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 14.5833333333334 15
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 16.666666666666742 17
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 16.666666666666742 27
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 16.666666666666742 42
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700262f60> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 8.333333333333371 9
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 15.625000000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 17.708333333333414 18
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 17.708333333333414 28
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 17.708333333333414 43
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700198080> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 8.333333333333371 9
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 9.375000000000043 10
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 16.666666666666742 17
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 18.750000000000085 19
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 18.750000000000085 29
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 18.750000000000085 44
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #4
root->1->26->0->27
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe70016f438> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 9.375000000000043 10
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 10.416666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 17.708333333333414 18
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 19.791666666666757 20
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 19.791666666666757 30
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 19.791666666666757 45
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aed68> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f588> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9ef0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 10.416666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 11.458333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 18.750000000000085 19
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 20.833333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 20.833333333333428 31
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 20.833333333333428 46
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7bc03ec50> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe70016f588> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9ef0> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 11.458333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 12.500000000000057 13
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 19.791666666666757 20
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 21.8750000000001 22
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 21.8750000000001 32
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 21.8750000000001 47
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700221048> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 12.500000000000057 13
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 13.541666666666728 14
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 20.833333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 22.91666666666677 23
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 22.91666666666677 33
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 22.91666666666677 48
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe78475c0f0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 13.541666666666728 14
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 14.5833333333334 15
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 21.8750000000001 22
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 23.958333333333442 24
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 23.958333333333442 34
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 23.958333333333442 49
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700221160> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 14.5833333333334 15
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 15.625000000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 22.91666666666677 23
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 25.000000000000114 25
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 25.000000000000114 35
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 25.000000000000114 50
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #5
root->1->26->0->27->0
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe70016fb38> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 15.625000000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 16.666666666666742 17
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 23.958333333333442 24
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 26.041666666666785 26
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 26.041666666666785 36
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 26.041666666666785 51
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700241a90> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 16.666666666666742 17
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 17.708333333333414 18
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 25.000000000000114 25
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 27.083333333333456 27
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 27.083333333333456 37
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 27.083333333333456 52
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d757320> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f940> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241a90> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 17.708333333333414 18
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 18.750000000000085 19
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 26.041666666666785 26
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 28.125000000000128 28
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 28.125000000000128 38
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 28.125000000000128 53
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d79bcc0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 18.750000000000085 19
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 19.791666666666757 20
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 27.083333333333456 27
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 29.1666666666668 29
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 29.1666666666668 39
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 29.1666666666668 54
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d78f518> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028828> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2dfd0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 7.2916666666667 8
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 8.333333333333371 9
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 19.791666666666757 20
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 20.833333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 28.125000000000128 28
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 30.20833333333347 30
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 30.20833333333347 40
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 30.20833333333347 55
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #6
root->1->26->0->27->0->7
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
coverage_call_count 6300
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Completed Iteration #8
Best Reward: 1.0416666666666714
Completed Iteration #9
Best Reward: 1.0416666666666714
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe700221d30> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f03c8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d79bcc0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 8.333333333333371 9
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 9.375000000000043 10
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 20.833333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 21.8750000000001 22
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 29.1666666666668 29
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 31.250000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 31.250000000000142 41
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 31.250000000000142 56
Completed Iteration #24
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7002415c0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 9.375000000000043 10
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 10.416666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 21.8750000000001 22
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 22.91666666666677 23
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 30.20833333333347 30
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 32.29166666666681 32
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 32.29166666666681 42
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 32.29166666666681 57
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #7
root->1->26->0->27->0->7->0
Best Reward: 1.0416666666666714
Completed Iteration #0
Best Reward: 1.0416666666666714
Completed Iteration #1
Best Reward: 1.0416666666666714
Completed Iteration #2
Best Reward: 1.0416666666666714
Completed Iteration #3
Best Reward: 1.0416666666666714
Completed Iteration #4
Best Reward: 1.0416666666666714
Completed Iteration #5
Best Reward: 1.0416666666666714
Completed Iteration #6
Best Reward: 1.0416666666666714
Completed Iteration #7
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649588> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028828> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2dfd0> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 10.416666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 11.458333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 22.91666666666677 23
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 23.958333333333442 24
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 31.250000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 33.333333333333485 33
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 33.333333333333485 43
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 33.333333333333485 58
Completed Iteration #8
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028828> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2dfd0> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 11.458333333333385 12
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 12.500000000000057 13
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 23.958333333333442 24
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 25.000000000000114 25
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 32.29166666666681 32
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 34.375000000000156 34
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 34.375000000000156 44
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 34.375000000000156 59
Completed Iteration #9
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a390> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028828> 4.166666666666686 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2dfd0> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 12.500000000000057 13
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 13.541666666666728 14
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 25.000000000000114 25
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 26.041666666666785 26
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 33.333333333333485 33
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 35.41666666666683 35
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 35.41666666666683 45
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 35.41666666666683 60
Completed Iteration #10
Best Reward: 1.0416666666666714
Completed Iteration #11
Best Reward: 1.0416666666666714
Completed Iteration #12
Best Reward: 1.0416666666666714
Completed Iteration #13
Best Reward: 1.0416666666666714
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7fe78473acf8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0e6c50> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e77b8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc028828> 5.208333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fac2dfd0> 6.250000000000028 7
backprop <src.mcts.MCTS_Node object at 0x7fe6fac913c8> 13.541666666666728 14
backprop <src.mcts.MCTS_Node object at 0x7fe7001f3ac8> 14.5833333333334 15
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7f9d68> 26.041666666666785 26
backprop <src.mcts.MCTS_Node object at 0x7fe6facfcb00> 27.083333333333456 27
backprop <src.mcts.MCTS_Node object at 0x7fe700154c50> 34.375000000000156 34
backprop <src.mcts.MCTS_Node object at 0x7fe700154eb8> 36.4583333333335 36
backprop <src.mcts.MCTS_Node object at 0x7fe6facfca20> 36.4583333333335 46
backprop <src.mcts.MCTS_Node object at 0x7fe6fac9f1d0> 36.4583333333335 61
Completed Iteration #14
Best Reward: 1.0416666666666714
Completed Iteration #15
Best Reward: 1.0416666666666714
Completed Iteration #16
Best Reward: 1.0416666666666714
Completed Iteration #17
Best Reward: 1.0416666666666714
Completed Iteration #18
Best Reward: 1.0416666666666714
Completed Iteration #19
Best Reward: 1.0416666666666714
Completed Iteration #20
Best Reward: 1.0416666666666714
Completed Iteration #21
Best Reward: 1.0416666666666714
Completed Iteration #22
Best Reward: 1.0416666666666714
Completed Iteration #23
Best Reward: 1.0416666666666714
Completed Iteration #24
Best Reward: 1.0416666666666714
Completed Iteration #25
Best Reward: 1.0416666666666714
Completed MCTS Level/Depth: #8
root->1->26->0->27->0->7->0->23
Best Reward: 1.0416666666666714
iteration: 173
found coverage increase 1.0416666666666714
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700241cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d75f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7001ca8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d737d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dcf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784794d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7118d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7119e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe819ede0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb822748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d7978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe819ede0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc030198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6dbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dea4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac731128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc06dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df83a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7cb810ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac719780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75d0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7847c4780> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac794828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe819ede470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe819ede470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700241400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7cb822128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d757668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe819ede470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6db470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70027e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 6500
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6d9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe784754e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dec80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaef60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de73cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0fe4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77deb16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002547b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78477f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700270400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1a90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe819ede470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7d76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847aa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847e2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d711278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe819ede588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df2cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700254ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 11
Completed Iteration #16
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 38.54166666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d685710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7003304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d685cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72d685048> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d76aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d737898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe819ede7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe819ede7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de9cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78477fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfae198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77ded7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df09b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe819ede7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700221898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb822128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eeef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7cb822128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700322eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7340092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe73401b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de90630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe77de90dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df447b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 14
Completed Iteration #13
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77df447b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df44dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700317978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033f978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70027e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77df446a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002faa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7e7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe734009fd0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6857b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d694b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc07dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700330cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe734010860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe70033fd68> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df83630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac649208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe73401b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002547b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe700322c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7003225f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70033fba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7003300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013a470> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7219b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7210b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7219b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac661588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700254400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe784754710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000cad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d6a6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70010e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7219b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7977f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70010e390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000caf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d79b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70010e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700317f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac64f0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d74dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df6e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 38.54166666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df44940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77dfb98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 9
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7133c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78473ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe70033ff28> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d694b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 6900
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7134e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77deb1da0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d6eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78473ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7464a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7464a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7466d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7466d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7466d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70033f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70033f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7bc0faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d128> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 38.54166666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000cac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe77de52438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe70013a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7467b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de90390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7dddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734009cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d720be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de59a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6edba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6edc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f99182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f99185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6edc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6edf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6edc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f99300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6edcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77dfaee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6edf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99185c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed5f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f99182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7847f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7528d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f99180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de73f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000e22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7528d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7000e2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f99304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99309b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99309b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df9e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77de52438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98feb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98900f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98feac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98908d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98906a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f99300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa746358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7000ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700198048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890780> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 38.54166666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fac72c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d7c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72d78fa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 38.54166666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98551d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98550b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98550b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98550b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98551d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0c88> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98636a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98637b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa721048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe734010ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98637b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98636a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72d711a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 38.54166666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f99302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98634e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98907b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70010e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98634e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe70013ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98907b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7002c8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0908> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9863630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98782e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98786d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98786a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe550> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 38.54166666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b198> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 38.54166666666667
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98786d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98782e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98907f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa797f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe700330cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98907f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7003178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9930a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93480f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad160> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ada90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 19
Completed Iteration #21
Best Reward: 0
coverage_call_count 7400
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad1d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7002fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93adba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ac50> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe77df2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99182b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99182b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7489e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc128> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93adeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93770b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93775f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93adeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93adeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377128> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f930acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f930ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f930ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98fe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa752470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930aa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9890e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93776d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9918358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f931ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa7466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a4e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 38.54166666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cbb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92deb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cbe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cbb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb2e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 38.54166666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 38.54166666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9855b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92deac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f939ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99182b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa76d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f99182b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98786d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa77f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cba58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f931ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92deac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cf98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa713518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92de780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ccef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93775f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92856a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92856d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f924ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f924ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f925c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f924ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f924eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f925c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f925cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6fa6c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924e400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdba8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98e4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98d3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93cc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f982eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9878208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f983b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 7700
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f98786d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9377eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f930a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f931cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f9348b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 38.54166666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92cb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f925c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f925c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f925cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f925c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f925cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f924ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f925c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f93ad7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f982eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9285518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f925cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f939ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f925cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f925cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f925c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f938a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f931c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f925c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f925c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f92bdcf8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 38.54166666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92029b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f92029b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f921a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f925cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f921a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f921a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f921a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f921a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f921a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f921a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f925cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f921ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f921ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f921acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f921a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f921ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f921ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f921aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f925cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9227358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9227320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f921ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f921a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f921ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f921ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f92279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9227d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f921ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe6f9227ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe6f9202a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 38.54166666666667
initial coverage: 5.20833
time passed (minutes): 60.3466
iterations: 229
number of new inputs: 640
final coverage: 38.5417
total coverage increase: 33.3333
