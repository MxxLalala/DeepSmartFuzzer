Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, kmn_k=10000, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'kmn'], random_seed=1, runner='mcts', save_batch=False, skip_layers=[0, 5], tc1=<function tc1 at 0x7f860bb5cf28>, tc2=<function tc2 at 0x7f860bb6d048>, tc3=<function tc3 at 0x7f860bb6d158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 37.786
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.06562500000000426
backprop <src.mcts.MCTS_Node object at 0x7f8536235da0> 0.06562500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235ba8> 0.06562500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 0.06562500000000426 2
Completed Iteration #0
Best Reward: 0.06562500000000426
Completed Iteration #1
Best Reward: 0.06562500000000426
Reward: 0.10625000000000284
backprop <src.mcts.MCTS_Node object at 0x7f8536235eb8> 0.10625000000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce278> 0.10625000000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 0.1718750000000071 3
Completed Iteration #2
Best Reward: 0.10625000000000284
Reward: 0.11583333333334167
backprop <src.mcts.MCTS_Node object at 0x7f85361ce550> 0.11583333333334167 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235ba8> 0.18145833333334593 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 0.2877083333333488 4
Completed Iteration #3
Best Reward: 0.11583333333334167
Reward: 0.06666666666666998
backprop <src.mcts.MCTS_Node object at 0x7f85361ce780> 0.06666666666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235ba8> 0.24812500000001592 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 0.35437500000001876 5
Completed Iteration #4
Best Reward: 0.11583333333334167
Completed Iteration #5
Best Reward: 0.11583333333334167
Reward: 0.08145833333333741
backprop <src.mcts.MCTS_Node object at 0x7f85361cec18> 0.08145833333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f85361cec88> 0.08145833333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 0.43583333333335617 6
Completed Iteration #6
Best Reward: 0.11583333333334167
Reward: 0.1060416666666697
backprop <src.mcts.MCTS_Node object at 0x7f85361cefd0> 0.1060416666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235f98> 0.1060416666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 0.5418750000000259 7
Completed Iteration #7
Best Reward: 0.11583333333334167
Reward: 0.11416666666666941
backprop <src.mcts.MCTS_Node object at 0x7f85361ce2b0> 0.11416666666666941 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235f98> 0.2202083333333391 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 0.6560416666666953 8
Completed Iteration #8
Best Reward: 0.11583333333334167
Completed Iteration #9
Best Reward: 0.11583333333334167
Reward: 0.10916666666667396
backprop <src.mcts.MCTS_Node object at 0x7f85361e3400> 0.10916666666667396 2
backprop <src.mcts.MCTS_Node object at 0x7f85361e3470> 0.10916666666667396 2
backprop <src.mcts.MCTS_Node object at 0x7f85361cefd0> 0.21520833333334366 3
backprop <src.mcts.MCTS_Node object at 0x7f8536235f98> 0.3293750000000131 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 0.7652083333333692 9
Completed Iteration #10
Best Reward: 0.11583333333334167
Completed Iteration #11
Best Reward: 0.11583333333334167
Reward: 0.11375000000000313
backprop <src.mcts.MCTS_Node object at 0x7f85361e3b00> 0.11375000000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235ba8> 0.36187500000001904 5
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 0.8789583333333724 10
Completed Iteration #12
Best Reward: 0.11583333333334167
Reward: 0.09083333333333599
backprop <src.mcts.MCTS_Node object at 0x7f85361e3d68> 0.09083333333333599 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235f98> 0.42020833333334906 5
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 0.9697916666667084 11
Completed Iteration #13
Best Reward: 0.11583333333334167
Reward: 0.1112500000000054
backprop <src.mcts.MCTS_Node object at 0x7f85361f1080> 0.1112500000000054 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235ba8> 0.47312500000002444 6
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 1.0810416666667138 12
Completed Iteration #14
Best Reward: 0.11583333333334167
Reward: 0.11166666666667169
backprop <src.mcts.MCTS_Node object at 0x7f85361e3e80> 0.11166666666667169 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235f98> 0.5318750000000207 6
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 1.1927083333333854 13
Completed Iteration #15
Best Reward: 0.11583333333334167
Reward: 0.08229166666666998
backprop <src.mcts.MCTS_Node object at 0x7f85361ce588> 0.08229166666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f85361e3cc0> 0.08229166666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 1.2750000000000554 14
Completed Iteration #16
Best Reward: 0.11583333333334167
Reward: 0.050625000000003695
backprop <src.mcts.MCTS_Node object at 0x7f85361f1550> 0.050625000000003695 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f13c8> 0.050625000000003695 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 1.3256250000000591 15
Completed Iteration #17
Best Reward: 0.11583333333334167
Reward: 0.11270833333333741
backprop <src.mcts.MCTS_Node object at 0x7f85361f1898> 0.11270833333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1518> 0.11270833333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 1.4383333333333965 16
Completed Iteration #18
Best Reward: 0.11583333333334167
Reward: 0.11062500000000597
backprop <src.mcts.MCTS_Node object at 0x7f85361f1b70> 0.11062500000000597 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce278> 0.2168750000000088 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 1.5489583333334025 17
Completed Iteration #19
Best Reward: 0.11583333333334167
Reward: 0.04208333333333769
backprop <src.mcts.MCTS_Node object at 0x7f85361f1e48> 0.04208333333333769 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1518> 0.1547916666666751 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 1.5910416666667402 18
Completed Iteration #20
Best Reward: 0.11583333333334167
Completed Iteration #21
Best Reward: 0.11583333333334167
Reward: 0.08895833333333769
backprop <src.mcts.MCTS_Node object at 0x7f8536235940> 0.08895833333333769 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235f98> 0.6208333333333584 7
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 1.6800000000000779 19
Completed Iteration #22
Best Reward: 0.11583333333334167
Reward: 0.06541666666667112
backprop <src.mcts.MCTS_Node object at 0x7f8536235b70> 0.06541666666667112 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235ba8> 0.5385416666666956 7
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 1.745416666666749 20
Completed Iteration #23
Best Reward: 0.11583333333334167
Reward: 0.06500000000000483
backprop <src.mcts.MCTS_Node object at 0x7f85361ce320> 0.06500000000000483 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235ba8> 0.6035416666667004 8
backprop <src.mcts.MCTS_Node object at 0x7f85b86504e0> 1.8104166666667538 21
Completed Iteration #24
Best Reward: 0.11583333333334167
Completed Iteration #25
Best Reward: 0.11583333333334167
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11583333333334167
No reward increase. Abort.
iteration: 0
found coverage increase 0.11583333333334167
Current Total Coverage 37.901875000000004
Reward: 0.09104166666666202
backprop <src.mcts.MCTS_Node object at 0x7f85361ce4e0> 0.09104166666666202 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce4a8> 0.09104166666666202 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.09104166666666202 2
Completed Iteration #0
Best Reward: 0.09104166666666202
Reward: 0.03229166666666572
backprop <src.mcts.MCTS_Node object at 0x7f85361e3550> 0.03229166666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce240> 0.03229166666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.12333333333332774 3
Completed Iteration #1
Best Reward: 0.09104166666666202
Reward: 0.09041666666666259
backprop <src.mcts.MCTS_Node object at 0x7f85361e3940> 0.09041666666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f85361e34e0> 0.09041666666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.21374999999999034 4
Completed Iteration #2
Best Reward: 0.09104166666666202
Completed Iteration #3
Best Reward: 0.09104166666666202
Reward: 0.037499999999994316
backprop <src.mcts.MCTS_Node object at 0x7f85361e3128> 0.037499999999994316 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce240> 0.06979166666666003 3
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.25124999999998465 5
Completed Iteration #4
Best Reward: 0.09104166666666202
Completed Iteration #5
Best Reward: 0.09104166666666202
Reward: 0.09333333333333371
backprop <src.mcts.MCTS_Node object at 0x7f85361f12e8> 0.09333333333333371 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1710> 0.09333333333333371 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.34458333333331836 6
Completed Iteration #6
Best Reward: 0.09333333333333371
Reward: 0.09458333333332547
backprop <src.mcts.MCTS_Node object at 0x7f85361f1ba8> 0.09458333333332547 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce4a8> 0.1856249999999875 3
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.43916666666664383 7
Completed Iteration #7
Best Reward: 0.09458333333332547
Reward: 0.08749999999999147
backprop <src.mcts.MCTS_Node object at 0x7f85361a6160> 0.08749999999999147 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1d68> 0.08749999999999147 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.5266666666666353 8
Completed Iteration #8
Best Reward: 0.09458333333332547
Completed Iteration #9
Best Reward: 0.09458333333332547
Reward: 0.06812499999999488
backprop <src.mcts.MCTS_Node object at 0x7f85361f10f0> 0.06812499999999488 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6128> 0.06812499999999488 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.5947916666666302 9
Completed Iteration #10
Best Reward: 0.09458333333332547
Reward: 0.0918749999999946
backprop <src.mcts.MCTS_Node object at 0x7f85361a6710> 0.0918749999999946 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6128> 0.15999999999998948 3
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.6866666666666248 10
Completed Iteration #11
Best Reward: 0.09458333333332547
Completed Iteration #12
Best Reward: 0.09458333333332547
Reward: 0.05916666666666259
backprop <src.mcts.MCTS_Node object at 0x7f85361a6ac8> 0.05916666666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1d68> 0.14666666666665407 3
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.7458333333332874 11
Completed Iteration #13
Best Reward: 0.09458333333332547
Reward: 0.07687499999999403
backprop <src.mcts.MCTS_Node object at 0x7f85361a6d30> 0.07687499999999403 2
backprop <src.mcts.MCTS_Node object at 0x7f85361e34e0> 0.16729166666665662 3
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.8227083333332814 12
Completed Iteration #14
Best Reward: 0.09458333333332547
Completed Iteration #15
Best Reward: 0.09458333333332547
Reward: 0.08499999999999375
backprop <src.mcts.MCTS_Node object at 0x7f85361af240> 0.08499999999999375 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af2b0> 0.08499999999999375 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.9077083333332752 13
Completed Iteration #16
Best Reward: 0.09458333333332547
Reward: 0.08916666666665662
backprop <src.mcts.MCTS_Node object at 0x7f85361af5f8> 0.08916666666665662 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce240> 0.15895833333331666 4
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 0.9968749999999318 14
Completed Iteration #17
Best Reward: 0.09458333333332547
Reward: 0.09291666666666032
backprop <src.mcts.MCTS_Node object at 0x7f85361a6fd0> 0.09291666666666032 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce4a8> 0.2785416666666478 4
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 1.089791666666592 15
Completed Iteration #18
Best Reward: 0.09458333333332547
Reward: 0.08083333333333087
backprop <src.mcts.MCTS_Node object at 0x7f85361af780> 0.08083333333333087 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1710> 0.17416666666666458 3
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 1.170624999999923 16
Completed Iteration #19
Best Reward: 0.09458333333332547
Reward: 0.06875000000000142
backprop <src.mcts.MCTS_Node object at 0x7f85361af1d0> 0.06875000000000142 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1d68> 0.2154166666666555 4
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 1.2393749999999244 17
Completed Iteration #20
Best Reward: 0.09458333333332547
Reward: 0.0606249999999946
backprop <src.mcts.MCTS_Node object at 0x7f85361afcc0> 0.0606249999999946 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6128> 0.22062499999998408 4
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 1.299999999999919 18
Completed Iteration #21
Best Reward: 0.09458333333332547
Reward: 0.09624999999999773
backprop <src.mcts.MCTS_Node object at 0x7f85361affd0> 0.09624999999999773 2
backprop <src.mcts.MCTS_Node object at 0x7f85361afc88> 0.09624999999999773 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af240> 0.18124999999999147 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af2b0> 0.18124999999999147 3
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 1.3962499999999167 19
Completed Iteration #22
Best Reward: 0.09624999999999773
Reward: 0.08374999999999488
backprop <src.mcts.MCTS_Node object at 0x7f853a41b390> 0.08374999999999488 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af2b0> 0.26499999999998636 4
backprop <src.mcts.MCTS_Node object at 0x7f85361ce898> 1.4799999999999116 20
Completed Iteration #23
Best Reward: 0.09624999999999773
Completed Iteration #24
Best Reward: 0.09624999999999773
Completed Iteration #25
Best Reward: 0.09624999999999773
Completed MCTS Level/Depth: #0
root
Best Reward: 0.09624999999999773
No reward increase. Abort.
iteration: 1
found coverage increase 0.09624999999999773
Current Total Coverage 37.998125
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.03916666666666657
backprop <src.mcts.MCTS_Node object at 0x7f85d7dd0470> 0.03916666666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f85b819dba8> 0.03916666666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.03916666666666657 2
Completed Iteration #2
Best Reward: 0.03916666666666657
Reward: 0.08916666666666373
backprop <src.mcts.MCTS_Node object at 0x7f85361a6550> 0.08916666666666373 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a61d0> 0.08916666666666373 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.1283333333333303 3
Completed Iteration #3
Best Reward: 0.08916666666666373
Reward: 0.0520833333333357
backprop <src.mcts.MCTS_Node object at 0x7f85361a6e48> 0.0520833333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a65c0> 0.0520833333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.180416666666666 4
Completed Iteration #4
Best Reward: 0.08916666666666373
Reward: 0.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f85361af390> 0.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f85b819dba8> 0.08083333333333087 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.2220833333333303 5
Completed Iteration #5
Best Reward: 0.08916666666666373
Completed Iteration #6
Best Reward: 0.08916666666666373
Completed Iteration #7
Best Reward: 0.08916666666666373
Reward: 0.0989583333333286
backprop <src.mcts.MCTS_Node object at 0x7f85361afbe0> 0.0989583333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a65c0> 0.1510416666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.3210416666666589 6
Completed Iteration #8
Best Reward: 0.0989583333333286
Reward: 0.10520833333333002
backprop <src.mcts.MCTS_Node object at 0x7f85361f1dd8> 0.10520833333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af358> 0.10520833333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.4262499999999889 7
Completed Iteration #9
Best Reward: 0.10520833333333002
Reward: 0.06020833333332831
backprop <src.mcts.MCTS_Node object at 0x7f85361f1f28> 0.06020833333332831 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6b70> 0.06020833333332831 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.4864583333333172 8
Completed Iteration #10
Best Reward: 0.10520833333333002
Completed Iteration #11
Best Reward: 0.10520833333333002
Reward: 0.06312499999999943
backprop <src.mcts.MCTS_Node object at 0x7f85361afdd8> 0.06312499999999943 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f12b0> 0.06312499999999943 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.5495833333333167 9
Completed Iteration #12
Best Reward: 0.10520833333333002
Reward: 0.09083333333332888
backprop <src.mcts.MCTS_Node object at 0x7f85361ce0b8> 0.09083333333332888 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1748> 0.09083333333332888 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.6404166666666455 10
Completed Iteration #13
Best Reward: 0.10520833333333002
Completed Iteration #14
Best Reward: 0.10520833333333002
Completed Iteration #15
Best Reward: 0.10520833333333002
Completed Iteration #16
Best Reward: 0.10520833333333002
Reward: 0.09104166666666913
backprop <src.mcts.MCTS_Node object at 0x7f85361ce550> 0.09104166666666913 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6518> 0.09104166666666913 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.7314583333333147 11
Completed Iteration #17
Best Reward: 0.10520833333333002
Completed Iteration #18
Best Reward: 0.10520833333333002
Reward: 0.09395833333333314
backprop <src.mcts.MCTS_Node object at 0x7f85361e3748> 0.09395833333333314 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af358> 0.19916666666666316 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.8254166666666478 12
Completed Iteration #19
Best Reward: 0.10520833333333002
Reward: 0.09645833333333087
backprop <src.mcts.MCTS_Node object at 0x7f85361e3cf8> 0.09645833333333087 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1748> 0.18729166666665975 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.9218749999999787 13
Completed Iteration #20
Best Reward: 0.10520833333333002
Reward: 0.10395833333333115
backprop <src.mcts.MCTS_Node object at 0x7f85361e3a20> 0.10395833333333115 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af3c8> 0.10395833333333115 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 1.0258333333333098 14
Completed Iteration #21
Best Reward: 0.10520833333333002
Reward: 0.09124999999999517
backprop <src.mcts.MCTS_Node object at 0x7f85361a6f28> 0.09124999999999517 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af3c8> 0.19520833333332632 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 1.117083333333305 15
Completed Iteration #22
Best Reward: 0.10520833333333002
Reward: 0.05520833333333286
backprop <src.mcts.MCTS_Node object at 0x7f8536235a90> 0.05520833333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a65c0> 0.20624999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 1.1722916666666379 16
Completed Iteration #23
Best Reward: 0.10520833333333002
Completed Iteration #24
Best Reward: 0.10520833333333002
Reward: 0.0435416666666697
backprop <src.mcts.MCTS_Node object at 0x7f853a41b160> 0.0435416666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f85b819dba8> 0.12437500000000057 4
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 1.2158333333333076 17
Completed Iteration #25
Best Reward: 0.10520833333333002
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10520833333333002
No reward increase. Abort.
iteration: 2
found coverage increase 0.10520833333333002
Current Total Coverage 38.10333333333333
Reward: 0.06937500000000085
backprop <src.mcts.MCTS_Node object at 0x7f8536235eb8> 0.06937500000000085 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bb70> 0.06937500000000085 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 0.06937500000000085 2
Completed Iteration #0
Best Reward: 0.06937500000000085
Reward: 0.08729166666666544
backprop <src.mcts.MCTS_Node object at 0x7f853a41b128> 0.08729166666666544 2
backprop <src.mcts.MCTS_Node object at 0x7f85361e36d8> 0.08729166666666544 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 0.1566666666666663 3
Completed Iteration #1
Best Reward: 0.08729166666666544
Completed Iteration #2
Best Reward: 0.08729166666666544
Reward: 0.07833333333334025
backprop <src.mcts.MCTS_Node object at 0x7f853a41bd30> 0.07833333333334025 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41be80> 0.07833333333334025 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 0.23500000000000654 4
Completed Iteration #3
Best Reward: 0.08729166666666544
Reward: 0.1056249999999963
backprop <src.mcts.MCTS_Node object at 0x7f853a3da278> 0.1056249999999963 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da0f0> 0.1056249999999963 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 0.34062500000000284 5
Completed Iteration #4
Best Reward: 0.1056249999999963
Reward: 0.0643749999999983
backprop <src.mcts.MCTS_Node object at 0x7f853a3da550> 0.0643749999999983 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bb70> 0.13374999999999915 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 0.40500000000000114 6
Completed Iteration #5
Best Reward: 0.1056249999999963
Reward: 0.0989583333333357
backprop <src.mcts.MCTS_Node object at 0x7f853a41bda0> 0.0989583333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da518> 0.0989583333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 0.5039583333333368 7
Completed Iteration #6
Best Reward: 0.1056249999999963
Reward: 0.10020833333333456
backprop <src.mcts.MCTS_Node object at 0x7f853a3da4a8> 0.10020833333333456 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bb70> 0.2339583333333337 4
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 0.6041666666666714 8
Completed Iteration #7
Best Reward: 0.1056249999999963
Reward: 0.05479166666666657
backprop <src.mcts.MCTS_Node object at 0x7f853a3daba8> 0.05479166666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da0f0> 0.16041666666666288 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 0.658958333333338 9
Completed Iteration #8
Best Reward: 0.1056249999999963
Completed Iteration #9
Best Reward: 0.1056249999999963
Reward: 0.08708333333333229
backprop <src.mcts.MCTS_Node object at 0x7f85361aff60> 0.08708333333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da518> 0.186041666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 0.7460416666666703 10
Completed Iteration #10
Best Reward: 0.1056249999999963
Reward: 0.10312499999999858
backprop <src.mcts.MCTS_Node object at 0x7f85361e3828> 0.10312499999999858 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da0f0> 0.26354166666666146 4
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 0.8491666666666688 11
Completed Iteration #11
Best Reward: 0.1056249999999963
Completed Iteration #12
Best Reward: 0.1056249999999963
Completed Iteration #13
Best Reward: 0.1056249999999963
Reward: 0.1027083333333394
backprop <src.mcts.MCTS_Node object at 0x7f85361af7b8> 0.1027083333333394 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6b38> 0.1027083333333394 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 0.9518750000000082 12
Completed Iteration #14
Best Reward: 0.1056249999999963
Reward: 0.10020833333333456
backprop <src.mcts.MCTS_Node object at 0x7f85361f1c18> 0.10020833333333456 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da0f0> 0.363749999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 1.0520833333333428 13
Completed Iteration #15
Best Reward: 0.1056249999999963
Reward: 0.09125000000000227
backprop <src.mcts.MCTS_Node object at 0x7f85361f14a8> 0.09125000000000227 2
backprop <src.mcts.MCTS_Node object at 0x7f85361e36d8> 0.1785416666666677 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 1.143333333333345 14
Completed Iteration #16
Best Reward: 0.1056249999999963
coverage_call_count 100
Completed Iteration #17
Best Reward: 0.1056249999999963
Completed Iteration #18
Best Reward: 0.1056249999999963
Reward: 0.09812500000000313
backprop <src.mcts.MCTS_Node object at 0x7f85361ce908> 0.09812500000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce160> 0.09812500000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 1.2414583333333482 15
Completed Iteration #19
Best Reward: 0.1056249999999963
Reward: 0.05124999999999602
backprop <src.mcts.MCTS_Node object at 0x7f853a41b278> 0.05124999999999602 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da0f0> 0.41499999999999204 6
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 1.2927083333333442 16
Completed Iteration #20
Best Reward: 0.1056249999999963
Reward: 0.08687499999999915
backprop <src.mcts.MCTS_Node object at 0x7f853a41bd68> 0.08687499999999915 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da518> 0.27291666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 1.3795833333333434 17
Completed Iteration #21
Best Reward: 0.1056249999999963
Reward: 0.07249999999999801
backprop <src.mcts.MCTS_Node object at 0x7f8536235940> 0.07249999999999801 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41be80> 0.15083333333333826 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 1.4520833333333414 18
Completed Iteration #22
Best Reward: 0.1056249999999963
Reward: 0.10104166666666714
backprop <src.mcts.MCTS_Node object at 0x7f85361e3ef0> 0.10104166666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6b38> 0.20375000000000654 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 1.5531250000000085 19
Completed Iteration #23
Best Reward: 0.1056249999999963
Reward: 0.05416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f853a3da748> 0.05416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da0f0> 0.4691666666666592 7
backprop <src.mcts.MCTS_Node object at 0x7f853a41b438> 1.6072916666666757 20
Completed Iteration #24
Best Reward: 0.1056249999999963
Completed Iteration #25
Best Reward: 0.1056249999999963
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1056249999999963
No reward increase. Abort.
iteration: 3
found coverage increase 0.1056249999999963
Current Total Coverage 38.20895833333333
Reward: 0.05041666666667055
backprop <src.mcts.MCTS_Node object at 0x7f853a3dabe0> 0.05041666666667055 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dae80> 0.05041666666667055 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 0.05041666666667055 2
Completed Iteration #0
Best Reward: 0.05041666666667055
Reward: 0.09708333333333741
backprop <src.mcts.MCTS_Node object at 0x7f853a406080> 0.09708333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da400> 0.09708333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 0.14750000000000796 3
Completed Iteration #1
Best Reward: 0.09708333333333741
Reward: 0.07458333333333655
backprop <src.mcts.MCTS_Node object at 0x7f853a4060f0> 0.07458333333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406048> 0.07458333333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 0.2220833333333445 4
Completed Iteration #2
Best Reward: 0.09708333333333741
Reward: 0.09250000000000114
backprop <src.mcts.MCTS_Node object at 0x7f853a4066d8> 0.09250000000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da400> 0.18958333333333854 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 0.31458333333334565 5
Completed Iteration #3
Best Reward: 0.09708333333333741
Completed Iteration #4
Best Reward: 0.09708333333333741
Reward: 0.09729166666667055
backprop <src.mcts.MCTS_Node object at 0x7f853a406b38> 0.09729166666667055 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406ba8> 0.09729166666667055 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 0.4118750000000162 6
Completed Iteration #5
Best Reward: 0.09729166666667055
Reward: 0.09604166666667169
backprop <src.mcts.MCTS_Node object at 0x7f853a406f28> 0.09604166666667169 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406a58> 0.09604166666667169 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 0.5079166666666879 7
Completed Iteration #6
Best Reward: 0.09729166666667055
Completed Iteration #7
Best Reward: 0.09729166666667055
Reward: 0.071041666666666
backprop <src.mcts.MCTS_Node object at 0x7f853a39a470> 0.071041666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f853a39a4e0> 0.071041666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 0.5789583333333539 8
Completed Iteration #8
Best Reward: 0.09729166666667055
Reward: 0.09666666666667112
backprop <src.mcts.MCTS_Node object at 0x7f853a4069e8> 0.09666666666667112 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da400> 0.28625000000000966 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 0.675625000000025 9
Completed Iteration #9
Best Reward: 0.09729166666667055
Reward: 0.04916666666667169
backprop <src.mcts.MCTS_Node object at 0x7f853a3da438> 0.04916666666667169 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406ba8> 0.14645833333334224 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 0.7247916666666967 10
Completed Iteration #10
Best Reward: 0.09729166666667055
Reward: 0.10541666666667027
backprop <src.mcts.MCTS_Node object at 0x7f853a3da780> 0.10541666666667027 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406048> 0.18000000000000682 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 0.830208333333367 11
Completed Iteration #11
Best Reward: 0.10541666666667027
Completed Iteration #12
Best Reward: 0.10541666666667027
Completed Iteration #13
Best Reward: 0.10541666666667027
Reward: 0.09354166666667396
backprop <src.mcts.MCTS_Node object at 0x7f853a41bbe0> 0.09354166666667396 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3daba8> 0.09354166666667396 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 0.9237500000000409 12
Completed Iteration #14
Best Reward: 0.10541666666667027
Reward: 0.08958333333334423
backprop <src.mcts.MCTS_Node object at 0x7f85361a6358> 0.08958333333334423 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da400> 0.3758333333333539 5
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 1.0133333333333852 13
Completed Iteration #15
Best Reward: 0.10541666666667027
Reward: 0.05250000000000199
backprop <src.mcts.MCTS_Node object at 0x7f85361a6ef0> 0.05250000000000199 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406ba8> 0.19895833333334423 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 1.0658333333333871 14
Completed Iteration #16
Best Reward: 0.10541666666667027
Reward: 0.053125000000008527
backprop <src.mcts.MCTS_Node object at 0x7f85361a6908> 0.053125000000008527 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dae80> 0.10354166666667908 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 1.1189583333333957 15
Completed Iteration #17
Best Reward: 0.10541666666667027
Reward: 0.057916666666670835
backprop <src.mcts.MCTS_Node object at 0x7f853a41b5c0> 0.057916666666670835 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6780> 0.057916666666670835 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 1.1768750000000665 16
Completed Iteration #18
Best Reward: 0.10541666666667027
Reward: 0.03145833333334025
backprop <src.mcts.MCTS_Node object at 0x7f853a41b470> 0.03145833333334025 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406a58> 0.12750000000001194 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 1.2083333333334068 17
Completed Iteration #19
Best Reward: 0.10541666666667027
Completed Iteration #20
Best Reward: 0.10541666666667027
Reward: 0.09979166666667538
backprop <src.mcts.MCTS_Node object at 0x7f8536235f60> 0.09979166666667538 2
backprop <src.mcts.MCTS_Node object at 0x7f853a39a4e0> 0.1708333333333414 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 1.3081250000000821 18
Completed Iteration #21
Best Reward: 0.10541666666667027
Completed Iteration #22
Best Reward: 0.10541666666667027
Completed Iteration #23
Best Reward: 0.10541666666667027
Reward: 0.08958333333334423
backprop <src.mcts.MCTS_Node object at 0x7f853a41beb8> 0.08958333333334423 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b4a8> 0.08958333333334423 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 1.3977083333334264 19
Completed Iteration #24
Best Reward: 0.10541666666667027
Completed Iteration #25
Best Reward: 0.10541666666667027
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10541666666667027
No reward increase. Abort.
iteration: 4
found coverage increase 0.10541666666667027
Current Total Coverage 38.314375
Reward: 0.09166666666666856
backprop <src.mcts.MCTS_Node object at 0x7f853a3da7f0> 0.09166666666666856 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.09166666666666856 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.09166666666666856 2
Completed Iteration #0
Best Reward: 0.09166666666666856
Reward: 0.04625000000000057
backprop <src.mcts.MCTS_Node object at 0x7f853a406898> 0.04625000000000057 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406160> 0.04625000000000057 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.13791666666666913 3
Completed Iteration #1
Best Reward: 0.09166666666666856
Reward: 0.03250000000000597
backprop <src.mcts.MCTS_Node object at 0x7f853a406c50> 0.03250000000000597 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406240> 0.03250000000000597 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.1704166666666751 4
Completed Iteration #2
Best Reward: 0.09166666666666856
Reward: 0.048541666666672256
backprop <src.mcts.MCTS_Node object at 0x7f853a406630> 0.048541666666672256 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406160> 0.09479166666667282 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.21895833333334735 5
Completed Iteration #3
Best Reward: 0.09166666666666856
Reward: 0.08874999999999744
backprop <src.mcts.MCTS_Node object at 0x7f853a406438> 0.08874999999999744 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce908> 0.08874999999999744 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.3077083333333448 6
Completed Iteration #4
Best Reward: 0.09166666666666856
Reward: 0.06208333333333371
backprop <src.mcts.MCTS_Node object at 0x7f85361ce780> 0.06208333333333371 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce710> 0.06208333333333371 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.3697916666666785 7
Completed Iteration #5
Best Reward: 0.09166666666666856
Completed Iteration #6
Best Reward: 0.09166666666666856
Reward: 0.05270833333333513
backprop <src.mcts.MCTS_Node object at 0x7f85361f1470> 0.05270833333333513 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f13c8> 0.05270833333333513 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.42250000000001364 8
Completed Iteration #7
Best Reward: 0.09166666666666856
Reward: 0.08750000000000568
backprop <src.mcts.MCTS_Node object at 0x7f85361e3278> 0.08750000000000568 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406160> 0.1822916666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.5100000000000193 9
Completed Iteration #8
Best Reward: 0.09166666666666856
Completed Iteration #9
Best Reward: 0.09166666666666856
Completed Iteration #10
Best Reward: 0.09166666666666856
Reward: 0.09333333333333371
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.09333333333333371 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.18500000000000227 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.603333333333353 10
Completed Iteration #11
Best Reward: 0.09333333333333371
Reward: 0.05000000000000426
backprop <src.mcts.MCTS_Node object at 0x7f85361e37b8> 0.05000000000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f13c8> 0.1027083333333394 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.6533333333333573 11
Completed Iteration #12
Best Reward: 0.09333333333333371
Completed Iteration #13
Best Reward: 0.09333333333333371
Reward: 0.09458333333333258
backprop <src.mcts.MCTS_Node object at 0x7f85361af6a0> 0.09458333333333258 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce908> 0.18333333333333002 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.7479166666666899 12
Completed Iteration #14
Best Reward: 0.09458333333333258
Reward: 0.051666666666669414
backprop <src.mcts.MCTS_Node object at 0x7f853a39a2e8> 0.051666666666669414 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406160> 0.23395833333334792 5
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.7995833333333593 13
Completed Iteration #15
Best Reward: 0.09458333333333258
Reward: 0.10875000000000057
backprop <src.mcts.MCTS_Node object at 0x7f853a39a898> 0.10875000000000057 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406240> 0.14125000000000654 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 0.9083333333333599 14
Completed Iteration #16
Best Reward: 0.10875000000000057
Reward: 0.09875000000000256
backprop <src.mcts.MCTS_Node object at 0x7f853a39aa90> 0.09875000000000256 2
backprop <src.mcts.MCTS_Node object at 0x7f853a39a860> 0.09875000000000256 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da7f0> 0.19041666666667112 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.28375000000000483 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 1.0070833333333624 15
Completed Iteration #17
Best Reward: 0.10875000000000057
Completed Iteration #18
Best Reward: 0.10875000000000057
Reward: 0.04916666666667169
backprop <src.mcts.MCTS_Node object at 0x7f85361af8d0> 0.04916666666667169 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406160> 0.2831250000000196 6
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 1.056250000000034 16
Completed Iteration #19
Best Reward: 0.10875000000000057
Reward: 0.10187500000000682
backprop <src.mcts.MCTS_Node object at 0x7f853a39a828> 0.10187500000000682 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce908> 0.28520833333333684 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 1.158125000000041 17
Completed Iteration #20
Best Reward: 0.10875000000000057
Reward: 0.09250000000000114
backprop <src.mcts.MCTS_Node object at 0x7f853a3d31d0> 0.09250000000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce908> 0.377708333333338 5
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 1.250625000000042 18
Completed Iteration #21
Best Reward: 0.10875000000000057
Completed Iteration #22
Best Reward: 0.10875000000000057
Completed Iteration #23
Best Reward: 0.10875000000000057
Reward: 0.09916666666666885
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3828> 0.09916666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3898> 0.09916666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 1.349791666666711 19
Completed Iteration #24
Best Reward: 0.10875000000000057
Reward: 0.035000000000003695
backprop <src.mcts.MCTS_Node object at 0x7f853a3dab70> 0.035000000000003695 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406240> 0.17625000000001023 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3da630> 1.3847916666667146 20
Completed Iteration #25
Best Reward: 0.10875000000000057
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10875000000000057
No reward increase. Abort.
iteration: 5
found coverage increase 0.10875000000000057
Current Total Coverage 38.423125
Reward: 0.09145833333333542
backprop <src.mcts.MCTS_Node object at 0x7f8536235a20> 0.09145833333333542 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6a20> 0.09145833333333542 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.09145833333333542 2
Completed Iteration #0
Best Reward: 0.09145833333333542
Reward: 0.02854166666666913
backprop <src.mcts.MCTS_Node object at 0x7f853a41b908> 0.02854166666666913 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bcc0> 0.02854166666666913 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.12000000000000455 3
Completed Iteration #1
Best Reward: 0.09145833333333542
Completed Iteration #2
Best Reward: 0.09145833333333542
Completed Iteration #3
Best Reward: 0.09145833333333542
Reward: 0.09770833333332973
backprop <src.mcts.MCTS_Node object at 0x7f85361e3908> 0.09770833333332973 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406358> 0.09770833333332973 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.21770833333333428 4
Completed Iteration #4
Best Reward: 0.09770833333332973
Reward: 0.10000000000000142
backprop <src.mcts.MCTS_Node object at 0x7f85361ce2e8> 0.10000000000000142 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce438> 0.10000000000000142 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.3177083333333357 5
Completed Iteration #5
Best Reward: 0.10000000000000142
Reward: 0.042499999999996874
backprop <src.mcts.MCTS_Node object at 0x7f853a41ba20> 0.042499999999996874 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406c88> 0.042499999999996874 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.3602083333333326 6
Completed Iteration #6
Best Reward: 0.10000000000000142
Reward: 0.09104166666666913
backprop <src.mcts.MCTS_Node object at 0x7f85361afbe0> 0.09104166666666913 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7b8> 0.09104166666666913 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.4512500000000017 7
Completed Iteration #7
Best Reward: 0.10000000000000142
Reward: 0.09833333333333627
backprop <src.mcts.MCTS_Node object at 0x7f853a39ae10> 0.09833333333333627 2
backprop <src.mcts.MCTS_Node object at 0x7f853a4067b8> 0.09833333333333627 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.549583333333338 8
Completed Iteration #8
Best Reward: 0.10000000000000142
Reward: 0.09812500000000313
backprop <src.mcts.MCTS_Node object at 0x7f853a39a908> 0.09812500000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bcc0> 0.12666666666667226 3
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.6477083333333411 9
Completed Iteration #9
Best Reward: 0.10000000000000142
Completed Iteration #10
Best Reward: 0.10000000000000142
Reward: 0.11708333333333343
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3400> 0.11708333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f853a39a940> 0.11708333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.7647916666666745 10
Completed Iteration #11
Best Reward: 0.11708333333333343
Completed Iteration #12
Best Reward: 0.11708333333333343
Reward: 0.10187499999999972
backprop <src.mcts.MCTS_Node object at 0x7f853a39a128> 0.10187499999999972 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406c88> 0.1443749999999966 3
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.8666666666666742 11
Completed Iteration #13
Best Reward: 0.11708333333333343
Completed Iteration #14
Best Reward: 0.11708333333333343
Reward: 0.03229166666666572
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3cc0> 0.03229166666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bcc0> 0.15895833333333798 4
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.89895833333334 12
Completed Iteration #15
Best Reward: 0.11708333333333343
Reward: 0.10354166666666487
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3f98> 0.10354166666666487 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce438> 0.2035416666666663 3
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 1.0025000000000048 13
Completed Iteration #16
Best Reward: 0.11708333333333343
Completed Iteration #17
Best Reward: 0.11708333333333343
Reward: 0.05312500000000142
backprop <src.mcts.MCTS_Node object at 0x7f853a3874a8> 0.05312500000000142 2
backprop <src.mcts.MCTS_Node object at 0x7f853a39a940> 0.17020833333333485 3
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 1.0556250000000063 14
Completed Iteration #18
Best Reward: 0.11708333333333343
Reward: 0.09312500000000057
backprop <src.mcts.MCTS_Node object at 0x7f853a387710> 0.09312500000000057 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406358> 0.1908333333333303 3
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 1.1487500000000068 15
Completed Iteration #19
Best Reward: 0.11708333333333343
Reward: 0.09916666666666885
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3c88> 0.09916666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3876d8> 0.09916666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce2e8> 0.19916666666667027 3
backprop <src.mcts.MCTS_Node object at 0x7f85361ce438> 0.30270833333333513 4
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 1.2479166666666757 16
Completed Iteration #20
Best Reward: 0.11708333333333343
Completed Iteration #21
Best Reward: 0.11708333333333343
Completed Iteration #22
Best Reward: 0.11708333333333343
Reward: 0.08708333333333229
backprop <src.mcts.MCTS_Node object at 0x7f853a387d68> 0.08708333333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406358> 0.2779166666666626 4
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 1.335000000000008 17
Completed Iteration #23
Best Reward: 0.11708333333333343
Reward: 0.09770833333332973
backprop <src.mcts.MCTS_Node object at 0x7f853a387fd0> 0.09770833333332973 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6a20> 0.18916666666666515 3
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 1.4327083333333377 18
Completed Iteration #24
Best Reward: 0.11708333333333343
Reward: 0.051250000000003126
backprop <src.mcts.MCTS_Node object at 0x7f853a3202e8> 0.051250000000003126 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406c88> 0.19562499999999972 4
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 1.4839583333333408 19
Completed Iteration #25
Best Reward: 0.11708333333333343
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11708333333333343
No reward increase. Abort.
iteration: 6
found coverage increase 0.11708333333333343
Current Total Coverage 38.54020833333333
Reward: 0.08833333333333115
backprop <src.mcts.MCTS_Node object at 0x7f853a387da0> 0.08833333333333115 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320668> 0.08833333333333115 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 0.08833333333333115 2
Completed Iteration #0
Best Reward: 0.08833333333333115
Reward: 0.0904166666666697
backprop <src.mcts.MCTS_Node object at 0x7f853a3872b0> 0.0904166666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3877b8> 0.0904166666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 0.17875000000000085 3
Completed Iteration #1
Best Reward: 0.0904166666666697
Reward: 0.09062499999999574
backprop <src.mcts.MCTS_Node object at 0x7f85361ce438> 0.09062499999999574 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3874a8> 0.09062499999999574 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 0.2693749999999966 4
Completed Iteration #2
Best Reward: 0.09062499999999574
Completed Iteration #3
Best Reward: 0.09062499999999574
Completed Iteration #4
Best Reward: 0.09062499999999574
Reward: 0.09541666666667226
backprop <src.mcts.MCTS_Node object at 0x7f85b819dd30> 0.09541666666667226 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406dd8> 0.09541666666667226 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 0.36479166666666885 5
Completed Iteration #5
Best Reward: 0.09541666666667226
Reward: 0.031458333333333144
backprop <src.mcts.MCTS_Node object at 0x7f853a387630> 0.031458333333333144 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406dd8> 0.1268750000000054 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 0.396250000000002 6
Completed Iteration #6
Best Reward: 0.09541666666667226
Completed Iteration #7
Best Reward: 0.09541666666667226
Reward: 0.09687500000000426
backprop <src.mcts.MCTS_Node object at 0x7f853a387e80> 0.09687500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406dd8> 0.22375000000000966 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 0.49312500000000625 7
Completed Iteration #8
Best Reward: 0.09687500000000426
coverage_call_count 200
Reward: 0.10312500000000568
backprop <src.mcts.MCTS_Node object at 0x7f853a3871d0> 0.10312500000000568 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3874a8> 0.19375000000000142 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 0.5962500000000119 8
Completed Iteration #9
Best Reward: 0.10312500000000568
Reward: 0.09020833333333655
backprop <src.mcts.MCTS_Node object at 0x7f853a41b908> 0.09020833333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.09020833333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 0.6864583333333485 9
Completed Iteration #10
Best Reward: 0.10312500000000568
Reward: 0.08770833333333172
backprop <src.mcts.MCTS_Node object at 0x7f85361ce908> 0.08770833333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.17791666666666828 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 0.7741666666666802 10
Completed Iteration #11
Best Reward: 0.10312500000000568
Reward: 0.08541666666666714
backprop <src.mcts.MCTS_Node object at 0x7f853a406240> 0.08541666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406470> 0.08541666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 0.8595833333333474 11
Completed Iteration #12
Best Reward: 0.10312500000000568
Reward: 0.057708333333330586
backprop <src.mcts.MCTS_Node object at 0x7f85361ce710> 0.057708333333330586 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3874a8> 0.251458333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 0.9172916666666779 12
Completed Iteration #13
Best Reward: 0.10312500000000568
Reward: 0.09416666666666629
backprop <src.mcts.MCTS_Node object at 0x7f853a3872e8> 0.09416666666666629 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.27208333333333456 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 1.0114583333333442 13
Completed Iteration #14
Best Reward: 0.10312500000000568
Completed Iteration #15
Best Reward: 0.10312500000000568
Reward: 0.08770833333333172
backprop <src.mcts.MCTS_Node object at 0x7f853a39ae10> 0.08770833333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3877b8> 0.17812500000000142 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 1.099166666666676 14
Completed Iteration #16
Best Reward: 0.10312500000000568
Reward: 0.09708333333333741
backprop <src.mcts.MCTS_Node object at 0x7f853a39a2e8> 0.09708333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f853a39a940> 0.09708333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 1.1962500000000134 15
Completed Iteration #17
Best Reward: 0.10312500000000568
Reward: 0.06624999999999659
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3c18> 0.06624999999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3128> 0.06624999999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 1.26250000000001 16
Completed Iteration #18
Best Reward: 0.10312500000000568
Reward: 0.09062499999999574
backprop <src.mcts.MCTS_Node object at 0x7f853a3d39b0> 0.09062499999999574 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3877b8> 0.26874999999999716 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 1.3531250000000057 17
Completed Iteration #19
Best Reward: 0.10312500000000568
Reward: 0.0956250000000054
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3668> 0.0956250000000054 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.36770833333333997 5
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 1.448750000000011 18
Completed Iteration #20
Best Reward: 0.10312500000000568
Reward: 0.0625
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3cc0> 0.0625 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3874a8> 0.313958333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 1.511250000000011 19
Completed Iteration #21
Best Reward: 0.10312500000000568
Reward: 0.08958333333333712
backprop <src.mcts.MCTS_Node object at 0x7f853a3d32e8> 0.08958333333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f853a39a940> 0.18666666666667453 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 1.6008333333333482 20
Completed Iteration #22
Best Reward: 0.10312500000000568
Completed Iteration #23
Best Reward: 0.10312500000000568
Reward: 0.02729166666666316
backprop <src.mcts.MCTS_Node object at 0x7f85361e3208> 0.02729166666666316 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406dd8> 0.2510416666666728 5
backprop <src.mcts.MCTS_Node object at 0x7f853a3207f0> 1.6281250000000114 21
Completed Iteration #24
Best Reward: 0.10312500000000568
Completed Iteration #25
Best Reward: 0.10312500000000568
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10312500000000568
No reward increase. Abort.
iteration: 7
found coverage increase 0.10312500000000568
Current Total Coverage 38.64333333333334
Reward: 0.10583333333332945
backprop <src.mcts.MCTS_Node object at 0x7f85361af6a0> 0.10583333333332945 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af6d8> 0.10583333333332945 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.10583333333332945 2
Completed Iteration #0
Best Reward: 0.10583333333332945
Reward: 0.03416666666665691
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3b70> 0.03416666666665691 2
backprop <src.mcts.MCTS_Node object at 0x7f85361e3198> 0.03416666666665691 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.13999999999998636 3
Completed Iteration #1
Best Reward: 0.10583333333332945
Reward: 0.07916666666665861
backprop <src.mcts.MCTS_Node object at 0x7f85361f1748> 0.07916666666665861 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1550> 0.07916666666665861 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.21916666666664497 4
Completed Iteration #2
Best Reward: 0.10583333333332945
Reward: 0.07229166666665776
backprop <src.mcts.MCTS_Node object at 0x7f853a3da7f0> 0.07229166666665776 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dab38> 0.07229166666665776 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.29145833333330273 5
Completed Iteration #3
Best Reward: 0.10583333333332945
Reward: 0.10833333333332718
backprop <src.mcts.MCTS_Node object at 0x7f85361a6400> 0.10833333333332718 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6630> 0.10833333333332718 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.3997916666666299 6
Completed Iteration #4
Best Reward: 0.10833333333332718
Completed Iteration #5
Best Reward: 0.10833333333332718
Reward: 0.1231249999999946
backprop <src.mcts.MCTS_Node object at 0x7f85361e3e80> 0.1231249999999946 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320828> 0.1231249999999946 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.5229166666666245 7
Completed Iteration #6
Best Reward: 0.1231249999999946
Reward: 0.10291666666665833
backprop <src.mcts.MCTS_Node object at 0x7f853a320780> 0.10291666666665833 2
backprop <src.mcts.MCTS_Node object at 0x7f853a39aef0> 0.10291666666665833 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.6258333333332828 8
Completed Iteration #7
Best Reward: 0.1231249999999946
Reward: 0.10604166666666259
backprop <src.mcts.MCTS_Node object at 0x7f853a320940> 0.10604166666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1550> 0.1852083333333212 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.7318749999999454 9
Completed Iteration #8
Best Reward: 0.1231249999999946
Completed Iteration #9
Best Reward: 0.1231249999999946
Reward: 0.07416666666666316
backprop <src.mcts.MCTS_Node object at 0x7f853a41ba20> 0.07416666666666316 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dab38> 0.14645833333332092 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.8060416666666086 10
Completed Iteration #10
Best Reward: 0.1231249999999946
Reward: 0.11312499999999659
backprop <src.mcts.MCTS_Node object at 0x7f85d7dd0780> 0.11312499999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406710> 0.11312499999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.9191666666666052 11
Completed Iteration #11
Best Reward: 0.1231249999999946
Reward: 0.11083333333333201
backprop <src.mcts.MCTS_Node object at 0x7f85361afd30> 0.11083333333333201 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1550> 0.2960416666666532 4
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.0299999999999372 12
Completed Iteration #12
Best Reward: 0.1231249999999946
Reward: 0.10999999999999943
backprop <src.mcts.MCTS_Node object at 0x7f853a406198> 0.10999999999999943 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dab38> 0.25645833333332035 4
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.1399999999999366 13
Completed Iteration #13
Best Reward: 0.1231249999999946
Reward: 0.06666666666666288
backprop <src.mcts.MCTS_Node object at 0x7f853a387d68> 0.06666666666666288 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320828> 0.18979166666665748 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.2066666666665995 14
Completed Iteration #14
Best Reward: 0.1231249999999946
Reward: 0.06270833333333314
backprop <src.mcts.MCTS_Node object at 0x7f853a387a20> 0.06270833333333314 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406710> 0.17583333333332973 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.2693749999999326 15
Completed Iteration #15
Best Reward: 0.1231249999999946
Completed Iteration #16
Best Reward: 0.1231249999999946
Completed Iteration #17
Best Reward: 0.1231249999999946
Reward: 0.1089583333333266
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3a20> 0.1089583333333266 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406710> 0.28479166666665634 4
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.3783333333332592 16
Completed Iteration #18
Best Reward: 0.1231249999999946
Reward: 0.1089583333333266
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3358> 0.1089583333333266 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af6d8> 0.21479166666665606 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.4872916666665859 17
Completed Iteration #19
Best Reward: 0.1231249999999946
Reward: 0.11583333333332746
backprop <src.mcts.MCTS_Node object at 0x7f85361f1be0> 0.11583333333332746 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a61d0> 0.11583333333332746 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41ba20> 0.18999999999999062 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3dab38> 0.3722916666666478 5
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.6031249999999133 18
Completed Iteration #20
Best Reward: 0.1231249999999946
Completed Iteration #21
Best Reward: 0.1231249999999946
Reward: 0.03499999999999659
backprop <src.mcts.MCTS_Node object at 0x7f853a41b3c8> 0.03499999999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f85361e3198> 0.0691666666666535 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.63812499999991 19
Completed Iteration #22
Best Reward: 0.1231249999999946
Completed Iteration #23
Best Reward: 0.1231249999999946
Reward: 0.11874999999999858
backprop <src.mcts.MCTS_Node object at 0x7f853a3202b0> 0.11874999999999858 2
backprop <src.mcts.MCTS_Node object at 0x7f85361e3198> 0.18791666666665208 4
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.7568749999999085 20
Completed Iteration #24
Best Reward: 0.1231249999999946
Reward: 0.10187499999999261
backprop <src.mcts.MCTS_Node object at 0x7f853a320c50> 0.10187499999999261 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6630> 0.21020833333331979 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.858749999999901 21
Completed Iteration #25
Best Reward: 0.1231249999999946
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1231249999999946
No reward increase. Abort.
iteration: 8
found coverage increase 0.1231249999999946
Current Total Coverage 38.76645833333333
Reward: 0.06125000000000114
backprop <src.mcts.MCTS_Node object at 0x7f853a320d68> 0.06125000000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320f98> 0.06125000000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 0.06125000000000114 2
Completed Iteration #0
Best Reward: 0.06125000000000114
Reward: 0.10104166666666714
backprop <src.mcts.MCTS_Node object at 0x7f853a3d36d8> 0.10104166666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce278> 0.10104166666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 0.16229166666666828 3
Completed Iteration #1
Best Reward: 0.10104166666666714
Reward: 0.09687499999999716
backprop <src.mcts.MCTS_Node object at 0x7f853a2f7470> 0.09687499999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2f7048> 0.09687499999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 0.25916666666666544 4
Completed Iteration #2
Best Reward: 0.10104166666666714
Completed Iteration #3
Best Reward: 0.10104166666666714
Reward: 0.11416666666666941
backprop <src.mcts.MCTS_Node object at 0x7f853a2f78d0> 0.11416666666666941 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2f7940> 0.11416666666666941 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3d36d8> 0.21520833333333655 3
backprop <src.mcts.MCTS_Node object at 0x7f85361ce278> 0.21520833333333655 3
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 0.37333333333333485 5
Completed Iteration #4
Best Reward: 0.11416666666666941
Reward: 0.09812500000000313
backprop <src.mcts.MCTS_Node object at 0x7f853a2f7cf8> 0.09812500000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2f7240> 0.09812500000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 0.471458333333338 6
Completed Iteration #5
Best Reward: 0.11416666666666941
Completed Iteration #6
Best Reward: 0.11416666666666941
Reward: 0.10104166666666714
backprop <src.mcts.MCTS_Node object at 0x7f853a2f7320> 0.10104166666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320f98> 0.16229166666666828 3
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 0.5725000000000051 7
Completed Iteration #7
Best Reward: 0.11416666666666941
Completed Iteration #8
Best Reward: 0.11416666666666941
Reward: 0.046875
backprop <src.mcts.MCTS_Node object at 0x7f853a3daa58> 0.046875 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da7f0> 0.046875 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 0.6193750000000051 8
Completed Iteration #9
Best Reward: 0.11416666666666941
Reward: 0.06270833333333314
backprop <src.mcts.MCTS_Node object at 0x7f853a41b940> 0.06270833333333314 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f1550> 0.06270833333333314 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 0.6820833333333383 9
Completed Iteration #10
Best Reward: 0.11416666666666941
Completed Iteration #11
Best Reward: 0.11416666666666941
Completed Iteration #12
Best Reward: 0.11416666666666941
Completed Iteration #13
Best Reward: 0.11416666666666941
Reward: 0.07124999999999915
backprop <src.mcts.MCTS_Node object at 0x7f853a406438> 0.07124999999999915 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320f98> 0.23354166666666742 4
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 0.7533333333333374 10
Completed Iteration #14
Best Reward: 0.11416666666666941
Reward: 0.102291666666666
backprop <src.mcts.MCTS_Node object at 0x7f85361a6630> 0.102291666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da7f0> 0.149166666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 0.8556250000000034 11
Completed Iteration #15
Best Reward: 0.11416666666666941
Reward: 0.06416666666667226
backprop <src.mcts.MCTS_Node object at 0x7f853a2f7198> 0.06416666666667226 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320f98> 0.2977083333333397 5
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 0.9197916666666757 12
Completed Iteration #16
Best Reward: 0.11416666666666941
Completed Iteration #17
Best Reward: 0.11416666666666941
Reward: 0.10770833333333485
backprop <src.mcts.MCTS_Node object at 0x7f853a39a550> 0.10770833333333485 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2f7240> 0.20583333333333798 3
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 1.0275000000000105 13
Completed Iteration #18
Best Reward: 0.11416666666666941
Completed Iteration #19
Best Reward: 0.11416666666666941
Reward: 0.09270833333333428
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3cf8> 0.09270833333333428 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406c88> 0.09270833333333428 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b940> 0.15541666666666742 3
backprop <src.mcts.MCTS_Node object at 0x7f85361f1550> 0.15541666666666742 3
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 1.1202083333333448 14
Completed Iteration #20
Best Reward: 0.11416666666666941
Completed Iteration #21
Best Reward: 0.11416666666666941
Reward: 0.054999999999999716
backprop <src.mcts.MCTS_Node object at 0x7f85361a6b00> 0.054999999999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3c88> 0.054999999999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 1.1752083333333445 15
Completed Iteration #22
Best Reward: 0.11416666666666941
Completed Iteration #23
Best Reward: 0.11416666666666941
Reward: 0.10166666666666657
backprop <src.mcts.MCTS_Node object at 0x7f85361af8d0> 0.10166666666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af518> 0.10166666666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 1.276875000000011 16
Completed Iteration #24
Best Reward: 0.11416666666666941
Reward: 0.06624999999999659
backprop <src.mcts.MCTS_Node object at 0x7f853a3201d0> 0.06624999999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320f98> 0.36395833333333627 6
backprop <src.mcts.MCTS_Node object at 0x7f853a320eb8> 1.3431250000000077 17
Completed Iteration #25
Best Reward: 0.11416666666666941
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11416666666666941
No reward increase. Abort.
iteration: 9
found coverage increase 0.11416666666666941
Current Total Coverage 38.880625
Reward: 0.11020833333333258
backprop <src.mcts.MCTS_Node object at 0x7f85361e36a0> 0.11020833333333258 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320e10> 0.11020833333333258 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 0.11020833333333258 2
Completed Iteration #0
Best Reward: 0.11020833333333258
Reward: 0.10458333333333059
backprop <src.mcts.MCTS_Node object at 0x7f853a320cc0> 0.10458333333333059 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320f60> 0.10458333333333059 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 0.21479166666666316 3
Completed Iteration #1
Best Reward: 0.11020833333333258
Reward: 0.06374999999999886
backprop <src.mcts.MCTS_Node object at 0x7f853a2f75f8> 0.06374999999999886 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dac88> 0.06374999999999886 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 0.278541666666662 4
Completed Iteration #2
Best Reward: 0.11020833333333258
Reward: 0.10145833333333343
backprop <src.mcts.MCTS_Node object at 0x7f853a2f7c88> 0.10145833333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320f60> 0.20604166666666401 3
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 0.37999999999999545 5
Completed Iteration #3
Best Reward: 0.11020833333333258
Reward: 0.10687500000000227
backprop <src.mcts.MCTS_Node object at 0x7f853a2f7c50> 0.10687500000000227 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2f77f0> 0.10687500000000227 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 0.4868749999999977 6
Completed Iteration #4
Best Reward: 0.11020833333333258
Reward: 0.0975000000000037
backprop <src.mcts.MCTS_Node object at 0x7f853a387d68> 0.0975000000000037 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320f60> 0.3035416666666677 4
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 0.5843750000000014 7
Completed Iteration #5
Best Reward: 0.11020833333333258
Completed Iteration #6
Best Reward: 0.11020833333333258
Reward: 0.09499999999999886
backprop <src.mcts.MCTS_Node object at 0x7f853a387080> 0.09499999999999886 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2f77f0> 0.20187500000000114 3
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 0.6793750000000003 8
Completed Iteration #7
Best Reward: 0.11020833333333258
Completed Iteration #8
Best Reward: 0.11020833333333258
Reward: 0.10333333333333172
backprop <src.mcts.MCTS_Node object at 0x7f853a315550> 0.10333333333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f853a315208> 0.10333333333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 0.782708333333332 9
Completed Iteration #9
Best Reward: 0.11020833333333258
Reward: 0.06520833333333087
backprop <src.mcts.MCTS_Node object at 0x7f853a3157b8> 0.06520833333333087 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dac88> 0.12895833333332973 3
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 0.8479166666666629 10
Completed Iteration #10
Best Reward: 0.11020833333333258
Reward: 0.10187499999999261
backprop <src.mcts.MCTS_Node object at 0x7f853a315a90> 0.10187499999999261 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2f77f0> 0.30374999999999375 4
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 0.9497916666666555 11
Completed Iteration #11
Best Reward: 0.11020833333333258
Reward: 0.08916666666666373
backprop <src.mcts.MCTS_Node object at 0x7f853a315d68> 0.08916666666666373 2
backprop <src.mcts.MCTS_Node object at 0x7f853a315208> 0.19249999999999545 3
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 1.0389583333333192 12
Completed Iteration #12
Best Reward: 0.11020833333333258
Reward: 0.06208333333332661
backprop <src.mcts.MCTS_Node object at 0x7f853a2c40f0> 0.06208333333332661 2
backprop <src.mcts.MCTS_Node object at 0x7f853a315d30> 0.06208333333332661 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 1.1010416666666458 13
Completed Iteration #13
Best Reward: 0.11020833333333258
Completed Iteration #14
Best Reward: 0.11020833333333258
Reward: 0.04791666666666572
backprop <src.mcts.MCTS_Node object at 0x7f853a315ef0> 0.04791666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2c45c0> 0.04791666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 1.1489583333333115 14
Completed Iteration #15
Best Reward: 0.11020833333333258
Reward: 0.04583333333333428
backprop <src.mcts.MCTS_Node object at 0x7f853a2f7748> 0.04583333333333428 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2c45c0> 0.09375 3
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 1.1947916666666458 15
Completed Iteration #16
Best Reward: 0.11020833333333258
Completed Iteration #17
Best Reward: 0.11020833333333258
Completed Iteration #18
Best Reward: 0.11020833333333258
Completed Iteration #19
Best Reward: 0.11020833333333258
Reward: 0.10249999999999915
backprop <src.mcts.MCTS_Node object at 0x7f853a2c4d68> 0.10249999999999915 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320f60> 0.40604166666666686 5
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 1.297291666666645 16
Completed Iteration #20
Best Reward: 0.11020833333333258
Reward: 0.08979166666666316
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4080> 0.08979166666666316 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2c4c18> 0.08979166666666316 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 1.3870833333333081 17
Completed Iteration #21
Best Reward: 0.11020833333333258
Reward: 0.1004166666666606
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4358> 0.1004166666666606 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2c45c0> 0.1941666666666606 4
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 1.4874999999999687 18
Completed Iteration #22
Best Reward: 0.11020833333333258
Completed Iteration #23
Best Reward: 0.11020833333333258
Completed Iteration #24
Best Reward: 0.11020833333333258
Reward: 0.08749999999999858
backprop <src.mcts.MCTS_Node object at 0x7f86102d9400> 0.08749999999999858 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2c4c18> 0.17729166666666174 3
backprop <src.mcts.MCTS_Node object at 0x7f853a320ef0> 1.5749999999999673 19
Completed Iteration #25
Best Reward: 0.11020833333333258
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11020833333333258
No reward increase. Abort.
iteration: 10
found coverage increase 0.11020833333333258
Current Total Coverage 38.990833333333335
Reward: 0.10000000000000142
backprop <src.mcts.MCTS_Node object at 0x7f853a39a7f0> 0.10000000000000142 2
backprop <src.mcts.MCTS_Node object at 0x7f85361e3f98> 0.10000000000000142 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.10000000000000142 2
Completed Iteration #0
Best Reward: 0.10000000000000142
coverage_call_count 300
Completed Iteration #1
Best Reward: 0.10000000000000142
Reward: 0.08187499999999659
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3400> 0.08187499999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f14e0> 0.08187499999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.181874999999998 3
Completed Iteration #2
Best Reward: 0.10000000000000142
Completed Iteration #3
Best Reward: 0.10000000000000142
Reward: 0.07000000000000028
backprop <src.mcts.MCTS_Node object at 0x7f853a320c18> 0.07000000000000028 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320470> 0.07000000000000028 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.2518749999999983 4
Completed Iteration #4
Best Reward: 0.10000000000000142
Completed Iteration #5
Best Reward: 0.10000000000000142
Completed Iteration #6
Best Reward: 0.10000000000000142
Completed Iteration #7
Best Reward: 0.10000000000000142
Reward: 0.07750000000000057
backprop <src.mcts.MCTS_Node object at 0x7f853a2f79e8> 0.07750000000000057 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f14e0> 0.15937499999999716 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.32937499999999886 5
Completed Iteration #8
Best Reward: 0.10000000000000142
Reward: 0.078125
backprop <src.mcts.MCTS_Node object at 0x7f853a2f7eb8> 0.078125 2
backprop <src.mcts.MCTS_Node object at 0x7f853a315940> 0.078125 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.40749999999999886 6
Completed Iteration #9
Best Reward: 0.10000000000000142
Reward: 0.08708333333333229
backprop <src.mcts.MCTS_Node object at 0x7f853a320da0> 0.08708333333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3080> 0.08708333333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.49458333333333115 7
Completed Iteration #10
Best Reward: 0.10000000000000142
Reward: 0.10312499999999858
backprop <src.mcts.MCTS_Node object at 0x7f853a2c49e8> 0.10312499999999858 2
backprop <src.mcts.MCTS_Node object at 0x7f85361f14e0> 0.26249999999999574 4
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.5977083333333297 8
Completed Iteration #11
Best Reward: 0.10312499999999858
Reward: 0.04854166666666515
backprop <src.mcts.MCTS_Node object at 0x7f853a2c4978> 0.04854166666666515 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2c4b38> 0.04854166666666515 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.6462499999999949 9
Completed Iteration #12
Best Reward: 0.10312499999999858
Reward: 0.10708333333332831
backprop <src.mcts.MCTS_Node object at 0x7f853a2c4208> 0.10708333333332831 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3080> 0.1941666666666606 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.7533333333333232 10
Completed Iteration #13
Best Reward: 0.10708333333332831
Reward: 0.04562500000000114
backprop <src.mcts.MCTS_Node object at 0x7f853a2d44e0> 0.04562500000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2c4b38> 0.09416666666666629 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.7989583333333243 11
Completed Iteration #14
Best Reward: 0.10708333333332831
Reward: 0.11395833333332916
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4828> 0.11395833333332916 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3d3080> 0.30812499999998977 4
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 0.9129166666666535 12
Completed Iteration #15
Best Reward: 0.11395833333332916
Completed Iteration #16
Best Reward: 0.11395833333332916
Reward: 0.10104166666666714
backprop <src.mcts.MCTS_Node object at 0x7f853a315160> 0.10104166666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f85361e3f98> 0.20104166666666856 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.0139583333333206 13
Completed Iteration #17
Best Reward: 0.11395833333332916
Reward: 0.051666666666669414
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4160> 0.051666666666669414 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d49b0> 0.051666666666669414 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.06562499999999 14
Completed Iteration #18
Best Reward: 0.11395833333332916
Reward: 0.11104166666666515
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4f98> 0.11104166666666515 2
backprop <src.mcts.MCTS_Node object at 0x7f853a315940> 0.18916666666666515 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.1766666666666552 15
Completed Iteration #19
Best Reward: 0.11395833333332916
Reward: 0.10958333333333314
backprop <src.mcts.MCTS_Node object at 0x7f853a28c320> 0.10958333333333314 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28c1d0> 0.10958333333333314 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4160> 0.16125000000000256 3
backprop <src.mcts.MCTS_Node object at 0x7f853a2d49b0> 0.16125000000000256 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.2862499999999883 16
Completed Iteration #20
Best Reward: 0.11395833333332916
Reward: 0.10333333333333172
backprop <src.mcts.MCTS_Node object at 0x7f853a28c668> 0.10333333333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f85361e3f98> 0.3043750000000003 4
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.38958333333332 17
Completed Iteration #21
Best Reward: 0.11395833333332916
Reward: 0.10812500000000114
backprop <src.mcts.MCTS_Node object at 0x7f853a28c9b0> 0.10812500000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28c630> 0.10812500000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2c49e8> 0.21124999999999972 3
backprop <src.mcts.MCTS_Node object at 0x7f85361f14e0> 0.3706249999999969 5
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.4977083333333212 18
Completed Iteration #22
Best Reward: 0.11395833333332916
Completed Iteration #23
Best Reward: 0.11395833333332916
Reward: 0.06312499999999943
backprop <src.mcts.MCTS_Node object at 0x7f853a28cf60> 0.06312499999999943 2
backprop <src.mcts.MCTS_Node object at 0x7f853a320470> 0.13312499999999972 3
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.5608333333333206 19
Completed Iteration #24
Best Reward: 0.11395833333332916
Reward: 0.10104166666666714
backprop <src.mcts.MCTS_Node object at 0x7f853a28c080> 0.10104166666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28ce10> 0.10104166666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f85361af7f0> 1.6618749999999878 20
Completed Iteration #25
Best Reward: 0.11395833333332916
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11395833333332916
No reward increase. Abort.
iteration: 11
found coverage increase 0.11395833333332916
Current Total Coverage 39.104791666666664
Reward: 0.10395833333333115
backprop <src.mcts.MCTS_Node object at 0x7f863308aa20> 0.10395833333333115 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4080> 0.10395833333333115 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 0.10395833333333115 2
Completed Iteration #0
Best Reward: 0.10395833333333115
Reward: 0.09229166666666799
backprop <src.mcts.MCTS_Node object at 0x7f853a28cd30> 0.09229166666666799 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28cf98> 0.09229166666666799 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 0.19624999999999915 3
Completed Iteration #1
Best Reward: 0.10395833333333115
Reward: 0.10770833333333485
backprop <src.mcts.MCTS_Node object at 0x7f853a2d43c8> 0.10770833333333485 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28cdd8> 0.10770833333333485 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 0.303958333333334 4
Completed Iteration #2
Best Reward: 0.10770833333333485
Reward: 0.10854166666666742
backprop <src.mcts.MCTS_Node object at 0x7f853a28c2e8> 0.10854166666666742 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28c198> 0.10854166666666742 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 0.4125000000000014 5
Completed Iteration #3
Best Reward: 0.10854166666666742
Completed Iteration #4
Best Reward: 0.10854166666666742
Reward: 0.1027083333333394
backprop <src.mcts.MCTS_Node object at 0x7f853a28c208> 0.1027083333333394 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28cdd8> 0.21041666666667425 3
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 0.5152083333333408 6
Completed Iteration #5
Best Reward: 0.10854166666666742
Reward: 0.09854166666666941
backprop <src.mcts.MCTS_Node object at 0x7f853a28c630> 0.09854166666666941 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28cf98> 0.1908333333333374 3
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 0.6137500000000102 7
Completed Iteration #6
Best Reward: 0.10854166666666742
Reward: 0.07708333333333428
backprop <src.mcts.MCTS_Node object at 0x7f853a28c0f0> 0.07708333333333428 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4518> 0.07708333333333428 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 0.6908333333333445 8
Completed Iteration #7
Best Reward: 0.10854166666666742
Reward: 0.09708333333333741
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4860> 0.09708333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28cf98> 0.2879166666666748 4
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 0.7879166666666819 9
Completed Iteration #8
Best Reward: 0.10854166666666742
Reward: 0.09854166666666941
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4dd8> 0.09854166666666941 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4908> 0.09854166666666941 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 0.8864583333333513 10
Completed Iteration #9
Best Reward: 0.10854166666666742
Reward: 0.07895833333333968
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4208> 0.07895833333333968 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28cdd8> 0.2893750000000139 4
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 0.965416666666691 11
Completed Iteration #10
Best Reward: 0.10854166666666742
Reward: 0.10249999999999915
backprop <src.mcts.MCTS_Node object at 0x7f85d7dd04a8> 0.10249999999999915 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28c550> 0.10249999999999915 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 1.0679166666666902 12
Completed Iteration #11
Best Reward: 0.10854166666666742
Completed Iteration #12
Best Reward: 0.10854166666666742
Reward: 0.10062500000000085
backprop <src.mcts.MCTS_Node object at 0x7f853a387908> 0.10062500000000085 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4080> 0.204583333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 1.168541666666691 13
Completed Iteration #13
Best Reward: 0.10854166666666742
Reward: 0.10583333333333655
backprop <src.mcts.MCTS_Node object at 0x7f853a3872e8> 0.10583333333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f853a387b00> 0.10583333333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 1.2743750000000276 14
Completed Iteration #14
Best Reward: 0.10854166666666742
Reward: 0.1075000000000017
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4ba8> 0.1075000000000017 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4080> 0.3120833333333337 4
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 1.3818750000000293 15
Completed Iteration #15
Best Reward: 0.10854166666666742
Reward: 0.10062500000000085
backprop <src.mcts.MCTS_Node object at 0x7f853a3872b0> 0.10062500000000085 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28c198> 0.20916666666666828 3
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 1.4825000000000301 16
Completed Iteration #16
Best Reward: 0.10854166666666742
Reward: 0.10000000000000142
backprop <src.mcts.MCTS_Node object at 0x7f853a387f28> 0.10000000000000142 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28c550> 0.20250000000000057 3
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 1.5825000000000315 17
Completed Iteration #17
Best Reward: 0.10854166666666742
Completed Iteration #18
Best Reward: 0.10854166666666742
Reward: 0.08750000000000568
backprop <src.mcts.MCTS_Node object at 0x7f8536235a20> 0.08750000000000568 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4908> 0.1860416666666751 3
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 1.6700000000000372 18
Completed Iteration #19
Best Reward: 0.10854166666666742
Completed Iteration #20
Best Reward: 0.10854166666666742
Completed Iteration #21
Best Reward: 0.10854166666666742
Reward: 0.10104166666666714
backprop <src.mcts.MCTS_Node object at 0x7f853a39a860> 0.10104166666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28cf98> 0.38895833333334195 5
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 1.7710416666667044 19
Completed Iteration #22
Best Reward: 0.10854166666666742
Reward: 0.11479166666666885
backprop <src.mcts.MCTS_Node object at 0x7f853a39a4e0> 0.11479166666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4518> 0.19187500000000313 3
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 1.8858333333333732 20
Completed Iteration #23
Best Reward: 0.11479166666666885
Reward: 0.07895833333333968
backprop <src.mcts.MCTS_Node object at 0x7f853a39a208> 0.07895833333333968 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4518> 0.2708333333333428 4
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 1.964791666666713 21
Completed Iteration #24
Best Reward: 0.11479166666666885
Reward: 0.10625000000000284
backprop <src.mcts.MCTS_Node object at 0x7f853a387160> 0.10625000000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4908> 0.29229166666667794 4
backprop <src.mcts.MCTS_Node object at 0x7f853a2d48d0> 2.0710416666667157 22
Completed Iteration #25
Best Reward: 0.11479166666666885
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11479166666666885
No reward increase. Abort.
iteration: 12
found coverage increase 0.11479166666666885
Current Total Coverage 39.21958333333333
Reward: 0.08229166666666288
backprop <src.mcts.MCTS_Node object at 0x7f8536235c50> 0.08229166666666288 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da8d0> 0.08229166666666288 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.08229166666666288 2
Completed Iteration #0
Best Reward: 0.08229166666666288
Reward: 0.07312499999999744
backprop <src.mcts.MCTS_Node object at 0x7f853a3daf28> 0.07312499999999744 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da390> 0.07312499999999744 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.15541666666666032 3
Completed Iteration #1
Best Reward: 0.08229166666666288
Completed Iteration #2
Best Reward: 0.08229166666666288
Reward: 0.07729166666666742
backprop <src.mcts.MCTS_Node object at 0x7f853a3da4a8> 0.07729166666666742 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da390> 0.15041666666666487 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.23270833333332774 4
Completed Iteration #3
Best Reward: 0.08229166666666288
Reward: 0.08729166666667254
backprop <src.mcts.MCTS_Node object at 0x7f853a406400> 0.08729166666667254 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406128> 0.08729166666667254 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.3200000000000003 5
Completed Iteration #4
Best Reward: 0.08729166666667254
Reward: 0.08812500000000512
backprop <src.mcts.MCTS_Node object at 0x7f853a406240> 0.08812500000000512 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406128> 0.17541666666667766 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.4081250000000054 6
Completed Iteration #5
Best Reward: 0.08812500000000512
Reward: 0.04187499999999744
backprop <src.mcts.MCTS_Node object at 0x7f853a406048> 0.04187499999999744 2
backprop <src.mcts.MCTS_Node object at 0x7f853a4067b8> 0.04187499999999744 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.45000000000000284 7
Completed Iteration #6
Best Reward: 0.08812500000000512
Reward: 0.09145833333333542
backprop <src.mcts.MCTS_Node object at 0x7f853a41b860> 0.09145833333333542 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406128> 0.2668750000000131 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.5414583333333383 8
Completed Iteration #7
Best Reward: 0.09145833333333542
Reward: 0.0885416666666643
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4898> 0.0885416666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f853a406128> 0.35541666666667737 5
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.6300000000000026 9
Completed Iteration #8
Best Reward: 0.09145833333333542
Reward: 0.10333333333333883
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4ef0> 0.10333333333333883 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4b38> 0.10333333333333883 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235c50> 0.1856250000000017 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3da8d0> 0.1856250000000017 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.7333333333333414 10
Completed Iteration #9
Best Reward: 0.10333333333333883
Reward: 0.060000000000002274
backprop <src.mcts.MCTS_Node object at 0x7f853a387080> 0.060000000000002274 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4710> 0.060000000000002274 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.7933333333333437 11
Completed Iteration #10
Best Reward: 0.10333333333333883
Reward: 0.09312500000000057
backprop <src.mcts.MCTS_Node object at 0x7f853a387400> 0.09312500000000057 2
backprop <src.mcts.MCTS_Node object at 0x7f853a4067b8> 0.134999999999998 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.8864583333333442 12
Completed Iteration #11
Best Reward: 0.10333333333333883
Reward: 0.086666666666666
backprop <src.mcts.MCTS_Node object at 0x7f853a28ca90> 0.086666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da208> 0.086666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 0.9731250000000102 13
Completed Iteration #12
Best Reward: 0.10333333333333883
Reward: 0.07125000000000625
backprop <src.mcts.MCTS_Node object at 0x7f853a28c7f0> 0.07125000000000625 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28c860> 0.07125000000000625 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 1.0443750000000165 14
Completed Iteration #13
Best Reward: 0.10333333333333883
Reward: 0.09104166666666913
backprop <src.mcts.MCTS_Node object at 0x7f8536235da0> 0.09104166666666913 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235978> 0.09104166666666913 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 1.1354166666666856 15
Completed Iteration #14
Best Reward: 0.10333333333333883
Completed Iteration #15
Best Reward: 0.10333333333333883
Reward: 0.04958333333333087
backprop <src.mcts.MCTS_Node object at 0x7f853a39aa90> 0.04958333333333087 2
backprop <src.mcts.MCTS_Node object at 0x7f853a4067b8> 0.18458333333332888 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 1.1850000000000165 16
Completed Iteration #16
Best Reward: 0.10333333333333883
Reward: 0.08958333333333712
backprop <src.mcts.MCTS_Node object at 0x7f8536235b00> 0.08958333333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f853a4067b8> 0.274166666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 1.2745833333333536 17
Completed Iteration #17
Best Reward: 0.10333333333333883
Reward: 0.06333333333333258
backprop <src.mcts.MCTS_Node object at 0x7f853a387b70> 0.06333333333333258 2
backprop <src.mcts.MCTS_Node object at 0x7f853a28c860> 0.13458333333333883 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 1.3379166666666862 18
Completed Iteration #18
Best Reward: 0.10333333333333883
Reward: 0.09062500000000284
backprop <src.mcts.MCTS_Node object at 0x7f853a3da7f0> 0.09062500000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da208> 0.17729166666666885 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 1.428541666666689 19
Completed Iteration #19
Best Reward: 0.10333333333333883
Completed Iteration #20
Best Reward: 0.10333333333333883
Reward: 0.09458333333333258
backprop <src.mcts.MCTS_Node object at 0x7f853a406438> 0.09458333333333258 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4710> 0.15458333333333485 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 1.5231250000000216 20
Completed Iteration #21
Best Reward: 0.10333333333333883
Reward: 0.09812500000000313
backprop <src.mcts.MCTS_Node object at 0x7f853a406978> 0.09812500000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f8536235978> 0.18916666666667226 3
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 1.6212500000000247 21
Completed Iteration #22
Best Reward: 0.10333333333333883
Reward: 0.0970833333333303
backprop <src.mcts.MCTS_Node object at 0x7f853a41b9e8> 0.0970833333333303 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da390> 0.24749999999999517 4
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 1.718333333333355 22
Completed Iteration #23
Best Reward: 0.10333333333333883
Completed Iteration #24
Best Reward: 0.10333333333333883
Reward: 0.06708333333332916
backprop <src.mcts.MCTS_Node object at 0x7f853a406518> 0.06708333333332916 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b4a8> 0.06708333333332916 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3dadd8> 1.7854166666666842 23
Completed Iteration #25
Best Reward: 0.10333333333333883
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10333333333333883
No reward increase. Abort.
iteration: 13
found coverage increase 0.10333333333333883
Current Total Coverage 39.32291666666667
Reward: 0.053124999999994316
backprop <src.mcts.MCTS_Node object at 0x7f853a41b128> 0.053124999999994316 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bba8> 0.053124999999994316 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.053124999999994316 2
Completed Iteration #0
Best Reward: 0.053124999999994316
Reward: 0.05062499999999659
backprop <src.mcts.MCTS_Node object at 0x7f853a41b5c0> 0.05062499999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bba8> 0.1037499999999909 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.1037499999999909 3
Completed Iteration #1
Best Reward: 0.053124999999994316
Reward: 0.03937499999999261
backprop <src.mcts.MCTS_Node object at 0x7f85361a6e10> 0.03937499999999261 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a66a0> 0.03937499999999261 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.14312499999998352 4
Completed Iteration #2
Best Reward: 0.053124999999994316
Reward: 0.08791666666666487
backprop <src.mcts.MCTS_Node object at 0x7f85361a6630> 0.08791666666666487 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6668> 0.08791666666666487 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.23104166666664838 5
Completed Iteration #3
Best Reward: 0.08791666666666487
Reward: 0.09999999999999432
backprop <src.mcts.MCTS_Node object at 0x7f85361a6eb8> 0.09999999999999432 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.09999999999999432 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.3310416666666427 6
Completed Iteration #4
Best Reward: 0.09999999999999432
Completed Iteration #5
Best Reward: 0.09999999999999432
Reward: 0.09250000000000114
backprop <src.mcts.MCTS_Node object at 0x7f85b819dbe0> 0.09250000000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6cc0> 0.09250000000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.42354166666664383 7
Completed Iteration #6
Best Reward: 0.09999999999999432
Reward: 0.09687499999999005
backprop <src.mcts.MCTS_Node object at 0x7f85b819db70> 0.09687499999999005 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bba8> 0.20062499999998096 4
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.5204166666666339 8
Completed Iteration #7
Best Reward: 0.09999999999999432
Completed Iteration #8
Best Reward: 0.09999999999999432
Completed Iteration #9
Best Reward: 0.09999999999999432
Reward: 0.08937499999999687
backprop <src.mcts.MCTS_Node object at 0x7f85361cefd0> 0.08937499999999687 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce358> 0.08937499999999687 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.6097916666666308 9
Completed Iteration #10
Best Reward: 0.09999999999999432
Completed Iteration #11
Best Reward: 0.09999999999999432
Completed Iteration #12
Best Reward: 0.09999999999999432
Reward: 0.08499999999999375
backprop <src.mcts.MCTS_Node object at 0x7f853a39af98> 0.08499999999999375 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a66a0> 0.12437499999998636 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.6947916666666245 10
Completed Iteration #13
Best Reward: 0.09999999999999432
Reward: 0.03999999999999204
backprop <src.mcts.MCTS_Node object at 0x7f853a39a7f0> 0.03999999999999204 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a66a0> 0.1643749999999784 4
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.7347916666666165 11
Completed Iteration #14
Best Reward: 0.09999999999999432
Reward: 0.07208333333333172
backprop <src.mcts.MCTS_Node object at 0x7f853a387f98> 0.07208333333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6cc0> 0.16458333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.8068749999999483 12
Completed Iteration #15
Best Reward: 0.09999999999999432
Reward: 0.08312499999999545
backprop <src.mcts.MCTS_Node object at 0x7f853a387c18> 0.08312499999999545 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce358> 0.17249999999999233 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.8899999999999437 13
Completed Iteration #16
Best Reward: 0.09999999999999432
Reward: 0.08437499999999432
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4eb8> 0.08437499999999432 2
backprop <src.mcts.MCTS_Node object at 0x7f85361ce358> 0.25687499999998664 4
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 0.974374999999938 14
Completed Iteration #17
Best Reward: 0.09999999999999432
Reward: 0.04187499999999034
backprop <src.mcts.MCTS_Node object at 0x7f853a2d46a0> 0.04187499999999034 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a66a0> 0.20624999999996874 5
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 1.0162499999999284 15
Completed Iteration #18
Best Reward: 0.09999999999999432
Reward: 0.054166666666660035
backprop <src.mcts.MCTS_Node object at 0x7f853a406048> 0.054166666666660035 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6c18> 0.15416666666665435 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 1.0704166666665884 16
Completed Iteration #19
Best Reward: 0.09999999999999432
coverage_call_count 400
Completed Iteration #20
Best Reward: 0.09999999999999432
Reward: 0.02645833333332348
backprop <src.mcts.MCTS_Node object at 0x7f853a39aa90> 0.02645833333332348 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d49b0> 0.02645833333332348 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 1.096874999999912 17
Completed Iteration #21
Best Reward: 0.09999999999999432
Completed Iteration #22
Best Reward: 0.09999999999999432
Reward: 0.0847916666666606
backprop <src.mcts.MCTS_Node object at 0x7f853a28c860> 0.0847916666666606 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6668> 0.17270833333332547 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 1.1816666666665725 18
Completed Iteration #23
Best Reward: 0.09999999999999432
Reward: 0.025416666666664867
backprop <src.mcts.MCTS_Node object at 0x7f853a28c5f8> 0.025416666666664867 2
backprop <src.mcts.MCTS_Node object at 0x7f853a2d49b0> 0.05187499999998835 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 1.2070833333332374 19
Completed Iteration #24
Best Reward: 0.09999999999999432
Reward: 0.08291666666666231
backprop <src.mcts.MCTS_Node object at 0x7f853a41ba58> 0.08291666666666231 2
backprop <src.mcts.MCTS_Node object at 0x7f86102d9400> 0.08291666666666231 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bc88> 1.2899999999998997 20
Completed Iteration #25
Best Reward: 0.09999999999999432
Completed MCTS Level/Depth: #0
root
Best Reward: 0.09999999999999432
No reward increase. Abort.
iteration: 14
found coverage increase 0.09999999999999432
Current Total Coverage 39.422916666666666
Reward: 0.05645833333333172
backprop <src.mcts.MCTS_Node object at 0x7f853a28c898> 0.05645833333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b358> 0.05645833333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 0.05645833333333172 2
Completed Iteration #0
Best Reward: 0.05645833333333172
Reward: 0.0885416666666643
backprop <src.mcts.MCTS_Node object at 0x7f853a387da0> 0.0885416666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f853a4065c0> 0.0885416666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 0.14499999999999602 3
Completed Iteration #1
Best Reward: 0.0885416666666643
Reward: 0.09916666666666885
backprop <src.mcts.MCTS_Node object at 0x7f853a3dab00> 0.09916666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bb00> 0.09916666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 0.24416666666666487 4
Completed Iteration #2
Best Reward: 0.09916666666666885
Reward: 0.08208333333333684
backprop <src.mcts.MCTS_Node object at 0x7f853a3daeb8> 0.08208333333333684 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da438> 0.08208333333333684 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 0.3262500000000017 5
Completed Iteration #3
Best Reward: 0.09916666666666885
Reward: 0.07208333333333883
backprop <src.mcts.MCTS_Node object at 0x7f85361a68d0> 0.07208333333333883 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da4a8> 0.07208333333333883 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 0.39833333333334053 6
Completed Iteration #4
Best Reward: 0.09916666666666885
Completed Iteration #5
Best Reward: 0.09916666666666885
Completed Iteration #6
Best Reward: 0.09916666666666885
Reward: 0.10562500000000341
backprop <src.mcts.MCTS_Node object at 0x7f853a41be48> 0.10562500000000341 2
backprop <src.mcts.MCTS_Node object at 0x7f85b819db38> 0.10562500000000341 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 0.5039583333333439 7
Completed Iteration #7
Best Reward: 0.10562500000000341
Reward: 0.08833333333333115
backprop <src.mcts.MCTS_Node object at 0x7f85b819dc18> 0.08833333333333115 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da4a8> 0.16041666666666998 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 0.5922916666666751 8
Completed Iteration #8
Best Reward: 0.10562500000000341
Completed Iteration #9
Best Reward: 0.10562500000000341
Reward: 0.08833333333333115
backprop <src.mcts.MCTS_Node object at 0x7f85361ce9b0> 0.08833333333333115 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41bb00> 0.1875 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 0.6806250000000063 9
Completed Iteration #10
Best Reward: 0.10562500000000341
Completed Iteration #11
Best Reward: 0.10562500000000341
Completed Iteration #12
Best Reward: 0.10562500000000341
Reward: 0.06791666666666174
backprop <src.mcts.MCTS_Node object at 0x7f85361af9b0> 0.06791666666666174 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da4a8> 0.22833333333333172 4
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 0.748541666666668 10
Completed Iteration #13
Best Reward: 0.10562500000000341
Reward: 0.100833333333334
backprop <src.mcts.MCTS_Node object at 0x7f85361ce278> 0.100833333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6d30> 0.100833333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 0.849375000000002 11
Completed Iteration #14
Best Reward: 0.10562500000000341
Completed Iteration #15
Best Reward: 0.10562500000000341
Reward: 0.100833333333334
backprop <src.mcts.MCTS_Node object at 0x7f85361af5c0> 0.100833333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6d30> 0.201666666666668 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 0.950208333333336 12
Completed Iteration #16
Best Reward: 0.10562500000000341
Completed Iteration #17
Best Reward: 0.10562500000000341
Reward: 0.08979166666667027
backprop <src.mcts.MCTS_Node object at 0x7f853a315da0> 0.08979166666667027 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6d30> 0.29145833333333826 4
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 1.0400000000000063 13
Completed Iteration #18
Best Reward: 0.10562500000000341
Reward: 0.07312499999999744
backprop <src.mcts.MCTS_Node object at 0x7f853a315ba8> 0.07312499999999744 2
backprop <src.mcts.MCTS_Node object at 0x7f85b819db38> 0.17875000000000085 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 1.1131250000000037 14
Completed Iteration #19
Best Reward: 0.10562500000000341
Completed Iteration #20
Best Reward: 0.10562500000000341
Reward: 0.09333333333333371
backprop <src.mcts.MCTS_Node object at 0x7f853a39aa20> 0.09333333333333371 2
backprop <src.mcts.MCTS_Node object at 0x7f85361a6d30> 0.38479166666667197 5
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 1.2064583333333374 15
Completed Iteration #21
Best Reward: 0.10562500000000341
Reward: 0.0435416666666697
backprop <src.mcts.MCTS_Node object at 0x7f853a2d4ac8> 0.0435416666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f853a39a780> 0.0435416666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 1.250000000000007 16
Completed Iteration #22
Best Reward: 0.10562500000000341
Completed Iteration #23
Best Reward: 0.10562500000000341
Reward: 0.09854166666666231
backprop <src.mcts.MCTS_Node object at 0x7f853a406400> 0.09854166666666231 2
backprop <src.mcts.MCTS_Node object at 0x7f853a41b358> 0.15499999999999403 3
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 1.3485416666666694 17
Completed Iteration #24
Best Reward: 0.10562500000000341
Reward: 0.09729166666667055
backprop <src.mcts.MCTS_Node object at 0x7f853a387e80> 0.09729166666667055 2
backprop <src.mcts.MCTS_Node object at 0x7f853a3da4a8> 0.3256250000000023 5
backprop <src.mcts.MCTS_Node object at 0x7f853a41b7f0> 1.44583333333334 18
Completed Iteration #25
Best Reward: 0.10562500000000341
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10562500000000341
No reward increase. Abort.
iteration: 15
found coverage increase 0.10562500000000341
Current Total Coverage 39.52854166666667
initial coverage: 37.786
time passed (minutes): 14.0628
iterations: 16
number of new inputs: 1024
final coverage: 39.5285
total coverage increase: 1.7425
