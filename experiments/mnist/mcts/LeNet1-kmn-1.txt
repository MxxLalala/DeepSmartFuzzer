Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'kmn'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f50204faf28>, tc2=<function tc2 at 0x7f502050b048>, tc3=<function tc3 at 0x7f502050b158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 25.625
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 25.624999999999996
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47bd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47bd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47743c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47743c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47743c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47743c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 25.624999999999996
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 25.624999999999996
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa47748d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 3
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 4
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 5
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 6
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 7
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 8
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 9
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 10
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 11
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 12
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 13
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 14
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 15
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 16
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 17
Completed Iteration #19
Best Reward: 0.10416666666666785
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 18
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 19
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 20
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 21
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47748d0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.10416666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 22
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.10416666666666785 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.10416666666666785 23
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.2083333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.2083333333333357 24
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.2083333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.2083333333333357 25
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.2083333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.2083333333333357 26
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.2083333333333357 10
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.2083333333333357 27
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.2083333333333357 11
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.2083333333333357 28
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #1
root->7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6390> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.31250000000000355 12
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.31250000000000355 29
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.31250000000000355 13
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.31250000000000355 30
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.31250000000000355 14
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.31250000000000355 31
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.2083333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.31250000000000355 15
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.31250000000000355 32
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eee80> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eeb38> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.31250000000000355 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.4166666666666714 16
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.4166666666666714 33
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.31250000000000355 8
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.4166666666666714 17
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.4166666666666714 34
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.31250000000000355 9
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.4166666666666714 18
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.4166666666666714 35
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d6d8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.4166666666666714 10
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.5208333333333393 19
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.5208333333333393 36
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.4166666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.5208333333333393 20
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.5208333333333393 37
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa467da20> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eeb38> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.5208333333333393 12
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.6250000000000071 21
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.6250000000000071 38
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eeb38> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.5208333333333393 13
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.6250000000000071 22
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.6250000000000071 39
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa467de48> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eeb38> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.6250000000000071 14
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.729166666666675 23
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.729166666666675 40
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eee80> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eeb38> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.6250000000000071 15
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.729166666666675 24
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.729166666666675 41
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d66d8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eeb38> 0.4166666666666714 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.729166666666675 16
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.8333333333333428 25
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.8333333333333428 42
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #2
root->7->16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa47633c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.8333333333333428 17
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.9375000000000107 26
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.9375000000000107 43
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.8333333333333428 18
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.9375000000000107 27
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.9375000000000107 44
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.8333333333333428 19
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.9375000000000107 28
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.9375000000000107 45
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.31250000000000355 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.8333333333333428 20
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 0.9375000000000107 29
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.9375000000000107 46
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6dd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.4166666666666714 8
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.9375000000000107 21
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.0416666666666785 30
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.0416666666666785 47
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47633c8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.4166666666666714 9
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 0.9375000000000107 22
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.0416666666666785 31
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.0416666666666785 48
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f668> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.5208333333333393 10
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.0416666666666785 23
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.1458333333333464 32
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.1458333333333464 49
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.5208333333333393 11
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.0416666666666785 24
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.1458333333333464 33
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.1458333333333464 50
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d6d8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.5208333333333393 12
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.0416666666666785 25
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.1458333333333464 34
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.1458333333333464 51
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 13
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 26
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 35
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 52
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 14
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 27
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 36
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 53
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6390> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 15
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 28
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 37
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 54
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #3
root->7->16->2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 29
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 38
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 55
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 17
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 30
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 39
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 56
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.10416666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 18
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 31
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 40
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 57
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.10416666666666785 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 19
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 32
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 41
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 58
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.10416666666666785 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 20
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 33
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 42
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 59
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.10416666666666785 8
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 21
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 34
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 43
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 60
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.10416666666666785 9
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 22
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 35
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 44
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 61
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.10416666666666785 10
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 23
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 36
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 45
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 62
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.10416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 24
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 37
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 46
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 63
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.10416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.6250000000000071 25
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.1458333333333464 38
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.2500000000000142 47
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.2500000000000142 64
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ea20> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467dd30> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.2083333333333357 13
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.729166666666675 26
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.2500000000000142 39
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.354166666666682 48
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.354166666666682 65
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa463edd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.31250000000000355 14
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.8333333333333428 27
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.354166666666682 40
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.45833333333335 49
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.45833333333335 66
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #4
root->7->16->2->2
Best Reward: 0.10416666666666785
coverage_call_count 200
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.31250000000000355 15
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.8333333333333428 28
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.354166666666682 41
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.45833333333335 50
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.45833333333335 67
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.31250000000000355 16
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.8333333333333428 29
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.354166666666682 42
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.45833333333335 51
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.45833333333335 68
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa47637f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.4166666666666714 17
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.9375000000000107 30
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.45833333333335 43
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.5625000000000178 52
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.5625000000000178 69
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6940> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.5208333333333393 18
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.0416666666666785 31
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.5625000000000178 44
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.6666666666666856 53
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.6666666666666856 70
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47637f0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.31250000000000355 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.5208333333333393 19
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.0416666666666785 32
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.5625000000000178 45
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.6666666666666856 54
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.6666666666666856 71
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e5f8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.4166666666666714 8
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.6250000000000071 20
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.1458333333333464 33
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.6666666666666856 46
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.7708333333333535 55
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.7708333333333535 72
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47637f0> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.4166666666666714 9
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.6250000000000071 21
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.1458333333333464 34
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.6666666666666856 47
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.7708333333333535 56
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.7708333333333535 73
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e160> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.5208333333333393 10
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.729166666666675 22
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.2500000000000142 35
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.7708333333333535 48
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.8750000000000213 57
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.8750000000000213 74
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.6250000000000071 11
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.8333333333333428 23
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.354166666666682 36
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.8750000000000213 49
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.9791666666666892 58
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.9791666666666892 75
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e160> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.6250000000000071 12
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.8333333333333428 24
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.354166666666682 37
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.8750000000000213 50
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.9791666666666892 59
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.9791666666666892 76
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47268d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.6250000000000071 13
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.8333333333333428 25
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.354166666666682 38
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.8750000000000213 51
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.9791666666666892 60
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.9791666666666892 77
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463edd8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.6250000000000071 14
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.8333333333333428 26
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.354166666666682 39
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.8750000000000213 52
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.9791666666666892 61
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.9791666666666892 78
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #5
root->7->16->2->2->0
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.6250000000000071 15
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.8333333333333428 27
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.354166666666682 40
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.8750000000000213 53
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.9791666666666892 62
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.9791666666666892 79
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.6250000000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.8333333333333428 28
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.354166666666682 41
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.8750000000000213 54
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.9791666666666892 63
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.9791666666666892 80
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.10416666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.6250000000000071 17
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.8333333333333428 29
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.354166666666682 42
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.8750000000000213 55
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.9791666666666892 64
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.9791666666666892 81
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.10416666666666785 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.6250000000000071 18
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.8333333333333428 30
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.354166666666682 43
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.8750000000000213 56
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.9791666666666892 65
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.9791666666666892 82
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.10416666666666785 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.6250000000000071 19
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.8333333333333428 31
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.354166666666682 44
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.8750000000000213 57
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 1.9791666666666892 66
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 1.9791666666666892 83
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.2083333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.729166666666675 20
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.9375000000000107 32
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.45833333333335 45
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 1.9791666666666892 58
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.083333333333357 67
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.083333333333357 84
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.31250000000000355 9
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.8333333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.0416666666666785 33
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.5625000000000178 46
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.083333333333357 59
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.187500000000025 68
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.187500000000025 85
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.31250000000000355 10
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.8333333333333428 22
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.0416666666666785 34
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.5625000000000178 47
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.083333333333357 60
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.187500000000025 69
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.187500000000025 86
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.2083333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.31250000000000355 11
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.8333333333333428 23
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.0416666666666785 35
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.5625000000000178 48
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.083333333333357 61
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.187500000000025 70
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.187500000000025 87
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.31250000000000355 12
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.8333333333333428 24
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.0416666666666785 36
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.5625000000000178 49
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.083333333333357 62
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.187500000000025 71
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.187500000000025 88
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f907baf28> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646c50> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.4166666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.9375000000000107 25
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.1458333333333464 37
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.6666666666666856 50
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.187500000000025 63
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.2916666666666927 72
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.2916666666666927 89
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.4166666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.9375000000000107 26
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.1458333333333464 38
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.6666666666666856 51
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.187500000000025 64
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.2916666666666927 73
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.2916666666666927 90
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #6
root->7->16->2->2->0->3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907baa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.2083333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.4166666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.9375000000000107 27
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.1458333333333464 39
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.6666666666666856 52
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.187500000000025 65
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.2916666666666927 74
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.2916666666666927 91
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.2083333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.4166666666666714 16
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.9375000000000107 28
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.1458333333333464 40
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.6666666666666856 53
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.187500000000025 66
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.2916666666666927 75
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.2916666666666927 92
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.2083333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.4166666666666714 17
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.9375000000000107 29
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.1458333333333464 41
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.6666666666666856 54
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.187500000000025 67
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.2916666666666927 76
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.2916666666666927 93
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.2083333333333357 10
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.4166666666666714 18
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.9375000000000107 30
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.1458333333333464 42
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.6666666666666856 55
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.187500000000025 68
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.2916666666666927 77
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.2916666666666927 94
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.2083333333333357 11
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.4166666666666714 19
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.9375000000000107 31
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.1458333333333464 43
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.6666666666666856 56
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.187500000000025 69
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.2916666666666927 78
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.2916666666666927 95
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.2083333333333357 12
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.4166666666666714 20
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.9375000000000107 32
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.1458333333333464 44
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.6666666666666856 57
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.187500000000025 70
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.2916666666666927 79
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.2916666666666927 96
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #7
root->7->16->2->2->0->3->4
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.2083333333333357 13
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.4166666666666714 21
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.9375000000000107 33
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.1458333333333464 45
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.6666666666666856 58
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.187500000000025 71
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.2916666666666927 80
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.2916666666666927 97
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e0f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fc88> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.31250000000000355 14
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.5208333333333393 22
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 1.0416666666666785 34
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.2500000000000142 46
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.7708333333333535 59
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.2916666666666927 72
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.3958333333333606 81
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.3958333333333606 98
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.31250000000000355 15
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.5208333333333393 23
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 1.0416666666666785 35
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.2500000000000142 47
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.7708333333333535 60
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.2916666666666927 73
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.3958333333333606 82
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.3958333333333606 99
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fbe0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bafd0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.4166666666666714 16
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.6250000000000071 24
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 1.1458333333333464 36
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.354166666666682 48
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.8750000000000213 61
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.3958333333333606 74
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.5000000000000284 83
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.5000000000000284 100
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.31250000000000355 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.4166666666666714 17
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.6250000000000071 25
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 1.1458333333333464 37
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.354166666666682 49
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.8750000000000213 62
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.3958333333333606 75
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.5000000000000284 84
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.5000000000000284 101
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcc50> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bafd0> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.4166666666666714 8
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.5208333333333393 18
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.729166666666675 26
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 1.2500000000000142 38
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.45833333333335 50
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 1.9791666666666892 63
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.5000000000000284 76
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.6041666666666963 85
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.6041666666666963 102
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcfd0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2f98> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.5208333333333393 9
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.6250000000000071 19
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.8333333333333428 27
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 1.354166666666682 39
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.5625000000000178 51
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 2.083333333333357 64
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.6041666666666963 77
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.708333333333364 86
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.708333333333364 103
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.5208333333333393 10
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.6250000000000071 20
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.8333333333333428 28
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 1.354166666666682 40
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.5625000000000178 52
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 2.083333333333357 65
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.6041666666666963 78
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.708333333333364 87
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.708333333333364 104
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.5208333333333393 11
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.6250000000000071 21
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.8333333333333428 29
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 1.354166666666682 41
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.5625000000000178 53
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 2.083333333333357 66
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.6041666666666963 79
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.708333333333364 88
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.708333333333364 105
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.5208333333333393 12
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.6250000000000071 22
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.8333333333333428 30
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 1.354166666666682 42
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.5625000000000178 54
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 2.083333333333357 67
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.6041666666666963 80
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.708333333333364 89
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.708333333333364 106
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.5208333333333393 13
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.6250000000000071 23
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.8333333333333428 31
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 1.354166666666682 43
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 1.5625000000000178 55
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 2.083333333333357 68
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763eb8> 2.6041666666666963 81
backprop <src.mcts.MCTS_Node object at 0x7f4fa47749e8> 2.708333333333364 90
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 2.708333333333364 107
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #8
root->7->16->2->2->0->3->4->0
Best Reward: 0.10416666666666785
iteration: 3
found coverage increase 0.10416666666666785
Current Total Coverage 25.729166666666664
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 25.729166666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907985f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798a20> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 25.729166666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 25.729166666666664
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0f0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 25.729166666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 25.729166666666664
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907044a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 25.729166666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907040f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c16a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 25.729166666666664
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907980f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907980f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907980f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907980f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 25.729166666666664
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef438> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 11
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 12
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 13
Completed Iteration #16
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 14
Completed Iteration #17
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.1041666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 15
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 16
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 17
Completed Iteration #21
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 18
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 19
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 20
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 21
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.1041666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 22
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.1041666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 23
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.1041666666666714 7
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 24
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.1041666666666714 8
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.1041666666666714 25
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90690630> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.2083333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.2083333333333428 26
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.2083333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.2083333333333428 27
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690630> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.2083333333333428 11
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.2083333333333428 28
Completed Iteration #16
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.2083333333333428 12
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.2083333333333428 29
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.3125000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.3125000000000142 30
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.3125000000000142 14
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.3125000000000142 31
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90679f28> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e828> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.4166666666666856 15
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.4166666666666856 32
Completed Iteration #21
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90686160> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.520833333333357 16
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.520833333333357 33
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.520833333333357 17
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.520833333333357 34
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #1
root->1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f906907b8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690588> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.6250000000000284 18
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.6250000000000284 35
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690d30> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.7291666666666998 19
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.7291666666666998 36
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90690e48> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e588> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.8333333333333712 20
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.8333333333333712 37
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e588> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 0.6250000000000284 8
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.8333333333333712 21
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.8333333333333712 38
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eb70> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ed68> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 0.7291666666666998 9
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 0.9375000000000426 22
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 0.9375000000000426 39
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907846d8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ed68> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 0.8333333333333712 10
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 1.041666666666714 23
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 1.041666666666714 40
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e10> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690d30> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 0.9375000000000426 11
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 1.1458333333333854 24
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 1.1458333333333854 41
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f503edd63c8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ed68> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 1.041666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 1.2500000000000568 25
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 1.2500000000000568 42
Completed Iteration #16
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec723588> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686160> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 1.1458333333333854 13
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 1.3541666666667282 26
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 1.3541666666667282 43
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fc400b908> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 1.2500000000000568 14
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 1.4583333333333997 27
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 1.4583333333333997 44
Completed Iteration #21
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 1.3541666666667282 15
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 1.562500000000071 28
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 1.562500000000071 45
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edd68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec710f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 1.3541666666667282 16
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 1.562500000000071 29
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 1.562500000000071 46
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #2
root->1->2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d62e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 1.4583333333333997 17
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 1.6666666666667425 30
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 1.6666666666667425 47
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 1.562500000000071 18
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 1.7708333333334139 31
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 1.7708333333334139 48
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f906797b8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679b00> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 1.6666666666667425 19
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 1.8750000000000853 32
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 1.8750000000000853 49
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90690b70> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec723588> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90686160> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 1.7708333333334139 20
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 1.9791666666667567 33
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 1.9791666666667567 50
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90686748> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 1.8750000000000853 21
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 2.083333333333428 34
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 2.083333333333428 51
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400b908> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 0.9375000000000426 11
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 1.8750000000000853 22
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 2.083333333333428 35
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 2.083333333333428 52
Completed Iteration #10
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90798f60> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798ef0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d62e8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 1.041666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 1.9791666666667567 23
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 2.1875000000000995 36
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 2.1875000000000995 53
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 1.1458333333333854 13
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 2.083333333333428 24
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 2.291666666666771 37
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 2.291666666666771 54
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a0f0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 1.2500000000000568 14
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 2.1875000000000995 25
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 2.3958333333334423 38
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 2.3958333333334423 55
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90679f60> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 1.3541666666667282 15
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 2.291666666666771 26
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 2.5000000000001137 39
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 2.5000000000001137 56
Completed Iteration #16
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f9071aeb8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686128> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686748> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 1.4583333333333997 16
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 2.3958333333334423 27
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 2.604166666666785 40
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 2.604166666666785 57
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e208> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 1.562500000000071 17
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 2.5000000000001137 28
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 2.7083333333334565 41
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 2.7083333333334565 58
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e550> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ebe0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 1.6666666666667425 18
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 2.604166666666785 29
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 2.812500000000128 42
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 2.812500000000128 59
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #3
root->1->2->8
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90679c50> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 1.7708333333334139 19
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 2.7083333333334565 30
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 2.9166666666667993 43
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 2.9166666666667993 60
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90798e48> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679b00> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 1.8750000000000853 20
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 2.812500000000128 31
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.0208333333334707 44
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.0208333333334707 61
Completed Iteration #3
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907982e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 1.9791666666667567 21
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 2.9166666666667993 32
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.125000000000142 45
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.125000000000142 62
Completed Iteration #4
Best Reward: 0.1041666666666714
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.6250000000000284 8
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 1.9791666666667567 22
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 2.9166666666667993 33
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.125000000000142 46
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.125000000000142 63
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679b00> 0.2083333333333428 4
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.6250000000000284 9
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 1.9791666666667567 23
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 2.9166666666667993 34
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.125000000000142 47
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.125000000000142 64
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ee80> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bf98> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.7291666666666998 10
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.083333333333428 24
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.0208333333334707 35
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.2291666666668135 48
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.2291666666668135 65
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90798f28> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.8333333333333712 11
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.1875000000000995 25
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.125000000000142 36
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.333333333333485 49
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.333333333333485 66
Completed Iteration #11
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f906c18d0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c15f8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.9375000000000426 12
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.291666666666771 26
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.2291666666668135 37
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.4375000000001563 50
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.4375000000001563 67
Completed Iteration #12
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f906c16d8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1a20> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.041666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.3958333333334423 27
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.333333333333485 38
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.5416666666668277 51
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.5416666666668277 68
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90784e48> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bf98> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.1458333333333854 14
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.5000000000001137 28
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.4375000000001563 39
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.645833333333499 52
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.645833333333499 69
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bf98> 0.2083333333333428 4
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.1458333333333854 15
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.5000000000001137 29
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.4375000000001563 40
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.645833333333499 53
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.645833333333499 70
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.2500000000000568 16
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.604166666666785 30
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.5416666666668277 41
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.7500000000001705 54
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.7500000000001705 71
Completed Iteration #18
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edd66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1a20> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.2500000000000568 17
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.604166666666785 31
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.5416666666668277 42
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.7500000000001705 55
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.7500000000001705 72
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e0f0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ecf8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c16d8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1a20> 0.2083333333333428 4
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.3541666666667282 18
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.7083333333334565 32
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.645833333333499 43
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.854166666666842 56
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.854166666666842 73
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679b00> 0.2083333333333428 5
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.3541666666667282 19
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.7083333333334565 33
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.645833333333499 44
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.854166666666842 57
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.854166666666842 74
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #4
root->1->2->8->0
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec723240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798f28> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 0.520833333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.3541666666667282 20
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.7083333333334565 34
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.645833333333499 45
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.854166666666842 58
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.854166666666842 75
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1080> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1c50> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e208> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 0.6250000000000284 8
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.4583333333333997 21
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.812500000000128 35
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.7500000000001705 46
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 3.9583333333335133 59
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 3.9583333333335133 76
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab208> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 0.7291666666666998 9
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.562500000000071 22
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 2.9166666666667993 36
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.854166666666842 47
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 4.062500000000185 60
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 4.062500000000185 77
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907abe80> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 0.8333333333333712 10
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.6666666666667425 23
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 3.0208333333334707 37
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 3.9583333333335133 48
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 4.166666666666856 61
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 4.166666666666856 78
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab4a8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 0.9375000000000426 11
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.7708333333334139 24
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 3.125000000000142 38
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 4.062500000000185 49
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 4.2708333333335275 62
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 4.2708333333335275 79
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d160> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 1.041666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.8750000000000853 25
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 3.2291666666668135 39
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 4.166666666666856 50
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 4.375000000000199 63
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 4.375000000000199 80
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907efcc0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef898> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab208> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 1.1458333333333854 13
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 1.9791666666667567 26
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 3.333333333333485 40
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 4.2708333333335275 51
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 4.47916666666687 64
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 4.47916666666687 81
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 1.2500000000000568 14
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 2.083333333333428 27
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 3.4375000000001563 41
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 4.375000000000199 52
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 4.583333333333542 65
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 4.583333333333542 82
Completed Iteration #17
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef908> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2b38> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d160> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 1.3541666666667282 15
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 2.1875000000000995 28
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 3.5416666666668277 42
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 4.47916666666687 53
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 4.687500000000213 66
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 4.687500000000213 83
Completed Iteration #18
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f90798320> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686828> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 1.4583333333333997 16
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 2.291666666666771 29
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 3.645833333333499 43
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 4.583333333333542 54
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 4.791666666666885 67
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 4.791666666666885 84
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2400> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 1.4583333333333997 17
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 2.291666666666771 30
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 3.645833333333499 44
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 4.583333333333542 55
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 4.791666666666885 68
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 4.791666666666885 85
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907abcc0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abba8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abe80> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 1.562500000000071 18
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 2.3958333333334423 31
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 3.7500000000001705 45
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 4.687500000000213 56
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 4.895833333333556 69
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 4.895833333333556 86
Completed Iteration #21
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef710> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 1.6666666666667425 19
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 2.5000000000001137 32
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 3.854166666666842 46
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 4.791666666666885 57
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 5.000000000000227 70
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 5.000000000000227 87
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef828> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686828> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 1.7708333333334139 20
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 2.604166666666785 33
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 3.9583333333335133 47
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 4.895833333333556 58
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 5.104166666666899 71
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 5.104166666666899 88
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d860> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 1.8750000000000853 21
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 2.7083333333334565 34
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 4.062500000000185 48
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 5.000000000000227 59
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 5.20833333333357 72
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 5.20833333333357 89
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1668> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1518> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1080> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1c50> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e208> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 1.9791666666667567 22
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 2.812500000000128 35
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 4.166666666666856 49
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 5.104166666666899 60
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 5.312500000000242 73
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 5.312500000000242 90
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #5
root->1->2->8->0->2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab978> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c23c8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 2.083333333333428 23
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 2.9166666666667993 36
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 4.2708333333335275 50
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 5.20833333333357 61
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 5.416666666666913 74
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 5.416666666666913 91
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2cf8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c23c8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 2.1875000000000995 24
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 3.0208333333334707 37
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 4.375000000000199 51
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 5.312500000000242 62
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 5.520833333333584 75
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 5.520833333333584 92
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcf60> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c23c8> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 2.291666666666771 25
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 3.125000000000142 38
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 4.47916666666687 52
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 5.416666666666913 63
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 5.625000000000256 76
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 5.625000000000256 93
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f906792e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c23c8> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 2.3958333333334423 26
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 3.2291666666668135 39
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 4.583333333333542 53
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 5.520833333333584 64
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 5.729166666666927 77
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 5.729166666666927 94
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6208> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a1d0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2cf8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c23c8> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 2.5000000000001137 27
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 3.333333333333485 40
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 4.687500000000213 54
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 5.625000000000256 65
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 5.833333333333599 78
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 5.833333333333599 95
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907aba90> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abb00> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab978> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c23c8> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 2.604166666666785 28
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 3.4375000000001563 41
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 4.791666666666885 55
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 5.729166666666927 66
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 5.93750000000027 79
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 5.93750000000027 96
Completed Iteration #10
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1eb8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efa20> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcf60> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c23c8> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 2.7083333333334565 29
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 3.5416666666668277 42
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 4.895833333333556 56
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 5.833333333333599 67
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 6.041666666666941 80
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 6.041666666666941 97
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c23c8> 0.7291666666666998 9
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 1.041666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 2.7083333333334565 30
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 3.5416666666668277 43
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 4.895833333333556 57
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 5.833333333333599 68
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 6.041666666666941 81
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 6.041666666666941 98
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 1.1458333333333854 13
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 2.812500000000128 31
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 3.645833333333499 44
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 5.000000000000227 58
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 5.93750000000027 69
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 6.145833333333613 82
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 6.145833333333613 99
Completed Iteration #16
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc5c0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686828> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 1.2500000000000568 14
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 2.9166666666667993 32
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 3.7500000000001705 45
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 5.104166666666899 59
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 6.041666666666941 70
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 6.250000000000284 83
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 6.250000000000284 100
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc940> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc668> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 1.3541666666667282 15
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 3.0208333333334707 33
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 3.854166666666842 46
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 5.20833333333357 60
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 6.145833333333613 71
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 6.354166666666956 84
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 6.354166666666956 101
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907bacf8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 1.4583333333333997 16
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 3.125000000000142 34
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 3.9583333333335133 47
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 5.312500000000242 61
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 6.250000000000284 72
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 6.458333333333627 85
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 6.458333333333627 102
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907aba90> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907abb00> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab978> 0.2083333333333428 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907c23c8> 0.7291666666666998 10
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 1.4583333333333997 17
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 3.125000000000142 35
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 3.9583333333335133 48
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 5.312500000000242 62
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 6.250000000000284 73
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 6.458333333333627 86
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 6.458333333333627 103
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d61d0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784c88> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 1.562500000000071 18
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 3.2291666666668135 36
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 4.062500000000185 49
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 5.416666666666913 63
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 6.354166666666956 74
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 6.562500000000298 87
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 6.562500000000298 104
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #6
root->1->2->8->0->2->3
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907efe10> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 1.6666666666667425 19
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 3.333333333333485 37
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 4.166666666666856 50
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 5.520833333333584 64
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 6.458333333333627 75
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 6.66666666666697 88
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 6.66666666666697 105
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d710> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2128> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 1.7708333333334139 20
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 3.4375000000001563 38
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 4.2708333333335275 51
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 5.625000000000256 65
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 6.562500000000298 76
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 6.770833333333641 89
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 6.770833333333641 106
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc358> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 1.8750000000000853 21
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 3.5416666666668277 39
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 4.375000000000199 52
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 5.729166666666927 66
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 6.66666666666697 77
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 6.875000000000313 90
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 6.875000000000313 107
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907baf60> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907baa20> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bacf8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 1.9791666666667567 22
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 3.645833333333499 40
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 4.47916666666687 53
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 5.833333333333599 67
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 6.770833333333641 78
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 6.979166666666984 91
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 6.979166666666984 108
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba5c0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba358> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc358> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 2.083333333333428 23
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 3.7500000000001705 41
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 4.583333333333542 54
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 5.93750000000027 68
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 6.875000000000313 79
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 7.0833333333336554 92
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 7.0833333333336554 109
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646240> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646828> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bacf8> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 2.1875000000000995 24
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 3.854166666666842 42
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 4.687500000000213 55
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 6.041666666666941 69
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 6.979166666666984 80
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 7.187500000000327 93
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 7.187500000000327 110
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa46462b0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 2.291666666666771 25
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 3.9583333333335133 43
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 4.791666666666885 56
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 6.145833333333613 70
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 7.0833333333336554 81
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 7.291666666666998 94
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 7.291666666666998 111
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 1.041666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 2.291666666666771 26
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 3.9583333333335133 44
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 4.791666666666885 57
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 6.145833333333613 71
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 7.0833333333336554 82
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 7.291666666666998 95
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 7.291666666666998 112
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef9b0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1d30> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efe10> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 1.1458333333333854 13
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 2.3958333333334423 27
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 4.062500000000185 45
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 4.895833333333556 58
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 6.250000000000284 72
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 7.187500000000327 83
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 7.39583333333367 96
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 7.39583333333367 113
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1d30> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907efe10> 0.2083333333333428 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 1.1458333333333854 14
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 2.3958333333334423 28
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 4.062500000000185 46
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 4.895833333333556 59
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 6.250000000000284 73
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 7.187500000000327 84
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 7.39583333333367 97
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 7.39583333333367 114
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc1d0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 1.2500000000000568 15
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 2.5000000000001137 29
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 4.166666666666856 47
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 5.000000000000227 60
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 6.354166666666956 74
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 7.291666666666998 85
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 7.500000000000341 98
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 7.500000000000341 115
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f907c27b8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2128> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 1.3541666666667282 16
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 2.604166666666785 30
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 4.2708333333335275 48
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 5.104166666666899 61
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 6.458333333333627 75
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 7.39583333333367 86
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 7.6041666666670125 99
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 7.6041666666670125 116
Completed Iteration #21
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646a20> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646c88> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efe10> 0.3125000000000142 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 1.4583333333333997 17
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 2.7083333333334565 31
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 4.375000000000199 49
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 5.20833333333357 62
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 6.562500000000298 76
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 7.500000000000341 87
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 7.708333333333684 100
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 7.708333333333684 117
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f860> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 1.562500000000071 18
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 2.812500000000128 32
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 4.47916666666687 50
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 5.312500000000242 63
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 6.66666666666697 77
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 7.6041666666670125 88
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 7.812500000000355 101
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 7.812500000000355 118
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #7
root->1->2->8->0->2->3->0
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f128> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f2e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 1.6666666666667425 19
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 2.9166666666667993 33
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 4.583333333333542 51
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 5.416666666666913 64
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 6.770833333333641 78
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 7.708333333333684 89
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 7.916666666667027 102
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 7.916666666667027 119
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa463eef0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463efd0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 1.7708333333334139 20
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 3.0208333333334707 34
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 4.687500000000213 52
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 5.520833333333584 65
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 6.875000000000313 79
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 7.812500000000355 90
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 8.020833333333698 103
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 8.020833333333698 120
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
coverage_call_count 700
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4f906c12e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463efd0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 1.8750000000000853 21
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 3.125000000000142 35
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 4.791666666666885 53
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 5.625000000000256 66
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 6.979166666666984 80
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 7.916666666667027 91
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 8.12500000000037 104
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 8.12500000000037 121
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa46465f8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2cc0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 1.9791666666667567 22
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 3.2291666666668135 36
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 4.895833333333556 54
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 5.729166666666927 67
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 7.0833333333336554 81
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 8.020833333333698 92
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 8.22916666666704 105
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 8.22916666666704 122
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f0f0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463efd0> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 2.083333333333428 23
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 3.333333333333485 37
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 5.000000000000227 55
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 5.833333333333599 68
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 7.187500000000327 82
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 8.12500000000037 93
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 8.333333333333712 106
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 8.333333333333712 123
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646898> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e320> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46465f8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2cc0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 2.1875000000000995 24
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 3.4375000000001563 38
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 5.104166666666899 56
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 5.93750000000027 69
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 7.291666666666998 83
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 8.22916666666704 94
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 8.437500000000384 107
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 8.437500000000384 124
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e7b8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463efd0> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 2.291666666666771 25
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 3.5416666666668277 39
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 5.20833333333357 57
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 6.041666666666941 70
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 7.39583333333367 84
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 8.333333333333712 95
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 8.541666666667055 108
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 8.541666666667055 125
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee278> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2cc0> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 2.3958333333334423 26
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 3.645833333333499 40
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 5.312500000000242 58
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 6.145833333333613 71
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 7.500000000000341 85
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 8.437500000000384 96
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 8.645833333333727 109
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 8.645833333333727 126
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eec50> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 2.5000000000001137 27
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 3.7500000000001705 41
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 5.416666666666913 59
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 6.250000000000284 72
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 7.6041666666670125 86
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 8.541666666667055 97
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 8.750000000000398 110
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 8.750000000000398 127
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f5f8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2cc0> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 2.604166666666785 28
backprop <src.mcts.MCTS_Node object at 0x7f4f90784780> 3.854166666666842 42
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a2b0> 5.520833333333584 60
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 6.354166666666956 73
backprop <src.mcts.MCTS_Node object at 0x7f4f90679748> 7.708333333333684 87
backprop <src.mcts.MCTS_Node object at 0x7f4f90679400> 8.645833333333727 98
backprop <src.mcts.MCTS_Node object at 0x7f4f907849e8> 8.85416666666707 111
backprop <src.mcts.MCTS_Node object at 0x7f4f907044e0> 8.85416666666707 128
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #8
root->1->2->8->0->2->3->0->3
Best Reward: 0.1041666666666714
iteration: 12
found coverage increase 0.1041666666666714
Current Total Coverage 25.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc8d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f940> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb160> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d978> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47265c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47266d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47266d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ee10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ee10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6908> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.10416666666666785 11
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.10416666666666785 12
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.2083333333333357 13
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.2083333333333357 14
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.2083333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.2083333333333357 15
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.2083333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.2083333333333357 16
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.2083333333333357 17
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.2083333333333357 18
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.2083333333333357 19
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.2083333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.2083333333333357 20
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f90704e10> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6908> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.31250000000000355 9
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.31250000000000355 21
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.31250000000000355 10
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.31250000000000355 22
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.31250000000000355 11
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.31250000000000355 23
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb400> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.4166666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.4166666666666714 24
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35908> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35588> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6908> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.5208333333333393 13
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.5208333333333393 25
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35f28> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e668> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.6250000000000071 14
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.6250000000000071 26
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee82b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.729166666666675 15
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.729166666666675 27
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee86d8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.8333333333333428 16
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.8333333333333428 28
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.9375000000000107 17
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.9375000000000107 29
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #1
root->1
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
coverage_call_count 1000
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef828> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 1.0416666666666785 18
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 1.0416666666666785 30
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8f98> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb400> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 1.1458333333333464 19
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 1.1458333333333464 31
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef048> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefdd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 1.2500000000000142 20
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 1.2500000000000142 32
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 1.354166666666682 21
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 1.354166666666682 33
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefdd8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 1.45833333333335 22
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 1.45833333333335 34
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abf60> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8f98> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb400> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 1.5625000000000178 23
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 1.5625000000000178 35
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee84e0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e668> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 1.6666666666666856 24
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 1.6666666666666856 36
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 1.7708333333333535 25
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 1.7708333333333535 37
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35b00> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb400> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 1.5625000000000178 16
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 1.8750000000000213 26
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 1.8750000000000213 38
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35e48> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35c88> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 1.6666666666666856 17
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 1.9791666666666892 27
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 1.9791666666666892 39
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefda0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35e48> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35c88> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 1.7708333333333535 18
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 2.083333333333357 28
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 2.083333333333357 40
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeeff28> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefc88> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 1.8750000000000213 19
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 2.187500000000025 29
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 2.187500000000025 41
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefc88> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 1.9791666666666892 20
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 2.2916666666666927 30
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 2.2916666666666927 42
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #2
root->1->19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 2.083333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 2.3958333333333606 31
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 2.3958333333333606 43
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 2.187500000000025 22
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 2.5000000000000284 32
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 2.5000000000000284 44
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35d68> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 2.2916666666666927 23
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 2.6041666666666963 33
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 2.6041666666666963 45
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96470> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 2.3958333333333606 24
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 2.708333333333364 34
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 2.708333333333364 46
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96b38> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96ba8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee82b0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 2.5000000000000284 25
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 2.812500000000032 35
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 2.812500000000032 47
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1278> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 2.6041666666666963 26
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 2.9166666666667 36
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 2.9166666666667 48
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbb70> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 2.708333333333364 27
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 3.0208333333333677 37
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 3.0208333333333677 49
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 2.812500000000032 28
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 3.1250000000000355 38
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 3.1250000000000355 50
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8518> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef98d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35d68> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 1.5625000000000178 16
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 2.9166666666667 29
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 3.2291666666667034 39
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 3.2291666666667034 51
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a90> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47745c0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1278> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 1.6666666666666856 17
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 3.0208333333333677 30
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 3.3333333333333712 40
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 3.3333333333333712 52
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8e48> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef359b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96470> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 1.7708333333333535 18
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 3.1250000000000355 31
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 3.437500000000039 41
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 3.437500000000039 53
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #3
root->1->19->2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef940> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 1.8750000000000213 19
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 3.2291666666667034 32
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 3.541666666666707 42
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 3.541666666666707 54
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96550> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 1.9791666666666892 20
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 3.3333333333333712 33
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 3.645833333333375 43
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 3.645833333333375 55
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96da0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96e10> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 2.083333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 3.437500000000039 34
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 3.7500000000000426 44
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 3.7500000000000426 56
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef95f8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96e10> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 2.187500000000025 22
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 3.541666666666707 35
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 3.8541666666667105 45
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 3.8541666666667105 57
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea18d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea16d8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 2.2916666666666927 23
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 3.645833333333375 36
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 3.9583333333333783 46
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 3.9583333333333783 58
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1c88> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef940> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 2.3958333333333606 24
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 3.7500000000000426 37
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 4.062500000000046 47
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 4.062500000000046 59
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 2.5000000000000284 25
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 3.8541666666667105 38
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 4.166666666666714 48
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 4.166666666666714 60
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f907c29e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef940> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 2.6041666666666963 26
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 3.9583333333333783 39
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 4.270833333333382 49
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 4.270833333333382 61
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee82e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8b38> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 2.708333333333364 27
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 4.062500000000046 40
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 4.37500000000005 50
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 4.37500000000005 62
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee966a0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8b38> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 2.812500000000032 28
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 4.166666666666714 41
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 4.479166666666718 51
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 4.479166666666718 63
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35080> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 2.9166666666667 29
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 4.270833333333382 42
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 4.583333333333385 52
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 4.583333333333385 64
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96208> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8b38> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 1.5625000000000178 16
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 3.0208333333333677 30
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 4.37500000000005 43
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 4.687500000000053 53
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 4.687500000000053 65
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8240> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1eb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96da0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96e10> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 1.6666666666666856 17
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 3.1250000000000355 31
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 4.479166666666718 44
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 4.791666666666721 54
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 4.791666666666721 66
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #4
root->1->19->2->17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8a90> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 1.7708333333333535 18
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 3.2291666666667034 32
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 4.583333333333385 45
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 4.895833333333389 55
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 4.895833333333389 67
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8eb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 1.8750000000000213 19
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 3.3333333333333712 33
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 4.687500000000053 46
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 5.000000000000057 56
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 5.000000000000057 68
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bbe0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b978> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8eb8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 1.9791666666666892 20
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 3.437500000000039 34
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 4.791666666666721 47
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 5.104166666666725 57
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 5.104166666666725 69
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b828> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 2.083333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 3.541666666666707 35
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 4.895833333333389 48
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 5.2083333333333925 58
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 5.2083333333333925 70
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b978> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8eb8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 2.187500000000025 22
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 3.645833333333375 36
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 5.000000000000057 49
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 5.31250000000006 59
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 5.31250000000006 71
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96668> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 2.2916666666666927 23
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 3.7500000000000426 37
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 5.104166666666725 50
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 5.416666666666728 60
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 5.416666666666728 72
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35748> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 2.3958333333333606 24
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 3.8541666666667105 38
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 5.2083333333333925 51
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 5.520833333333396 61
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 5.520833333333396 73
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1518> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8198> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96668> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 2.5000000000000284 25
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 3.9583333333333783 39
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 5.31250000000006 52
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 5.625000000000064 62
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 5.625000000000064 74
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #5
root->1->19->2->17->4
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 2.6041666666666963 26
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 4.062500000000046 40
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 5.416666666666728 53
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 5.729166666666732 63
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 5.729166666666732 75
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
coverage_call_count 1100
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56e48> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8a90> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8898> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 2.708333333333364 27
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 4.166666666666714 41
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 5.520833333333396 54
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 5.8333333333334 64
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 5.8333333333334 76
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bda0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8ef0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 1.5625000000000178 16
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 2.812500000000032 28
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 4.270833333333382 42
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 5.625000000000064 55
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 5.9375000000000675 65
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 5.9375000000000675 77
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77da0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 1.6666666666666856 17
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 2.9166666666667 29
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 4.37500000000005 43
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 5.729166666666732 56
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 6.041666666666735 66
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 6.041666666666735 78
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77a20> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb048> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 1.7708333333333535 18
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 3.0208333333333677 30
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 4.479166666666718 44
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 5.8333333333334 57
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 6.145833333333403 67
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 6.145833333333403 79
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #6
root->1->19->2->17->4->14
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8fd0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 1.8750000000000213 19
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 3.1250000000000355 31
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 4.583333333333385 45
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 5.9375000000000675 58
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 6.250000000000071 68
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 6.250000000000071 80
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56f60> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 1.9791666666666892 20
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 3.2291666666667034 32
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 4.687500000000053 46
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 6.041666666666735 59
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 6.354166666666739 69
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 6.354166666666739 81
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea15c0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 2.083333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 3.3333333333333712 33
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 4.791666666666721 47
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 6.145833333333403 60
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 6.458333333333407 70
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 6.458333333333407 82
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb470> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77da0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 2.187500000000025 22
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 3.437500000000039 34
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 4.895833333333389 48
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 6.250000000000071 61
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 6.562500000000075 71
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 6.562500000000075 83
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 2.2916666666666927 23
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 3.541666666666707 35
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 5.000000000000057 49
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 6.354166666666739 62
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 6.6666666666667425 72
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 6.6666666666667425 84
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee771d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee773c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8fd0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 1.5625000000000178 16
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 2.3958333333333606 24
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 3.645833333333375 36
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 5.104166666666725 50
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 6.458333333333407 63
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 6.77083333333341 73
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 6.77083333333341 85
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbb70> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 1.6666666666666856 17
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 2.5000000000000284 25
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 3.7500000000000426 37
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 5.2083333333333925 51
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 6.562500000000075 64
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 6.875000000000078 74
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 6.875000000000078 86
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56390> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 1.7708333333333535 18
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 2.6041666666666963 26
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 3.8541666666667105 38
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 5.31250000000006 52
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 6.6666666666667425 65
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 6.979166666666746 75
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 6.979166666666746 87
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ab38> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 1.8750000000000213 19
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 2.708333333333364 27
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 3.9583333333333783 39
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 5.416666666666728 53
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 6.77083333333341 66
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 7.083333333333414 76
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 7.083333333333414 88
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee774a8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8fd0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 1.9791666666666892 20
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 2.812500000000032 28
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 4.062500000000046 40
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 5.520833333333396 54
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 6.875000000000078 67
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 7.187500000000082 77
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 7.187500000000082 89
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #7
root->1->19->2->17->4->14->3
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56ac8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee774a8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35438> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8fd0> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 2.083333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 2.9166666666667 29
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 4.166666666666714 41
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 5.625000000000064 55
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 6.979166666666746 68
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 7.29166666666675 78
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 7.29166666666675 90
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee568d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1d30> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee774a8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35438> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8fd0> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 1.5625000000000178 16
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 2.187500000000025 22
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 3.0208333333333677 30
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 4.270833333333382 42
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 5.729166666666732 56
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 7.083333333333414 69
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 7.395833333333417 79
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 7.395833333333417 91
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a240> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35438> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8fd0> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 1.6666666666666856 17
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 2.2916666666666927 23
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 3.1250000000000355 31
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 4.37500000000005 43
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 5.8333333333334 57
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 7.187500000000082 70
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 7.500000000000085 80
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 7.500000000000085 92
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1300f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11af28> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8fd0> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 1.7708333333333535 18
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 2.3958333333333606 24
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 3.2291666666667034 32
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 4.479166666666718 44
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 5.9375000000000675 58
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 7.29166666666675 71
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 7.604166666666753 81
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 7.604166666666753 93
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130c88> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130cf8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8fd0> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 1.8750000000000213 19
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 2.5000000000000284 25
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 3.3333333333333712 33
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 4.583333333333385 45
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 6.041666666666735 59
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 7.395833333333417 72
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 7.708333333333421 82
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 7.708333333333421 94
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138240> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee773c8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8fd0> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 1.9791666666666892 20
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 2.6041666666666963 26
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 3.437500000000039 34
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 4.687500000000053 46
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 6.145833333333403 60
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 7.500000000000085 73
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 7.812500000000089 83
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 7.812500000000089 95
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138748> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8320> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8fd0> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 2.083333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 2.708333333333364 27
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 3.541666666666707 35
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 4.791666666666721 47
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 6.250000000000071 61
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 7.604166666666753 74
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 7.916666666666757 84
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 7.916666666666757 96
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56dd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb828> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8fd0> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 2.187500000000025 22
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 2.812500000000032 28
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 3.645833333333375 36
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 4.895833333333389 48
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 6.354166666666739 62
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726550> 7.708333333333421 75
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 8.020833333333425 85
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 8.020833333333425 97
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #8
root->1->19->2->17->4->14->3->10
Best Reward: 0.10416666666666785
iteration: 22
found coverage increase 0.10416666666666785
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1387f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1301d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1302b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1389b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 1200
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d54e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0850f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1382b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1387f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1387f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1387f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ece48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0409e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068fd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee772e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b60f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b60f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a61d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0856d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1382b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0856d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1300b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0728d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0722e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0722e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0722b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0985f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0342b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0985c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0985c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e44a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0723c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0720f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0720f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0347b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0986a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c75c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 25.937500000000004
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edcf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee965f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee963c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeeffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeeffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 19
Completed Iteration #21
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef0b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473da20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d780> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeeffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeeffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeeffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeeffd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47176d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47176d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 16
Completed Iteration #18
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd30> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47745f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47745f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef96d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee87f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f5f8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee4a8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47745f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec710e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb86a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc4061f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec7d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec710ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec723320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec723208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec7234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400be80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edc1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400be80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba90> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edd69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f503edd6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edc1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc4076748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907baf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dfdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec723128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9588> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 2100
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906792e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec710f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec723080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f390> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907efa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec723128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec710f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46460b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46460b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec710f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd68> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcd30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907982e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1387f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1382e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1382e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907985f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 3
Completed Iteration #3
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc40767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907985f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc40767b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907982e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907985f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907985f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085cc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 25.937500000000004
coverage_call_count 2400
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec7d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e48d0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec710f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0342b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7e80> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1179b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 2500
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec7d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11aba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11aba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11aba8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6080> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b68d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0985c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0985c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0985c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 25.937500000000004
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec7d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0723c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0723c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0727f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0726a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0344e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0682e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 2700
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907842b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906797b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906797b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1386a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec723160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec723320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec723320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1386a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6160> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc4056358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc4056358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc4056358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edd6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc4056470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 18
Completed Iteration #20
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1387b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec7230b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec7230b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1387b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1387b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90784358> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47264a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47633c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edc1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee968d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc4056358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc4056470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef352b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef352b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef352b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 3100
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8fd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907984a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907984a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cf28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c198> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc4056358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907846a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 3200
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906864e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0683c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034c18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098240> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee779b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b64a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c76d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0726d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee771d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee771d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee566d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47744a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56cc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907983c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1179b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907c29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47744a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0819b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0811d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0819b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0987b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0eceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac18> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34feff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34feff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34feff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ffffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ffff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ffff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ffff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ffff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34facf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34faccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34faccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95fd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ffff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34face80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34facda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34facfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f040f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcd30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f045c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f045c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34facac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f045c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34faceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34facfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34facfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34facfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34facfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb70> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eddc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eddeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edda58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f153c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f153c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eeca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eeca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eeca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 17
Completed Iteration #16
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eeca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e542e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e542b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e542b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e542b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34facc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eaba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eaba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eaba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb75f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab2b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab9e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e090b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e091d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e094e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 4000
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e330b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e094e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e337b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e331d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e094e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c25f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c25f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e336d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e330b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e330b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e637b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e637b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 4100
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d47f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e095c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349aff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e094a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349645f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349718d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349646a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349afeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90704128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971240> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971240> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34905400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eeca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb76a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb76a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb76a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f153c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f040f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 4300
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34facef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34face10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34facac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34faca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34facef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34faca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907baa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907baa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34faceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349715f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eeca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3358> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ef28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34faceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90784080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90690f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eeceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fc400ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77cc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee563c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee563c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eeceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349717b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee563c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34f159e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90686240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90798e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90798a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907986d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907986d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907986d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 4600
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dfd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee80f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f034a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9b00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349717f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349717f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349717f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0725f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b278> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f72e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90784080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 4700
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34face48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726c50> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46eec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edd6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906794e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 13
Completed Iteration #18
Best Reward: 0
coverage_call_count 4800
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edc1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906794e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349642b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9a20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349647b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349647b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4646c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90679f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349646a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349646a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffe80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec723320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec723128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ffff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edc1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeefb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349646a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349646a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f751d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 7
Completed Iteration #11
Best Reward: 0
coverage_call_count 5100
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e338d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e338d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4717780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f751d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75588> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0400b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349642b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aeb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e547b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349054a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349057f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63dd8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e542e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e542e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e542e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34905828> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0400b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0400b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e546a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e541d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f756a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34feff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f756a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f756a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f756a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f756a0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402ff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbfff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbfff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbfff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba65c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba65c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba65c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 5300
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbfff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcbd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e549b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e549b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e549b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb676a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb102e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb007b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 5400
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e549b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e549b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb677f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e549b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb108d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f34905be0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb679e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbfff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e632e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a828> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeae80> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafde80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ad68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa36d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa36d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4cdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c748> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 19
Completed Iteration #21
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5dcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa252e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa196a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa346d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa199b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbdd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19860> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa345f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa345f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa345f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5972e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34080> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.1041666666666643 5
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.1041666666666643 6
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.2083333333333286 7
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.2083333333333286 8
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.2083333333333286 9
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.2083333333333286 10
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.2083333333333286 11
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.2083333333333286 12
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.2083333333333286 13
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.2083333333333286 14
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.2083333333333286 15
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.2083333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.2083333333333286 16
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.2083333333333286 17
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.2083333333333286 18
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabae48> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3390> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.3124999999999929 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.3124999999999929 19
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.3124999999999929 7
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.3124999999999929 20
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19240> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.4166666666666572 8
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.4166666666666572 21
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9588> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.5208333333333215 9
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.5208333333333215 22
Completed Iteration #2
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.5208333333333215 10
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.5208333333333215 23
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34080> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.5208333333333215 11
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.5208333333333215 24
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.5208333333333215 12
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.5208333333333215 25
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.5208333333333215 13
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.5208333333333215 26
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.5208333333333215 14
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.5208333333333215 27
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.5208333333333215 15
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.5208333333333215 28
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5496d8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.6249999999999858 16
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.6249999999999858 29
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5496d8> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.6249999999999858 17
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.6249999999999858 30
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.6249999999999858 18
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.6249999999999858 31
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.6249999999999858 19
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.6249999999999858 32
Completed Iteration #14
Best Reward: 0.1041666666666643
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.6249999999999858 20
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.6249999999999858 33
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5495f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5496d8> 0.1041666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.6249999999999858 21
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.6249999999999858 34
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550358> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.7291666666666501 22
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.7291666666666501 35
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.7291666666666501 23
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.7291666666666501 36
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.7291666666666501 24
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.7291666666666501 37
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa190f0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.8333333333333144 25
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.8333333333333144 38
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.8333333333333144 26
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.8333333333333144 39
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 0.2083333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.8333333333333144 27
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.8333333333333144 40
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5499b0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549748> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 0.3124999999999929 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 0.9374999999999787 28
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 0.9374999999999787 41
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549048> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3390> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 0.4166666666666572 7
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.041666666666643 29
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.041666666666643 42
Completed Iteration #2
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549e80> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3390> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 0.5208333333333215 8
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.1458333333333073 30
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.1458333333333073 43
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19be0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3390> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 0.6249999999999858 9
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.2499999999999716 31
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.2499999999999716 44
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 0.7291666666666501 10
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.3541666666666359 32
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.3541666666666359 45
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 0.7291666666666501 11
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.3541666666666359 33
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.3541666666666359 46
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550d30> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 0.8333333333333144 12
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.4583333333333002 34
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.4583333333333002 47
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5660b8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549748> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 0.9374999999999787 13
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.5624999999999645 35
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.5624999999999645 48
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566400> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549748> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.041666666666643 14
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.6666666666666288 36
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.6666666666666288 49
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.041666666666643 15
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.6666666666666288 37
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.6666666666666288 50
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549e80> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3390> 0.4166666666666572 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.041666666666643 16
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.6666666666666288 38
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.6666666666666288 51
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566a58> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.1458333333333073 17
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.770833333333293 39
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.770833333333293 52
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566c18> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.2499999999999716 18
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.8749999999999574 40
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.8749999999999574 53
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566f28> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549748> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.3541666666666359 19
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.9791666666666217 41
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.9791666666666217 54
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.3541666666666359 20
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 1.9791666666666217 42
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 1.9791666666666217 55
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19908> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549748> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.4583333333333002 21
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.083333333333286 43
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.083333333333286 56
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5500f0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.5624999999999645 22
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.1874999999999503 44
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.1874999999999503 57
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566048> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3390> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.6666666666666288 23
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.2916666666666146 45
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.2916666666666146 58
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.6666666666666288 24
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.2916666666666146 46
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.2916666666666146 59
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #2
root->0->1
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550d30> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.6666666666666288 25
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.2916666666666146 47
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.2916666666666146 60
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566a58> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 0.5208333333333215 8
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.6666666666666288 26
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.2916666666666146 48
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.2916666666666146 61
Completed Iteration #2
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5701d0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 0.6249999999999858 9
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.770833333333293 27
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.395833333333279 49
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.395833333333279 62
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570748> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5707b8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566c18> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 0.7291666666666501 10
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.8749999999999574 28
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.499999999999943 50
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.499999999999943 63
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570f98> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570cc0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 0.8333333333333144 11
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.9791666666666217 29
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.6041666666666075 51
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.6041666666666075 64
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 0.8333333333333144 12
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 1.9791666666666217 30
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.6041666666666075 52
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.6041666666666075 65
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550f60> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 0.9374999999999787 13
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.083333333333286 31
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.7083333333332718 53
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.7083333333332718 66
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f50cd68> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.041666666666643 14
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.1874999999999503 32
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.812499999999936 54
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.812499999999936 67
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517278> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5172e8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550d30> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.1458333333333073 15
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.2916666666666146 33
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.9166666666666003 55
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.9166666666666003 68
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5500f0> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.1458333333333073 16
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.2916666666666146 34
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.9166666666666003 56
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.9166666666666003 69
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f50cd68> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.1458333333333073 17
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.2916666666666146 35
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 2.9166666666666003 57
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 2.9166666666666003 70
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570c50> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570cc0> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.2499999999999716 18
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.395833333333279 36
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.0208333333332646 58
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.0208333333332646 71
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #3
root->0->1->3
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.3124999999999929 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.2499999999999716 19
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.395833333333279 37
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.0208333333332646 59
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.0208333333332646 72
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.3124999999999929 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.2499999999999716 20
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.395833333333279 38
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.0208333333332646 60
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.0208333333332646 73
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570f98> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570cc0> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.3124999999999929 7
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.2499999999999716 21
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.395833333333279 39
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.0208333333332646 61
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.0208333333332646 74
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f50cac8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566358> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.4166666666666572 8
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.3541666666666359 22
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.499999999999943 40
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.124999999999929 62
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.124999999999929 75
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5175f8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.5208333333333215 9
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.4583333333333002 23
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.6041666666666075 41
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.2291666666665932 63
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.2291666666665932 76
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f50ca58> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.6249999999999858 10
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.5624999999999645 24
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.7083333333332718 42
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.3333333333332575 64
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.3333333333332575 77
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5179b0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f50cf60> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.7291666666666501 11
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.6666666666666288 25
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.812499999999936 43
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.437499999999922 65
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.437499999999922 78
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570cc0> 0.2083333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.7291666666666501 12
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.6666666666666288 26
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.812499999999936 44
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.437499999999922 66
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.437499999999922 79
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.7291666666666501 13
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.6666666666666288 27
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.812499999999936 45
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.437499999999922 67
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.437499999999922 80
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566358> 0.1041666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.7291666666666501 14
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.6666666666666288 28
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.812499999999936 46
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.437499999999922 68
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.437499999999922 81
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570208> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.8333333333333144 15
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.770833333333293 29
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 2.9166666666666003 47
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.541666666666586 69
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.541666666666586 82
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f50cbe0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.9374999999999787 16
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.8749999999999574 30
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 3.0208333333332646 48
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.6458333333332504 70
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.6458333333332504 83
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #4
root->0->1->3->3
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f50c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f50cbe0> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 0.4166666666666572 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 0.9374999999999787 17
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.8749999999999574 31
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 3.0208333333332646 49
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.6458333333332504 71
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.6458333333332504 84
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530358> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 1.041666666666643 18
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 1.9791666666666217 32
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 3.124999999999929 50
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.7499999999999147 72
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.7499999999999147 85
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 0.6249999999999858 8
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 1.1458333333333073 19
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 2.083333333333286 33
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 3.2291666666665932 51
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.854166666666579 73
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.854166666666579 86
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530c18> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 0.7291666666666501 9
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 1.2499999999999716 20
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 2.1874999999999503 34
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 3.3333333333332575 52
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 3.9583333333332433 74
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 3.9583333333332433 87
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530fd0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 1.3541666666666359 21
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 2.2916666666666146 35
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 3.437499999999922 53
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 4.062499999999908 75
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 4.062499999999908 88
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14e0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1320> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 1.4583333333333002 22
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 2.395833333333279 36
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 3.541666666666586 54
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 4.166666666666572 76
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 4.166666666666572 89
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530eb8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 1.041666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 1.5624999999999645 23
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 2.499999999999943 37
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 3.6458333333332504 55
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 4.270833333333236 77
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 4.270833333333236 90
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1978> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 1.1458333333333073 13
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 1.6666666666666288 24
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 2.6041666666666075 38
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 3.7499999999999147 56
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 4.3749999999999005 78
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 4.3749999999999005 91
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1cf8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 1.2499999999999716 14
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 1.770833333333293 25
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 2.7083333333332718 39
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 3.854166666666579 57
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 4.479166666666565 79
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 4.479166666666565 92
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
coverage_call_count 5900
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1cf8> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 1.2499999999999716 15
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 1.770833333333293 26
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 2.7083333333332718 40
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 3.854166666666579 58
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 4.479166666666565 80
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 4.479166666666565 93
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549b70> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530438> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530c18> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 1.3541666666666359 16
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 1.8749999999999574 27
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 2.812499999999936 41
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 3.9583333333332433 59
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 4.583333333333229 81
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 4.583333333333229 94
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c10b8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1be0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f50cbe0> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 1.4583333333333002 17
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 1.9791666666666217 28
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 2.9166666666666003 42
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.062499999999908 60
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 4.687499999999893 82
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 4.687499999999893 95
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #5
root->0->1->3->3->6
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1f98> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1320> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 1.5624999999999645 18
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 2.083333333333286 29
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.0208333333332646 43
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.166666666666572 61
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 4.791666666666558 83
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 4.791666666666558 96
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc8d0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 1.6666666666666288 19
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 2.1874999999999503 30
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.124999999999929 44
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.270833333333236 62
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 4.895833333333222 84
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 4.895833333333222 97
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 1.6666666666666288 20
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 2.1874999999999503 31
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.124999999999929 45
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.270833333333236 63
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 4.895833333333222 85
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 4.895833333333222 98
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6390> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 0.6249999999999858 8
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 1.770833333333293 21
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 2.2916666666666146 32
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.2291666666665932 46
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.3749999999999005 64
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 4.999999999999886 86
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 4.999999999999886 99
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1588> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcc18> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 0.7291666666666501 9
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 1.8749999999999574 22
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 2.395833333333279 33
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.3333333333332575 47
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.479166666666565 65
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 5.104166666666551 87
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 5.104166666666551 100
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6a58> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e62e8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1978> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 1.9791666666666217 23
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 2.499999999999943 34
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.437499999999922 48
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.583333333333229 66
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 5.208333333333215 88
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 5.208333333333215 101
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517f28> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcc18> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 2.083333333333286 24
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 2.6041666666666075 35
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.541666666666586 49
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.687499999999893 67
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 5.312499999999879 89
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 5.312499999999879 102
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530048> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcc18> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 1.041666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 2.1874999999999503 25
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 2.7083333333332718 36
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.6458333333332504 50
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.791666666666558 68
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 5.4166666666665435 90
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 5.4166666666665435 103
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc6d8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 1.1458333333333073 13
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 2.2916666666666146 26
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 2.812499999999936 37
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.7499999999999147 51
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.895833333333222 69
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 5.520833333333208 91
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 5.520833333333208 104
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 1.1458333333333073 14
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 2.2916666666666146 27
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 2.812499999999936 38
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.7499999999999147 52
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.895833333333222 70
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 5.520833333333208 92
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 5.520833333333208 105
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6518> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 0.6249999999999858 7
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 1.2499999999999716 15
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 2.395833333333279 28
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 2.9166666666666003 39
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.854166666666579 53
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.999999999999886 71
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 5.624999999999872 93
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 5.624999999999872 106
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #6
root->0->1->3->3->6->19
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc8d0> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 0.6249999999999858 8
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 1.2499999999999716 16
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 2.395833333333279 29
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 2.9166666666666003 40
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.854166666666579 54
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 4.999999999999886 72
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 5.624999999999872 94
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 5.624999999999872 107
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6c18> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480198> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6518> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 0.7291666666666501 9
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 1.3541666666666359 17
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 2.499999999999943 30
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 3.0208333333332646 41
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 3.9583333333332433 55
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 5.104166666666551 73
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 5.729166666666536 95
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 5.729166666666536 108
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480320> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 1.4583333333333002 18
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 2.6041666666666075 31
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 3.124999999999929 42
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 4.062499999999908 56
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 5.208333333333215 74
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 5.833333333333201 96
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 5.833333333333201 109
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b390> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 1.5624999999999645 19
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 2.7083333333332718 32
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 3.2291666666665932 43
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 4.166666666666572 57
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 5.312499999999879 75
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 5.937499999999865 97
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 5.937499999999865 110
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530f28> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.041666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 1.6666666666666288 20
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 2.812499999999936 33
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 3.3333333333332575 44
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 4.270833333333236 58
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 5.4166666666665435 76
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.041666666666529 98
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.041666666666529 111
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517908> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1eb8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480320> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.1458333333333073 13
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 1.770833333333293 21
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 2.9166666666666003 34
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 3.437499999999922 45
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 4.3749999999999005 59
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 5.520833333333208 77
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.145833333333194 99
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.145833333333194 112
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6438> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e63c8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530f28> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.2499999999999716 14
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 1.8749999999999574 22
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 3.0208333333332646 35
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 3.541666666666586 46
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 4.479166666666565 60
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 5.624999999999872 78
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.249999999999858 100
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.249999999999858 113
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dccf8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.3541666666666359 15
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 1.9791666666666217 23
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 3.124999999999929 36
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 3.6458333333332504 47
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 4.583333333333229 61
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 5.729166666666536 79
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.354166666666522 101
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.354166666666522 114
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #7
root->0->1->3->3->6->19->0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480518> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1eb8> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480320> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.4583333333333002 16
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 2.083333333333286 24
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 3.2291666666665932 37
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 3.7499999999999147 48
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 4.687499999999893 62
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 5.833333333333201 80
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.4583333333331865 102
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.4583333333331865 115
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480320> 0.3124999999999929 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.4583333333333002 17
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 2.083333333333286 25
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 3.2291666666665932 38
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 3.7499999999999147 49
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 4.687499999999893 63
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 5.833333333333201 81
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.4583333333331865 103
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.4583333333331865 116
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffc50> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b6d8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480320> 0.4166666666666572 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.5624999999999645 18
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 2.1874999999999503 26
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 3.3333333333332575 39
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 3.854166666666579 50
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 4.791666666666558 64
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 5.937499999999865 82
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.562499999999851 104
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.562499999999851 117
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff780> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffb70> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480320> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.6666666666666288 19
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 2.2916666666666146 27
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 3.437499999999922 40
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 3.9583333333332433 51
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 4.895833333333222 65
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 6.041666666666529 83
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.666666666666515 105
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.666666666666515 118
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b6d8> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480320> 0.5208333333333215 8
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.6666666666666288 20
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 2.2916666666666146 28
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 3.437499999999922 41
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 3.9583333333332433 52
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 4.895833333333222 66
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 6.041666666666529 84
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.666666666666515 106
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.666666666666515 119
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff5f8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffb70> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480320> 0.6249999999999858 9
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.770833333333293 21
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 2.395833333333279 29
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 3.541666666666586 42
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 4.062499999999908 53
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 4.999999999999886 67
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 6.145833333333194 85
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.770833333333179 107
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.770833333333179 120
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550a58> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffb70> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480320> 0.7291666666666501 10
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.8749999999999574 22
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 2.499999999999943 30
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 3.6458333333332504 43
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 4.166666666666572 54
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 5.104166666666551 68
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 6.249999999999858 86
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.874999999999844 108
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.874999999999844 121
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9072eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480320> 0.7291666666666501 11
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.8749999999999574 23
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 2.499999999999943 31
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 3.6458333333332504 44
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 4.166666666666572 55
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 5.104166666666551 69
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 6.249999999999858 87
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.874999999999844 109
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.874999999999844 122
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4802e8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffb70> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480320> 0.8333333333333144 12
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 1.9791666666666217 24
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 2.6041666666666075 32
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 3.7499999999999147 45
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 4.270833333333236 56
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 5.208333333333215 70
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 6.354166666666522 88
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 6.979166666666508 110
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 6.979166666666508 123
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5170f0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc860> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480320> 0.9374999999999787 13
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517d68> 2.083333333333286 25
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530860> 2.7083333333332718 33
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517390> 3.854166666666579 46
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5506d8> 4.3749999999999005 57
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5505c0> 5.312499999999879 71
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597a58> 6.4583333333331865 89
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3cf8> 7.083333333333172 111
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597128> 7.083333333333172 124
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #8
root->0->1->3->3->6->19->0->0
Best Reward: 0.1041666666666643
iteration: 202
found coverage increase 0.1041666666666643
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 6000
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e69e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5972e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4803c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5974e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa192b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f566a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa192b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa192b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edd65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fdac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f570630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f550b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d940> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f50c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5977b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 11
Completed Iteration #14
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa253c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa340b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa340b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa340b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafde48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafde48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa4c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa32b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa19e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f517e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 14
Completed Iteration #13
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa256a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fde80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f38d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f38d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5a9ac8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb003c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb109e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46abcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb109e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb10ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f480358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f50ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb004e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb67cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fabad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 6300
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f549dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa347f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa347f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34feff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6b00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f503edd66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fac5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f530710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5f3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f9074d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f5fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa348d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafda58> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fefa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb00e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e637f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faeab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fafdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb860> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb278> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33c88> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c5f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa34e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33dd8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eaba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec723160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed09b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed09b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed09b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbca20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c040240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c20f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9069ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c20f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f9069e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34964198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349d45c0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e63518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbb64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e090b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0fbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1ae48> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f75f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c1300f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34964d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9071a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa474b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46cb898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa47e9080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35208> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa25940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fec7d0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fb8a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeb8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ffff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2faa34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c130048> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463eb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463eb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa47dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0710> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90679b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 6700
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907984e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa473d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90798588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34ed0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c7507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6fd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eabda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fa5da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3498ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fc400bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3ed470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fba6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa463e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ef35198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6eeef898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee774a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa463ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee772b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee774a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e54a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c05bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec7d0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fec7d0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee779b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 21
Completed Iteration #23
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eee8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee774a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b66a0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0e43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0346a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f90690e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee1d0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e540b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e540b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e540b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4e3c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e540b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2fadb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eef92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c138668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f081898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa469f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0852b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34facbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34faca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907986a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34facef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee4b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34e33908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907986a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f044a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90704588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907ba438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f4f117710> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f906c19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f9075eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f906c10b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec438> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4763c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f098eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4726a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2fbcb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f4c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c085400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c11ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c72a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f597470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34faca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee56b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34faceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34faceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34edd3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f4f068eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34e09f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34faceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0680f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349aff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349aff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e7260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e7261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e7268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905d68> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e7264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349affd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349afb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349affd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349afb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c0d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48be80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fbcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa4774b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2f48b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f072b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349af160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f90686cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34faca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3402f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6eea1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34faca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34faca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee960f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3499ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f0b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee960f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34faca20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e7262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34faca20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34eec080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f95b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e7268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f4f1170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f15e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f34905860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6834e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6830f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6834e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6834e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6834e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6990b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6834e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1d68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6c068908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1cf8> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f349afa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34905160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6997f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6997f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6403c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f907bacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e61d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f349719b0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6405c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34facb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6407b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e7265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6637b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6637b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 7200
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6637b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6785f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6637b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c70ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6784e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6784e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34eb7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678048> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa467ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34905160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f955c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa465fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f349053c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34f955c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f349053c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6998d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6630f0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1748> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e7269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c71cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4fa465f7b8> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6400b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6400b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6409e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34facb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6997b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e683668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a66d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62ccc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 7400
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34f04ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e640a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f34971550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e64f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6996a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4fa46ee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e678978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6996a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e726f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6e10> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1713c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34971668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1979b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1979b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f907ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1185f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1185f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f34fac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171be0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1710b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 7500
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1716d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f3c750a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663f98> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e663438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e197588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e06a0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6e6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e17f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0454a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6784e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0455c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0450b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0457f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f3c6f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f6ee77278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e171198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e62c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0569e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069588> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 26.041666666666668
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1bf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0d3a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e12cc18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e08cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1e4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e1715f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e118b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e056588> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0331d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0331d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0339b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e045ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e6996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0331d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9df518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9df4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9df2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0332b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9df710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9df4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e07cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9df710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e033cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 7800
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0e0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e069f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f4f2e0332b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f4f2d9c7dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 26.041666666666668
initial coverage: 25.625
time passed (minutes): 60.0655
iterations: 274
number of new inputs: 256
final coverage: 26.0417
total coverage increase: 0.416667
